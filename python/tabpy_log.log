2021-01-28,13:46:50 [INFO] (app.py:app:242): Parsing config file /usr/local/lib/python3.8/site-packages/tabpy/tabpy_server/app/../common/default.conf
2021-01-28,13:46:50 [DEBUG] (app.py:app:194): Parameter port set to "9004" from config file or environment variable
2021-01-28,13:46:50 [DEBUG] (app.py:app:203): Parameter server_version set to "2.3.1" from default value
2021-01-28,13:46:50 [DEBUG] (app.py:app:194): Parameter evaluate_timeout set to "600.0" from config file or environment variable
2021-01-28,13:46:50 [DEBUG] (app.py:app:203): Parameter upload_dir set to "/usr/local/lib/python3.8/site-packages/tabpy/tmp/query_objects" from default value
2021-01-28,13:46:50 [DEBUG] (app.py:app:203): Parameter transfer_protocol set to "http" from default value
2021-01-28,13:46:50 [DEBUG] (app.py:app:210): Parameter certificate_file is not set
2021-01-28,13:46:50 [DEBUG] (app.py:app:210): Parameter key_file is not set
2021-01-28,13:46:50 [DEBUG] (app.py:app:203): Parameter state_file_path set to "/usr/local/lib/python3.8/site-packages/tabpy/tabpy_server" from default value
2021-01-28,13:46:50 [DEBUG] (app.py:app:203): Parameter static_path set to "/usr/local/lib/python3.8/site-packages/tabpy/tabpy_server/static" from default value
2021-01-28,13:46:50 [DEBUG] (app.py:app:210): Parameter TABPY_PWD_FILE is not set
2021-01-28,13:46:50 [DEBUG] (app.py:app:203): Parameter log_request_context set to "false" from default value
2021-01-28,13:46:50 [DEBUG] (app.py:app:203): Parameter max_request_size_in_mb set to "100" from default value
2021-01-28,13:46:50 [INFO] (app.py:app:431): Loading state from state file /usr/local/lib/python3.8/site-packages/tabpy/tabpy_server/state.ini
2021-01-28,13:46:50 [DEBUG] (app.py:app:309): Static pages folder set to "/usr/local/lib/python3.8/site-packages/tabpy/tabpy_server/static"
2021-01-28,13:46:50 [INFO] (app.py:app:328): Password file is not specified: Authentication is not enabled
2021-01-28,13:46:50 [INFO] (app.py:app:343): Call context logging is disabled
2021-01-28,13:46:50 [INFO] (app.py:app:124): Initializing TabPy...
2021-01-28,13:46:50 [DEBUG] (selector_events.py:selector_events:59): Using selector: EpollSelector
2021-01-28,13:46:50 [INFO] (callbacks.py:callbacks:43): Initializing TabPy Server...
2021-01-28,13:46:50 [DEBUG] (state.py:state:613): Loading option 'None' from section [Query Objects Service Versions]...
2021-01-28,13:46:50 [DEBUG] (state.py:state:635): Returning value '[]'
2021-01-28,13:46:50 [DEBUG] (state.py:state:148): Collected endpoints: {}
2021-01-28,13:46:50 [INFO] (app.py:app:128): Done initializing TabPy.
2021-01-28,13:46:50 [INFO] (app.py:app:82): Setting max request size to 104857600 bytes
2021-01-28,13:46:50 [INFO] (callbacks.py:callbacks:64): Initializing models...
2021-01-28,13:46:50 [DEBUG] (state.py:state:613): Loading option 'None' from section [Query Objects Service Versions]...
2021-01-28,13:46:50 [DEBUG] (state.py:state:635): Returning value '[]'
2021-01-28,13:46:50 [DEBUG] (state.py:state:148): Collected endpoints: {}
2021-01-28,13:46:50 [INFO] (app.py:app:105): Web service listening on port 9004
2021-01-28,13:46:55 [DEBUG] (base_handler.py:base_handler:115): Checking if need to handle authentication
2021-01-28,13:46:55 [DEBUG] (base_handler.py:base_handler:115): Handling authentication
2021-01-28,13:46:55 [INFO] (base_handler.py:base_handler:115): Authentication is not a required feature for API "v1"
2021-01-28,13:46:55 [DEBUG] (base_handler.py:base_handler:115): Checking request headers for authentication data
2021-01-28,13:46:55 [INFO] (base_handler.py:base_handler:115): Authorization header not found
2021-01-28,13:46:55 [DEBUG] (base_handler.py:base_handler:115): authentication not required, username and password are none
2021-01-28,13:46:55 [DEBUG] (state.py:state:511): Collecting Access-Control-Allow-Origin from state file ...
2021-01-28,13:46:55 [DEBUG] (state.py:state:613): Loading option 'Access-Control-Allow-Origin' from section [Service Info]...
2021-01-28,13:46:55 [DEBUG] (state.py:state:635): Returning value ''
2021-01-28,13:46:55 [DEBUG] (state.py:state:613): Loading option 'Access-Control-Allow-Headers' from section [Service Info]...
2021-01-28,13:46:55 [DEBUG] (state.py:state:635): Returning value ''
2021-01-28,13:46:55 [DEBUG] (state.py:state:613): Loading option 'Access-Control-Allow-Methods' from section [Service Info]...
2021-01-28,13:46:55 [DEBUG] (state.py:state:635): Returning value ''
2021-01-28,13:46:55 [DEBUG] (base_handler.py:base_handler:115): Processing POST request '{'data': {'_arg1': {'ds_name': ['prep_string_type']}}, 'script': 'import pandas as pd\ndef get_output_schema():\n\treturn \'5e1663ee-aeb8-40e2-9e10-d7644bc9e928\'\ndef prep_string():\n\treturn [\'prep_string_type\']\ndef prep_bool():\n\treturn [\'prep_bool_type\']\ndef prep_int():\n\treturn [\'prep_int_type\']\ndef prep_decimal():\n    return [\'prep_decimal_type\']\ndef prep_date():\n\treturn [\'prep_date_type\']\ndef prep_datetime():\n\treturn [\'prep_datetime_type\']\n# os is used to retrieve environment variables\n# requests is used to make HTTP requests out to Tableau Server\n# json is used to parse the answer received from the Tableau metadata API\n# pandas is used to build a dataframe and return data to Tableau Prep\n\nimport os\nimport requests\nimport json\nimport pandas as pd\n\n\n# login will perform a login into Tableau Server and return a session token\n# it uses the API_SERVER, API_SECRET_TOKEN and API_TOKEN_NAME environment variables\n# see docker-compose.yml for these environment variables\n\ndef login():\n    body = {"credentials": {"personalAccessTokenName": os.environ[\'API_TOKEN_NAME\'],\n                            "personalAccessTokenSecret": os.environ[\'API_SECRET_TOKEN\'],\n                            "site": {"contentUrl": ""}}}\n\n    print("Performing login")\n\n    url = "https://{server}/api/3.9/auth/signin".format(\n        server=os.environ["API_SERVER"])\n\n    headers = {\n        \'accept\': \'application/json\',\n        \'content-type\': \'application/json\'\n    }\n\n    # making the request\n    x = requests.post(url, json=body, headers=headers)\n    # parsing the login response\n    response = json.loads(x.text)\n    # if everything goes well, session token is found here:\n    token = response["credentials"]["token"]\n\n    return token\n\n# run_query runs a GRAPHQL query against the Tableau metadata API\n# arguments are a session token (obtained with login function) and the query text\n# it uses the API_SERVER environment variable to connect to the server; see docker-compose.yml\n\n\ndef run_query(token, query):\n    uri = "https://{server}/api/metadata/graphql".format(\n        server=os.environ["API_SERVER"])\n    headers = {\n        \'content-type\': \'application/json\',\n        \'accept\': \'application/json\',\n        \'X-Tableau-Auth\': token\n    }\n    x = requests.post(uri, json={\'query\': query}, headers=headers)\n\n    # we print the plain text answer for debugging purposes\n    print(x.text)\n\n    # we return the plain text answer received\n    return x.text\n\n\n# This function is called by Tableau Prep to obtain the expected schema of the data to receive\ndef get_output_schema():\n    return pd.DataFrame({\n        \'ds_name\': prep_string(),\n        \'flow_name\': prep_string(),\n        \'owner_name\': prep_string(),\n        \'project_name\': prep_string()\n    })\n\n\n# This is the function we well name in a Tableau Prep script node\n# It received data on the input, but doesn\'t use it\n\ndef get_published_ds_used_in_flow(input):\n\n    # The hardcoded Graphql query\n    query = """query published_datasources_certified {\n    publishedDatasources {\n      name\n      isCertified\n      downstreamFlows {\n        name,\n        owner {\n          name\n        },\n        projectName\n      }\n    }\n  }\n  """\n\n    print("Logging into Tableau Server...")\n    token = login()\n    print("Session token is: " + token)\n    print("")\n    print("Running the following query:")\n    print(query)\n    print("")\n    print("Answer below:")\n\n    # here we get text\n    json_string = run_query(token, query)\n\n    # we parse the result as a json structure\n    response_as_json = json.loads(json_string)\n\n    # we print the json structure\n    print(json.dumps(response_as_json, sort_keys=True, indent=4))\n\n    # navigating the json structure to find the starting node we need\n    list_of_published_ds = response_as_json["data"]["publishedDatasources"]\n\n    # this array will contain the data we will return to Tableau Prep\n    resultset = []\n\n    # navigating the json structure and collecting data\n    for ds in list_of_published_ds:\n        for flow in ds["downstreamFlows"]:\n            # when we find a downstream flow, we create one entry into the resultset\n            resultset.append([ds["name"], flow["name"],\n                              flow["owner"]["name"], flow["projectName"]])\n\n    # print the resultset for debugging purposes\n    print(resultset)\n\n    # we turn this python array into a pandas dataframe\n    df = pd.DataFrame(data=resultset, columns=[\n                      "ds_name", "flow_name", "owner_name", "project_name"])\n\n    # we return the dataframe to Tableau Prep\n    return(df)\ndef get_output_schema_bea97b3a58e648258274adfc99cd41f5(df = pd.DataFrame()):\n    import inspect\n    if len(inspect.getfullargspec(get_output_schema).args) == 0:\n        return get_output_schema()\n    else:\n        return get_output_schema(df)\nresult_schema_output = get_output_schema_bea97b3a58e648258274adfc99cd41f5(pd.DataFrame(_arg1))\nreturn result_schema_output.to_dict(orient=\'split\') if isinstance(result_schema_output, pd.DataFrame) else result_schema_output'}'...
2021-01-28,13:46:55 [INFO] (base_handler.py:base_handler:115): function to evaluate=def _user_script(tabpy, _arg1):
 import pandas as pd
 def get_output_schema():
 	return '5e1663ee-aeb8-40e2-9e10-d7644bc9e928'
 def prep_string():
 	return ['prep_string_type']
 def prep_bool():
 	return ['prep_bool_type']
 def prep_int():
 	return ['prep_int_type']
 def prep_decimal():
     return ['prep_decimal_type']
 def prep_date():
 	return ['prep_date_type']
 def prep_datetime():
 	return ['prep_datetime_type']
 # os is used to retrieve environment variables
 # requests is used to make HTTP requests out to Tableau Server
 # json is used to parse the answer received from the Tableau metadata API
 # pandas is used to build a dataframe and return data to Tableau Prep
 
 import os
 import requests
 import json
 import pandas as pd
 
 
 # login will perform a login into Tableau Server and return a session token
 # it uses the API_SERVER, API_SECRET_TOKEN and API_TOKEN_NAME environment variables
 # see docker-compose.yml for these environment variables
 
 def login():
     body = {"credentials": {"personalAccessTokenName": os.environ['API_TOKEN_NAME'],
                             "personalAccessTokenSecret": os.environ['API_SECRET_TOKEN'],
                             "site": {"contentUrl": ""}}}
 
     print("Performing login")
 
     url = "https://{server}/api/3.9/auth/signin".format(
         server=os.environ["API_SERVER"])
 
     headers = {
         'accept': 'application/json',
         'content-type': 'application/json'
     }
 
     # making the request
     x = requests.post(url, json=body, headers=headers)
     # parsing the login response
     response = json.loads(x.text)
     # if everything goes well, session token is found here:
     token = response["credentials"]["token"]
 
     return token
 
 # run_query runs a GRAPHQL query against the Tableau metadata API
 # arguments are a session token (obtained with login function) and the query text
 # it uses the API_SERVER environment variable to connect to the server; see docker-compose.yml
 
 
 def run_query(token, query):
     uri = "https://{server}/api/metadata/graphql".format(
         server=os.environ["API_SERVER"])
     headers = {
         'content-type': 'application/json',
         'accept': 'application/json',
         'X-Tableau-Auth': token
     }
     x = requests.post(uri, json={'query': query}, headers=headers)
 
     # we print the plain text answer for debugging purposes
     print(x.text)
 
     # we return the plain text answer received
     return x.text
 
 
 # This function is called by Tableau Prep to obtain the expected schema of the data to receive
 def get_output_schema():
     return pd.DataFrame({
         'ds_name': prep_string(),
         'flow_name': prep_string(),
         'owner_name': prep_string(),
         'project_name': prep_string()
     })
 
 
 # This is the function we well name in a Tableau Prep script node
 # It received data on the input, but doesn't use it
 
 def get_published_ds_used_in_flow(input):
 
     # The hardcoded Graphql query
     query = """query published_datasources_certified {
     publishedDatasources {
       name
       isCertified
       downstreamFlows {
         name,
         owner {
           name
         },
         projectName
       }
     }
   }
   """
 
     print("Logging into Tableau Server...")
     token = login()
     print("Session token is: " + token)
     print("")
     print("Running the following query:")
     print(query)
     print("")
     print("Answer below:")
 
     # here we get text
     json_string = run_query(token, query)
 
     # we parse the result as a json structure
     response_as_json = json.loads(json_string)
 
     # we print the json structure
     print(json.dumps(response_as_json, sort_keys=True, indent=4))
 
     # navigating the json structure to find the starting node we need
     list_of_published_ds = response_as_json["data"]["publishedDatasources"]
 
     # this array will contain the data we will return to Tableau Prep
     resultset = []
 
     # navigating the json structure and collecting data
     for ds in list_of_published_ds:
         for flow in ds["downstreamFlows"]:
             # when we find a downstream flow, we create one entry into the resultset
             resultset.append([ds["name"], flow["name"],
                               flow["owner"]["name"], flow["projectName"]])
 
     # print the resultset for debugging purposes
     print(resultset)
 
     # we turn this python array into a pandas dataframe
     df = pd.DataFrame(data=resultset, columns=[
                       "ds_name", "flow_name", "owner_name", "project_name"])
 
     # we return the dataframe to Tableau Prep
     return(df)
 def get_output_schema_bea97b3a58e648258274adfc99cd41f5(df = pd.DataFrame()):
     import inspect
     if len(inspect.getfullargspec(get_output_schema).args) == 0:
         return get_output_schema()
     else:
         return get_output_schema(df)
 result_schema_output = get_output_schema_bea97b3a58e648258274adfc99cd41f5(pd.DataFrame(_arg1))
 return result_schema_output.to_dict(orient='split') if isinstance(result_schema_output, pd.DataFrame) else result_schema_output

2021-01-28,13:46:55 [INFO] (web.py:web:2239): 200 POST /evaluate (172.18.0.1) 295.70ms
2021-01-28,13:46:55 [DEBUG] (base_handler.py:base_handler:115): Checking if need to handle authentication
2021-01-28,13:46:55 [DEBUG] (base_handler.py:base_handler:115): Handling authentication
2021-01-28,13:46:55 [INFO] (base_handler.py:base_handler:115): Authentication is not a required feature for API "v1"
2021-01-28,13:46:55 [DEBUG] (base_handler.py:base_handler:115): Checking request headers for authentication data
2021-01-28,13:46:55 [INFO] (base_handler.py:base_handler:115): Authorization header not found
2021-01-28,13:46:55 [DEBUG] (base_handler.py:base_handler:115): authentication not required, username and password are none
2021-01-28,13:46:55 [DEBUG] (state.py:state:511): Collecting Access-Control-Allow-Origin from state file ...
2021-01-28,13:46:55 [DEBUG] (state.py:state:613): Loading option 'Access-Control-Allow-Origin' from section [Service Info]...
2021-01-28,13:46:55 [DEBUG] (state.py:state:635): Returning value ''
2021-01-28,13:46:55 [DEBUG] (state.py:state:613): Loading option 'Access-Control-Allow-Headers' from section [Service Info]...
2021-01-28,13:46:55 [DEBUG] (state.py:state:635): Returning value ''
2021-01-28,13:46:55 [DEBUG] (state.py:state:613): Loading option 'Access-Control-Allow-Methods' from section [Service Info]...
2021-01-28,13:46:55 [DEBUG] (state.py:state:635): Returning value ''
2021-01-28,13:46:55 [DEBUG] (base_handler.py:base_handler:115): Processing POST request '{'data': {'_arg1': {'ds_name': ['prep_string_type']}}, 'script': 'import pandas as pd\ndef get_output_schema():\n\treturn \'5e1663ee-aeb8-40e2-9e10-d7644bc9e928\'\ndef prep_string():\n\treturn [\'prep_string_type\']\ndef prep_bool():\n\treturn [\'prep_bool_type\']\ndef prep_int():\n\treturn [\'prep_int_type\']\ndef prep_decimal():\n    return [\'prep_decimal_type\']\ndef prep_date():\n\treturn [\'prep_date_type\']\ndef prep_datetime():\n\treturn [\'prep_datetime_type\']\n# os is used to retrieve environment variables\n# requests is used to make HTTP requests out to Tableau Server\n# json is used to parse the answer received from the Tableau metadata API\n# pandas is used to build a dataframe and return data to Tableau Prep\n\nimport os\nimport requests\nimport json\nimport pandas as pd\n\n\n# login will perform a login into Tableau Server and return a session token\n# it uses the API_SERVER, API_SECRET_TOKEN and API_TOKEN_NAME environment variables\n# see docker-compose.yml for these environment variables\n\ndef login():\n    body = {"credentials": {"personalAccessTokenName": os.environ[\'API_TOKEN_NAME\'],\n                            "personalAccessTokenSecret": os.environ[\'API_SECRET_TOKEN\'],\n                            "site": {"contentUrl": ""}}}\n\n    print("Performing login")\n\n    url = "https://{server}/api/3.9/auth/signin".format(\n        server=os.environ["API_SERVER"])\n\n    headers = {\n        \'accept\': \'application/json\',\n        \'content-type\': \'application/json\'\n    }\n\n    # making the request\n    x = requests.post(url, json=body, headers=headers)\n    # parsing the login response\n    response = json.loads(x.text)\n    # if everything goes well, session token is found here:\n    token = response["credentials"]["token"]\n\n    return token\n\n# run_query runs a GRAPHQL query against the Tableau metadata API\n# arguments are a session token (obtained with login function) and the query text\n# it uses the API_SERVER environment variable to connect to the server; see docker-compose.yml\n\n\ndef run_query(token, query):\n    uri = "https://{server}/api/metadata/graphql".format(\n        server=os.environ["API_SERVER"])\n    headers = {\n        \'content-type\': \'application/json\',\n        \'accept\': \'application/json\',\n        \'X-Tableau-Auth\': token\n    }\n    x = requests.post(uri, json={\'query\': query}, headers=headers)\n\n    # we print the plain text answer for debugging purposes\n    print(x.text)\n\n    # we return the plain text answer received\n    return x.text\n\n\n# This function is called by Tableau Prep to obtain the expected schema of the data to receive\ndef get_output_schema():\n    return pd.DataFrame({\n        \'ds_name\': prep_string(),\n        \'flow_name\': prep_string(),\n        \'owner_name\': prep_string(),\n        \'project_name\': prep_string()\n    })\n\n\n# This is the function we well name in a Tableau Prep script node\n# It received data on the input, but doesn\'t use it\n\ndef get_published_ds_used_in_flow(input):\n\n    # The hardcoded Graphql query\n    query = """query published_datasources_certified {\n    publishedDatasources {\n      name\n      isCertified\n      downstreamFlows {\n        name,\n        owner {\n          name\n        },\n        projectName\n      }\n    }\n  }\n  """\n\n    print("Logging into Tableau Server...")\n    token = login()\n    print("Session token is: " + token)\n    print("")\n    print("Running the following query:")\n    print(query)\n    print("")\n    print("Answer below:")\n\n    # here we get text\n    json_string = run_query(token, query)\n\n    # we parse the result as a json structure\n    response_as_json = json.loads(json_string)\n\n    # we print the json structure\n    print(json.dumps(response_as_json, sort_keys=True, indent=4))\n\n    # navigating the json structure to find the starting node we need\n    list_of_published_ds = response_as_json["data"]["publishedDatasources"]\n\n    # this array will contain the data we will return to Tableau Prep\n    resultset = []\n\n    # navigating the json structure and collecting data\n    for ds in list_of_published_ds:\n        for flow in ds["downstreamFlows"]:\n            # when we find a downstream flow, we create one entry into the resultset\n            resultset.append([ds["name"], flow["name"],\n                              flow["owner"]["name"], flow["projectName"]])\n\n    # print the resultset for debugging purposes\n    print(resultset)\n\n    # we turn this python array into a pandas dataframe\n    df = pd.DataFrame(data=resultset, columns=[\n                      "ds_name", "flow_name", "owner_name", "project_name"])\n\n    # we return the dataframe to Tableau Prep\n    return(df)\ndef get_output_schema_bea97b3a58e648258274adfc99cd41f5(df = pd.DataFrame()):\n    import inspect\n    if len(inspect.getfullargspec(get_output_schema).args) == 0:\n        return get_output_schema()\n    else:\n        return get_output_schema(df)\nresult_schema_output = get_output_schema_bea97b3a58e648258274adfc99cd41f5(pd.DataFrame(_arg1))\nreturn result_schema_output.to_dict(orient=\'split\') if isinstance(result_schema_output, pd.DataFrame) else result_schema_output'}'...
2021-01-28,13:46:55 [INFO] (base_handler.py:base_handler:115): function to evaluate=def _user_script(tabpy, _arg1):
 import pandas as pd
 def get_output_schema():
 	return '5e1663ee-aeb8-40e2-9e10-d7644bc9e928'
 def prep_string():
 	return ['prep_string_type']
 def prep_bool():
 	return ['prep_bool_type']
 def prep_int():
 	return ['prep_int_type']
 def prep_decimal():
     return ['prep_decimal_type']
 def prep_date():
 	return ['prep_date_type']
 def prep_datetime():
 	return ['prep_datetime_type']
 # os is used to retrieve environment variables
 # requests is used to make HTTP requests out to Tableau Server
 # json is used to parse the answer received from the Tableau metadata API
 # pandas is used to build a dataframe and return data to Tableau Prep
 
 import os
 import requests
 import json
 import pandas as pd
 
 
 # login will perform a login into Tableau Server and return a session token
 # it uses the API_SERVER, API_SECRET_TOKEN and API_TOKEN_NAME environment variables
 # see docker-compose.yml for these environment variables
 
 def login():
     body = {"credentials": {"personalAccessTokenName": os.environ['API_TOKEN_NAME'],
                             "personalAccessTokenSecret": os.environ['API_SECRET_TOKEN'],
                             "site": {"contentUrl": ""}}}
 
     print("Performing login")
 
     url = "https://{server}/api/3.9/auth/signin".format(
         server=os.environ["API_SERVER"])
 
     headers = {
         'accept': 'application/json',
         'content-type': 'application/json'
     }
 
     # making the request
     x = requests.post(url, json=body, headers=headers)
     # parsing the login response
     response = json.loads(x.text)
     # if everything goes well, session token is found here:
     token = response["credentials"]["token"]
 
     return token
 
 # run_query runs a GRAPHQL query against the Tableau metadata API
 # arguments are a session token (obtained with login function) and the query text
 # it uses the API_SERVER environment variable to connect to the server; see docker-compose.yml
 
 
 def run_query(token, query):
     uri = "https://{server}/api/metadata/graphql".format(
         server=os.environ["API_SERVER"])
     headers = {
         'content-type': 'application/json',
         'accept': 'application/json',
         'X-Tableau-Auth': token
     }
     x = requests.post(uri, json={'query': query}, headers=headers)
 
     # we print the plain text answer for debugging purposes
     print(x.text)
 
     # we return the plain text answer received
     return x.text
 
 
 # This function is called by Tableau Prep to obtain the expected schema of the data to receive
 def get_output_schema():
     return pd.DataFrame({
         'ds_name': prep_string(),
         'flow_name': prep_string(),
         'owner_name': prep_string(),
         'project_name': prep_string()
     })
 
 
 # This is the function we well name in a Tableau Prep script node
 # It received data on the input, but doesn't use it
 
 def get_published_ds_used_in_flow(input):
 
     # The hardcoded Graphql query
     query = """query published_datasources_certified {
     publishedDatasources {
       name
       isCertified
       downstreamFlows {
         name,
         owner {
           name
         },
         projectName
       }
     }
   }
   """
 
     print("Logging into Tableau Server...")
     token = login()
     print("Session token is: " + token)
     print("")
     print("Running the following query:")
     print(query)
     print("")
     print("Answer below:")
 
     # here we get text
     json_string = run_query(token, query)
 
     # we parse the result as a json structure
     response_as_json = json.loads(json_string)
 
     # we print the json structure
     print(json.dumps(response_as_json, sort_keys=True, indent=4))
 
     # navigating the json structure to find the starting node we need
     list_of_published_ds = response_as_json["data"]["publishedDatasources"]
 
     # this array will contain the data we will return to Tableau Prep
     resultset = []
 
     # navigating the json structure and collecting data
     for ds in list_of_published_ds:
         for flow in ds["downstreamFlows"]:
             # when we find a downstream flow, we create one entry into the resultset
             resultset.append([ds["name"], flow["name"],
                               flow["owner"]["name"], flow["projectName"]])
 
     # print the resultset for debugging purposes
     print(resultset)
 
     # we turn this python array into a pandas dataframe
     df = pd.DataFrame(data=resultset, columns=[
                       "ds_name", "flow_name", "owner_name", "project_name"])
 
     # we return the dataframe to Tableau Prep
     return(df)
 def get_output_schema_bea97b3a58e648258274adfc99cd41f5(df = pd.DataFrame()):
     import inspect
     if len(inspect.getfullargspec(get_output_schema).args) == 0:
         return get_output_schema()
     else:
         return get_output_schema(df)
 result_schema_output = get_output_schema_bea97b3a58e648258274adfc99cd41f5(pd.DataFrame(_arg1))
 return result_schema_output.to_dict(orient='split') if isinstance(result_schema_output, pd.DataFrame) else result_schema_output

2021-01-28,13:46:55 [INFO] (web.py:web:2239): 200 POST /evaluate (172.18.0.1) 21.27ms
2021-01-28,13:47:52 [DEBUG] (base_handler.py:base_handler:115): Checking if need to handle authentication
2021-01-28,13:47:52 [DEBUG] (base_handler.py:base_handler:115): Handling authentication
2021-01-28,13:47:52 [INFO] (base_handler.py:base_handler:115): Authentication is not a required feature for API "v1"
2021-01-28,13:47:52 [DEBUG] (base_handler.py:base_handler:115): Checking request headers for authentication data
2021-01-28,13:47:52 [INFO] (base_handler.py:base_handler:115): Authorization header not found
2021-01-28,13:47:52 [DEBUG] (base_handler.py:base_handler:115): authentication not required, username and password are none
2021-01-28,13:47:52 [DEBUG] (state.py:state:511): Collecting Access-Control-Allow-Origin from state file ...
2021-01-28,13:47:52 [DEBUG] (state.py:state:613): Loading option 'Access-Control-Allow-Origin' from section [Service Info]...
2021-01-28,13:47:52 [DEBUG] (state.py:state:635): Returning value ''
2021-01-28,13:47:52 [DEBUG] (state.py:state:613): Loading option 'Access-Control-Allow-Headers' from section [Service Info]...
2021-01-28,13:47:52 [DEBUG] (state.py:state:635): Returning value ''
2021-01-28,13:47:52 [DEBUG] (state.py:state:613): Loading option 'Access-Control-Allow-Methods' from section [Service Info]...
2021-01-28,13:47:52 [DEBUG] (state.py:state:635): Returning value ''
2021-01-28,13:47:52 [DEBUG] (base_handler.py:base_handler:115): Processing POST request '{'data': {'_arg1': {'ds_name': ['prep_string_type']}}, 'script': 'import pandas as pd\ndef get_output_schema():\n\treturn \'5e1663ee-aeb8-40e2-9e10-d7644bc9e928\'\ndef prep_string():\n\treturn [\'prep_string_type\']\ndef prep_bool():\n\treturn [\'prep_bool_type\']\ndef prep_int():\n\treturn [\'prep_int_type\']\ndef prep_decimal():\n    return [\'prep_decimal_type\']\ndef prep_date():\n\treturn [\'prep_date_type\']\ndef prep_datetime():\n\treturn [\'prep_datetime_type\']\n# os is used to retrieve environment variables\n# requests is used to make HTTP requests out to Tableau Server\n# json is used to parse the answer received from the Tableau metadata API\n# pandas is used to build a dataframe and return data to Tableau Prep\n\nimport os\nimport requests\nimport json\nimport pandas as pd\n\n\n# login will perform a login into Tableau Server and return a session token\n# it uses the API_SERVER, API_SECRET_TOKEN and API_TOKEN_NAME environment variables\n# see docker-compose.yml for these environment variables\n\ndef login():\n    body = {"credentials": {"personalAccessTokenName": os.environ[\'API_TOKEN_NAME\'],\n                            "personalAccessTokenSecret": os.environ[\'API_SECRET_TOKEN\'],\n                            "site": {"contentUrl": ""}}}\n\n    print("Performing login")\n\n    url = "https://{server}/api/3.9/auth/signin".format(\n        server=os.environ["API_SERVER"])\n\n    headers = {\n        \'accept\': \'application/json\',\n        \'content-type\': \'application/json\'\n    }\n\n    # making the request\n    x = requests.post(url, json=body, headers=headers)\n    # parsing the login response\n    response = json.loads(x.text)\n    # if everything goes well, session token is found here:\n    token = response["credentials"]["token"]\n\n    return token\n\n# run_query runs a GRAPHQL query against the Tableau metadata API\n# arguments are a session token (obtained with login function) and the query text\n# it uses the API_SERVER environment variable to connect to the server; see docker-compose.yml\n\n\ndef run_query(token, query):\n    uri = "https://{server}/api/metadata/graphql".format(\n        server=os.environ["API_SERVER"])\n    headers = {\n        \'content-type\': \'application/json\',\n        \'accept\': \'application/json\',\n        \'X-Tableau-Auth\': token\n    }\n    x = requests.post(uri, json={\'query\': query}, headers=headers)\n\n    # we print the plain text answer for debugging purposes\n    print(x.text)\n\n    # we return the plain text answer received\n    return x.text\n\n\n# This function is called by Tableau Prep to obtain the expected schema of the data to receive\ndef get_output_schema():\n    return pd.DataFrame({\n        \'ds_name\': prep_string(),\n        \'flow_name\': prep_string(),\n        \'owner_name\': prep_string(),\n        \'project_name\': prep_string()\n    })\n\n\n# This is the function we well name in a Tableau Prep script node\n# It received data on the input, but doesn\'t use it\n\ndef get_published_ds_used_in_flow(input):\n\n    # The hardcoded Graphql query\n    query = """query published_datasources_certified {\n    publishedDatasources {\n      name\n      isCertified\n      downstreamFlows {\n        name,\n        owner {\n          name\n        },\n        projectName\n      }\n    }\n  }\n  """\n\n    print("Logging into Tableau Server...")\n    token = login()\n    print("Session token is: " + token)\n    print("")\n    print("Running the following query:")\n    print(query)\n    print("")\n    print("Answer below:")\n\n    # here we get text\n    json_string = run_query(token, query)\n\n    # we parse the result as a json structure\n    response_as_json = json.loads(json_string)\n\n    # we print the json structure\n    print(json.dumps(response_as_json, sort_keys=True, indent=4))\n\n    # navigating the json structure to find the starting node we need\n    list_of_published_ds = response_as_json["data"]["publishedDatasources"]\n\n    # this array will contain the data we will return to Tableau Prep\n    resultset = []\n\n    # navigating the json structure and collecting data\n    for ds in list_of_published_ds:\n        for flow in ds["downstreamFlows"]:\n            # when we find a downstream flow, we create one entry into the resultset\n            resultset.append([ds["name"], flow["name"],\n                              flow["owner"]["name"], flow["projectName"]])\n\n    # print the resultset for debugging purposes\n    print(resultset)\n\n    # we turn this python array into a pandas dataframe\n    df = pd.DataFrame(data=resultset, columns=[\n                      "ds_name", "flow_name", "owner_name", "project_name"])\n\n    # we return the dataframe to Tableau Prep\n    return(df)\ndef get_output_schema_bea97b3a58e648258274adfc99cd41f5(df = pd.DataFrame()):\n    import inspect\n    if len(inspect.getfullargspec(get_output_schema).args) == 0:\n        return get_output_schema()\n    else:\n        return get_output_schema(df)\nresult_schema_output = get_output_schema_bea97b3a58e648258274adfc99cd41f5(pd.DataFrame(_arg1))\nreturn result_schema_output.to_dict(orient=\'split\') if isinstance(result_schema_output, pd.DataFrame) else result_schema_output'}'...
2021-01-28,13:47:52 [INFO] (base_handler.py:base_handler:115): function to evaluate=def _user_script(tabpy, _arg1):
 import pandas as pd
 def get_output_schema():
 	return '5e1663ee-aeb8-40e2-9e10-d7644bc9e928'
 def prep_string():
 	return ['prep_string_type']
 def prep_bool():
 	return ['prep_bool_type']
 def prep_int():
 	return ['prep_int_type']
 def prep_decimal():
     return ['prep_decimal_type']
 def prep_date():
 	return ['prep_date_type']
 def prep_datetime():
 	return ['prep_datetime_type']
 # os is used to retrieve environment variables
 # requests is used to make HTTP requests out to Tableau Server
 # json is used to parse the answer received from the Tableau metadata API
 # pandas is used to build a dataframe and return data to Tableau Prep
 
 import os
 import requests
 import json
 import pandas as pd
 
 
 # login will perform a login into Tableau Server and return a session token
 # it uses the API_SERVER, API_SECRET_TOKEN and API_TOKEN_NAME environment variables
 # see docker-compose.yml for these environment variables
 
 def login():
     body = {"credentials": {"personalAccessTokenName": os.environ['API_TOKEN_NAME'],
                             "personalAccessTokenSecret": os.environ['API_SECRET_TOKEN'],
                             "site": {"contentUrl": ""}}}
 
     print("Performing login")
 
     url = "https://{server}/api/3.9/auth/signin".format(
         server=os.environ["API_SERVER"])
 
     headers = {
         'accept': 'application/json',
         'content-type': 'application/json'
     }
 
     # making the request
     x = requests.post(url, json=body, headers=headers)
     # parsing the login response
     response = json.loads(x.text)
     # if everything goes well, session token is found here:
     token = response["credentials"]["token"]
 
     return token
 
 # run_query runs a GRAPHQL query against the Tableau metadata API
 # arguments are a session token (obtained with login function) and the query text
 # it uses the API_SERVER environment variable to connect to the server; see docker-compose.yml
 
 
 def run_query(token, query):
     uri = "https://{server}/api/metadata/graphql".format(
         server=os.environ["API_SERVER"])
     headers = {
         'content-type': 'application/json',
         'accept': 'application/json',
         'X-Tableau-Auth': token
     }
     x = requests.post(uri, json={'query': query}, headers=headers)
 
     # we print the plain text answer for debugging purposes
     print(x.text)
 
     # we return the plain text answer received
     return x.text
 
 
 # This function is called by Tableau Prep to obtain the expected schema of the data to receive
 def get_output_schema():
     return pd.DataFrame({
         'ds_name': prep_string(),
         'flow_name': prep_string(),
         'owner_name': prep_string(),
         'project_name': prep_string()
     })
 
 
 # This is the function we well name in a Tableau Prep script node
 # It received data on the input, but doesn't use it
 
 def get_published_ds_used_in_flow(input):
 
     # The hardcoded Graphql query
     query = """query published_datasources_certified {
     publishedDatasources {
       name
       isCertified
       downstreamFlows {
         name,
         owner {
           name
         },
         projectName
       }
     }
   }
   """
 
     print("Logging into Tableau Server...")
     token = login()
     print("Session token is: " + token)
     print("")
     print("Running the following query:")
     print(query)
     print("")
     print("Answer below:")
 
     # here we get text
     json_string = run_query(token, query)
 
     # we parse the result as a json structure
     response_as_json = json.loads(json_string)
 
     # we print the json structure
     print(json.dumps(response_as_json, sort_keys=True, indent=4))
 
     # navigating the json structure to find the starting node we need
     list_of_published_ds = response_as_json["data"]["publishedDatasources"]
 
     # this array will contain the data we will return to Tableau Prep
     resultset = []
 
     # navigating the json structure and collecting data
     for ds in list_of_published_ds:
         for flow in ds["downstreamFlows"]:
             # when we find a downstream flow, we create one entry into the resultset
             resultset.append([ds["name"], flow["name"],
                               flow["owner"]["name"], flow["projectName"]])
 
     # print the resultset for debugging purposes
     print(resultset)
 
     # we turn this python array into a pandas dataframe
     df = pd.DataFrame(data=resultset, columns=[
                       "ds_name", "flow_name", "owner_name", "project_name"])
 
     # we return the dataframe to Tableau Prep
     return(df)
 def get_output_schema_bea97b3a58e648258274adfc99cd41f5(df = pd.DataFrame()):
     import inspect
     if len(inspect.getfullargspec(get_output_schema).args) == 0:
         return get_output_schema()
     else:
         return get_output_schema(df)
 result_schema_output = get_output_schema_bea97b3a58e648258274adfc99cd41f5(pd.DataFrame(_arg1))
 return result_schema_output.to_dict(orient='split') if isinstance(result_schema_output, pd.DataFrame) else result_schema_output

2021-01-28,13:47:52 [INFO] (web.py:web:2239): 200 POST /evaluate (172.18.0.1) 30.42ms
2021-01-28,13:47:52 [DEBUG] (base_handler.py:base_handler:115): Checking if need to handle authentication
2021-01-28,13:47:52 [DEBUG] (base_handler.py:base_handler:115): Handling authentication
2021-01-28,13:47:52 [INFO] (base_handler.py:base_handler:115): Authentication is not a required feature for API "v1"
2021-01-28,13:47:52 [DEBUG] (base_handler.py:base_handler:115): Checking request headers for authentication data
2021-01-28,13:47:52 [INFO] (base_handler.py:base_handler:115): Authorization header not found
2021-01-28,13:47:52 [DEBUG] (base_handler.py:base_handler:115): authentication not required, username and password are none
2021-01-28,13:47:52 [DEBUG] (state.py:state:511): Collecting Access-Control-Allow-Origin from state file ...
2021-01-28,13:47:52 [DEBUG] (state.py:state:613): Loading option 'Access-Control-Allow-Origin' from section [Service Info]...
2021-01-28,13:47:52 [DEBUG] (state.py:state:635): Returning value ''
2021-01-28,13:47:52 [DEBUG] (state.py:state:613): Loading option 'Access-Control-Allow-Headers' from section [Service Info]...
2021-01-28,13:47:52 [DEBUG] (state.py:state:635): Returning value ''
2021-01-28,13:47:52 [DEBUG] (state.py:state:613): Loading option 'Access-Control-Allow-Methods' from section [Service Info]...
2021-01-28,13:47:52 [DEBUG] (state.py:state:635): Returning value ''
2021-01-28,13:47:52 [DEBUG] (base_handler.py:base_handler:115): Processing POST request '{'data': {'_arg1': {'ds_name': ['prep_string_type']}}, 'script': 'import pandas as pd\ndef get_output_schema():\n\treturn \'5e1663ee-aeb8-40e2-9e10-d7644bc9e928\'\ndef prep_string():\n\treturn [\'prep_string_type\']\ndef prep_bool():\n\treturn [\'prep_bool_type\']\ndef prep_int():\n\treturn [\'prep_int_type\']\ndef prep_decimal():\n    return [\'prep_decimal_type\']\ndef prep_date():\n\treturn [\'prep_date_type\']\ndef prep_datetime():\n\treturn [\'prep_datetime_type\']\n# os is used to retrieve environment variables\n# requests is used to make HTTP requests out to Tableau Server\n# json is used to parse the answer received from the Tableau metadata API\n# pandas is used to build a dataframe and return data to Tableau Prep\n\nimport os\nimport requests\nimport json\nimport pandas as pd\n\n\n# login will perform a login into Tableau Server and return a session token\n# it uses the API_SERVER, API_SECRET_TOKEN and API_TOKEN_NAME environment variables\n# see docker-compose.yml for these environment variables\n\ndef login():\n    body = {"credentials": {"personalAccessTokenName": os.environ[\'API_TOKEN_NAME\'],\n                            "personalAccessTokenSecret": os.environ[\'API_SECRET_TOKEN\'],\n                            "site": {"contentUrl": ""}}}\n\n    print("Performing login")\n\n    url = "https://{server}/api/3.9/auth/signin".format(\n        server=os.environ["API_SERVER"])\n\n    headers = {\n        \'accept\': \'application/json\',\n        \'content-type\': \'application/json\'\n    }\n\n    # making the request\n    x = requests.post(url, json=body, headers=headers)\n    # parsing the login response\n    response = json.loads(x.text)\n    # if everything goes well, session token is found here:\n    token = response["credentials"]["token"]\n\n    return token\n\n# run_query runs a GRAPHQL query against the Tableau metadata API\n# arguments are a session token (obtained with login function) and the query text\n# it uses the API_SERVER environment variable to connect to the server; see docker-compose.yml\n\n\ndef run_query(token, query):\n    uri = "https://{server}/api/metadata/graphql".format(\n        server=os.environ["API_SERVER"])\n    headers = {\n        \'content-type\': \'application/json\',\n        \'accept\': \'application/json\',\n        \'X-Tableau-Auth\': token\n    }\n    x = requests.post(uri, json={\'query\': query}, headers=headers)\n\n    # we print the plain text answer for debugging purposes\n    print(x.text)\n\n    # we return the plain text answer received\n    return x.text\n\n\n# This function is called by Tableau Prep to obtain the expected schema of the data to receive\ndef get_output_schema():\n    return pd.DataFrame({\n        \'ds_name\': prep_string(),\n        \'flow_name\': prep_string(),\n        \'owner_name\': prep_string(),\n        \'project_name\': prep_string()\n    })\n\n\n# This is the function we well name in a Tableau Prep script node\n# It received data on the input, but doesn\'t use it\n\ndef get_published_ds_used_in_flow(input):\n\n    # The hardcoded Graphql query\n    query = """query published_datasources_certified {\n    publishedDatasources {\n      name\n      isCertified\n      downstreamFlows {\n        name,\n        owner {\n          name\n        },\n        projectName\n      }\n    }\n  }\n  """\n\n    print("Logging into Tableau Server...")\n    token = login()\n    print("Session token is: " + token)\n    print("")\n    print("Running the following query:")\n    print(query)\n    print("")\n    print("Answer below:")\n\n    # here we get text\n    json_string = run_query(token, query)\n\n    # we parse the result as a json structure\n    response_as_json = json.loads(json_string)\n\n    # we print the json structure\n    print(json.dumps(response_as_json, sort_keys=True, indent=4))\n\n    # navigating the json structure to find the starting node we need\n    list_of_published_ds = response_as_json["data"]["publishedDatasources"]\n\n    # this array will contain the data we will return to Tableau Prep\n    resultset = []\n\n    # navigating the json structure and collecting data\n    for ds in list_of_published_ds:\n        for flow in ds["downstreamFlows"]:\n            # when we find a downstream flow, we create one entry into the resultset\n            resultset.append([ds["name"], flow["name"],\n                              flow["owner"]["name"], flow["projectName"]])\n\n    # print the resultset for debugging purposes\n    print(resultset)\n\n    # we turn this python array into a pandas dataframe\n    df = pd.DataFrame(data=resultset, columns=[\n                      "ds_name", "flow_name", "owner_name", "project_name"])\n\n    # we return the dataframe to Tableau Prep\n    return(df)\ndef get_output_schema_bea97b3a58e648258274adfc99cd41f5(df = pd.DataFrame()):\n    import inspect\n    if len(inspect.getfullargspec(get_output_schema).args) == 0:\n        return get_output_schema()\n    else:\n        return get_output_schema(df)\nresult_schema_output = get_output_schema_bea97b3a58e648258274adfc99cd41f5(pd.DataFrame(_arg1))\nreturn result_schema_output.to_dict(orient=\'split\') if isinstance(result_schema_output, pd.DataFrame) else result_schema_output'}'...
2021-01-28,13:47:53 [INFO] (base_handler.py:base_handler:115): function to evaluate=def _user_script(tabpy, _arg1):
 import pandas as pd
 def get_output_schema():
 	return '5e1663ee-aeb8-40e2-9e10-d7644bc9e928'
 def prep_string():
 	return ['prep_string_type']
 def prep_bool():
 	return ['prep_bool_type']
 def prep_int():
 	return ['prep_int_type']
 def prep_decimal():
     return ['prep_decimal_type']
 def prep_date():
 	return ['prep_date_type']
 def prep_datetime():
 	return ['prep_datetime_type']
 # os is used to retrieve environment variables
 # requests is used to make HTTP requests out to Tableau Server
 # json is used to parse the answer received from the Tableau metadata API
 # pandas is used to build a dataframe and return data to Tableau Prep
 
 import os
 import requests
 import json
 import pandas as pd
 
 
 # login will perform a login into Tableau Server and return a session token
 # it uses the API_SERVER, API_SECRET_TOKEN and API_TOKEN_NAME environment variables
 # see docker-compose.yml for these environment variables
 
 def login():
     body = {"credentials": {"personalAccessTokenName": os.environ['API_TOKEN_NAME'],
                             "personalAccessTokenSecret": os.environ['API_SECRET_TOKEN'],
                             "site": {"contentUrl": ""}}}
 
     print("Performing login")
 
     url = "https://{server}/api/3.9/auth/signin".format(
         server=os.environ["API_SERVER"])
 
     headers = {
         'accept': 'application/json',
         'content-type': 'application/json'
     }
 
     # making the request
     x = requests.post(url, json=body, headers=headers)
     # parsing the login response
     response = json.loads(x.text)
     # if everything goes well, session token is found here:
     token = response["credentials"]["token"]
 
     return token
 
 # run_query runs a GRAPHQL query against the Tableau metadata API
 # arguments are a session token (obtained with login function) and the query text
 # it uses the API_SERVER environment variable to connect to the server; see docker-compose.yml
 
 
 def run_query(token, query):
     uri = "https://{server}/api/metadata/graphql".format(
         server=os.environ["API_SERVER"])
     headers = {
         'content-type': 'application/json',
         'accept': 'application/json',
         'X-Tableau-Auth': token
     }
     x = requests.post(uri, json={'query': query}, headers=headers)
 
     # we print the plain text answer for debugging purposes
     print(x.text)
 
     # we return the plain text answer received
     return x.text
 
 
 # This function is called by Tableau Prep to obtain the expected schema of the data to receive
 def get_output_schema():
     return pd.DataFrame({
         'ds_name': prep_string(),
         'flow_name': prep_string(),
         'owner_name': prep_string(),
         'project_name': prep_string()
     })
 
 
 # This is the function we well name in a Tableau Prep script node
 # It received data on the input, but doesn't use it
 
 def get_published_ds_used_in_flow(input):
 
     # The hardcoded Graphql query
     query = """query published_datasources_certified {
     publishedDatasources {
       name
       isCertified
       downstreamFlows {
         name,
         owner {
           name
         },
         projectName
       }
     }
   }
   """
 
     print("Logging into Tableau Server...")
     token = login()
     print("Session token is: " + token)
     print("")
     print("Running the following query:")
     print(query)
     print("")
     print("Answer below:")
 
     # here we get text
     json_string = run_query(token, query)
 
     # we parse the result as a json structure
     response_as_json = json.loads(json_string)
 
     # we print the json structure
     print(json.dumps(response_as_json, sort_keys=True, indent=4))
 
     # navigating the json structure to find the starting node we need
     list_of_published_ds = response_as_json["data"]["publishedDatasources"]
 
     # this array will contain the data we will return to Tableau Prep
     resultset = []
 
     # navigating the json structure and collecting data
     for ds in list_of_published_ds:
         for flow in ds["downstreamFlows"]:
             # when we find a downstream flow, we create one entry into the resultset
             resultset.append([ds["name"], flow["name"],
                               flow["owner"]["name"], flow["projectName"]])
 
     # print the resultset for debugging purposes
     print(resultset)
 
     # we turn this python array into a pandas dataframe
     df = pd.DataFrame(data=resultset, columns=[
                       "ds_name", "flow_name", "owner_name", "project_name"])
 
     # we return the dataframe to Tableau Prep
     return(df)
 def get_output_schema_bea97b3a58e648258274adfc99cd41f5(df = pd.DataFrame()):
     import inspect
     if len(inspect.getfullargspec(get_output_schema).args) == 0:
         return get_output_schema()
     else:
         return get_output_schema(df)
 result_schema_output = get_output_schema_bea97b3a58e648258274adfc99cd41f5(pd.DataFrame(_arg1))
 return result_schema_output.to_dict(orient='split') if isinstance(result_schema_output, pd.DataFrame) else result_schema_output

2021-01-28,13:47:53 [INFO] (web.py:web:2239): 200 POST /evaluate (172.18.0.1) 27.83ms
2021-01-28,13:47:53 [DEBUG] (base_handler.py:base_handler:115): Checking if need to handle authentication
2021-01-28,13:47:53 [DEBUG] (base_handler.py:base_handler:115): Handling authentication
2021-01-28,13:47:53 [INFO] (base_handler.py:base_handler:115): Authentication is not a required feature for API "v1"
2021-01-28,13:47:53 [DEBUG] (base_handler.py:base_handler:115): Checking request headers for authentication data
2021-01-28,13:47:53 [INFO] (base_handler.py:base_handler:115): Authorization header not found
2021-01-28,13:47:53 [DEBUG] (base_handler.py:base_handler:115): authentication not required, username and password are none
2021-01-28,13:47:53 [DEBUG] (state.py:state:511): Collecting Access-Control-Allow-Origin from state file ...
2021-01-28,13:47:53 [DEBUG] (state.py:state:613): Loading option 'Access-Control-Allow-Origin' from section [Service Info]...
2021-01-28,13:47:53 [DEBUG] (state.py:state:635): Returning value ''
2021-01-28,13:47:53 [DEBUG] (state.py:state:613): Loading option 'Access-Control-Allow-Headers' from section [Service Info]...
2021-01-28,13:47:53 [DEBUG] (state.py:state:635): Returning value ''
2021-01-28,13:47:53 [DEBUG] (state.py:state:613): Loading option 'Access-Control-Allow-Methods' from section [Service Info]...
2021-01-28,13:47:53 [DEBUG] (state.py:state:635): Returning value ''
2021-01-28,13:47:53 [DEBUG] (base_handler.py:base_handler:115): Processing POST request '{'data': {'_arg1': {'ds_name': ['prep_string_type']}}, 'script': 'import pandas as pd\ndef get_output_schema():\n\treturn \'5e1663ee-aeb8-40e2-9e10-d7644bc9e928\'\ndef prep_string():\n\treturn [\'prep_string_type\']\ndef prep_bool():\n\treturn [\'prep_bool_type\']\ndef prep_int():\n\treturn [\'prep_int_type\']\ndef prep_decimal():\n    return [\'prep_decimal_type\']\ndef prep_date():\n\treturn [\'prep_date_type\']\ndef prep_datetime():\n\treturn [\'prep_datetime_type\']\n# os is used to retrieve environment variables\n# requests is used to make HTTP requests out to Tableau Server\n# json is used to parse the answer received from the Tableau metadata API\n# pandas is used to build a dataframe and return data to Tableau Prep\n\nimport os\nimport requests\nimport json\nimport pandas as pd\n\n\n# login will perform a login into Tableau Server and return a session token\n# it uses the API_SERVER, API_SECRET_TOKEN and API_TOKEN_NAME environment variables\n# see docker-compose.yml for these environment variables\n\ndef login():\n    body = {"credentials": {"personalAccessTokenName": os.environ[\'API_TOKEN_NAME\'],\n                            "personalAccessTokenSecret": os.environ[\'API_SECRET_TOKEN\'],\n                            "site": {"contentUrl": ""}}}\n\n    print("Performing login")\n\n    url = "https://{server}/api/3.9/auth/signin".format(\n        server=os.environ["API_SERVER"])\n\n    headers = {\n        \'accept\': \'application/json\',\n        \'content-type\': \'application/json\'\n    }\n\n    # making the request\n    x = requests.post(url, json=body, headers=headers)\n    # parsing the login response\n    response = json.loads(x.text)\n    # if everything goes well, session token is found here:\n    token = response["credentials"]["token"]\n\n    return token\n\n# run_query runs a GRAPHQL query against the Tableau metadata API\n# arguments are a session token (obtained with login function) and the query text\n# it uses the API_SERVER environment variable to connect to the server; see docker-compose.yml\n\n\ndef run_query(token, query):\n    uri = "https://{server}/api/metadata/graphql".format(\n        server=os.environ["API_SERVER"])\n    headers = {\n        \'content-type\': \'application/json\',\n        \'accept\': \'application/json\',\n        \'X-Tableau-Auth\': token\n    }\n    x = requests.post(uri, json={\'query\': query}, headers=headers)\n\n    # we print the plain text answer for debugging purposes\n    print(x.text)\n\n    # we return the plain text answer received\n    return x.text\n\n\n# This function is called by Tableau Prep to obtain the expected schema of the data to receive\ndef get_output_schema():\n    return pd.DataFrame({\n        \'ds_name\': prep_string(),\n        \'flow_name\': prep_string(),\n        \'owner_name\': prep_string(),\n        \'project_name\': prep_string()\n    })\n\n\n# This is the function we well name in a Tableau Prep script node\n# It received data on the input, but doesn\'t use it\n\ndef get_published_ds_used_in_flow(input):\n\n    # The hardcoded Graphql query\n    query = """query published_datasources_certified {\n    publishedDatasources {\n      name\n      isCertified\n      downstreamFlows {\n        name,\n        owner {\n          name\n        },\n        projectName\n      }\n    }\n  }\n  """\n\n    print("Logging into Tableau Server...")\n    token = login()\n    print("Session token is: " + token)\n    print("")\n    print("Running the following query:")\n    print(query)\n    print("")\n    print("Answer below:")\n\n    # here we get text\n    json_string = run_query(token, query)\n\n    # we parse the result as a json structure\n    response_as_json = json.loads(json_string)\n\n    # we print the json structure\n    print(json.dumps(response_as_json, sort_keys=True, indent=4))\n\n    # navigating the json structure to find the starting node we need\n    list_of_published_ds = response_as_json["data"]["publishedDatasources"]\n\n    # this array will contain the data we will return to Tableau Prep\n    resultset = []\n\n    # navigating the json structure and collecting data\n    for ds in list_of_published_ds:\n        for flow in ds["downstreamFlows"]:\n            # when we find a downstream flow, we create one entry into the resultset\n            resultset.append([ds["name"], flow["name"],\n                              flow["owner"]["name"], flow["projectName"]])\n\n    # print the resultset for debugging purposes\n    print(resultset)\n\n    # we turn this python array into a pandas dataframe\n    df = pd.DataFrame(data=resultset, columns=[\n                      "ds_name", "flow_name", "owner_name", "project_name"])\n\n    # we return the dataframe to Tableau Prep\n    return(df)\ndef get_output_schema_bea97b3a58e648258274adfc99cd41f5(df = pd.DataFrame()):\n    import inspect\n    if len(inspect.getfullargspec(get_output_schema).args) == 0:\n        return get_output_schema()\n    else:\n        return get_output_schema(df)\nresult_schema_output = get_output_schema_bea97b3a58e648258274adfc99cd41f5(pd.DataFrame(_arg1))\nreturn result_schema_output.to_dict(orient=\'split\') if isinstance(result_schema_output, pd.DataFrame) else result_schema_output'}'...
2021-01-28,13:47:53 [INFO] (base_handler.py:base_handler:115): function to evaluate=def _user_script(tabpy, _arg1):
 import pandas as pd
 def get_output_schema():
 	return '5e1663ee-aeb8-40e2-9e10-d7644bc9e928'
 def prep_string():
 	return ['prep_string_type']
 def prep_bool():
 	return ['prep_bool_type']
 def prep_int():
 	return ['prep_int_type']
 def prep_decimal():
     return ['prep_decimal_type']
 def prep_date():
 	return ['prep_date_type']
 def prep_datetime():
 	return ['prep_datetime_type']
 # os is used to retrieve environment variables
 # requests is used to make HTTP requests out to Tableau Server
 # json is used to parse the answer received from the Tableau metadata API
 # pandas is used to build a dataframe and return data to Tableau Prep
 
 import os
 import requests
 import json
 import pandas as pd
 
 
 # login will perform a login into Tableau Server and return a session token
 # it uses the API_SERVER, API_SECRET_TOKEN and API_TOKEN_NAME environment variables
 # see docker-compose.yml for these environment variables
 
 def login():
     body = {"credentials": {"personalAccessTokenName": os.environ['API_TOKEN_NAME'],
                             "personalAccessTokenSecret": os.environ['API_SECRET_TOKEN'],
                             "site": {"contentUrl": ""}}}
 
     print("Performing login")
 
     url = "https://{server}/api/3.9/auth/signin".format(
         server=os.environ["API_SERVER"])
 
     headers = {
         'accept': 'application/json',
         'content-type': 'application/json'
     }
 
     # making the request
     x = requests.post(url, json=body, headers=headers)
     # parsing the login response
     response = json.loads(x.text)
     # if everything goes well, session token is found here:
     token = response["credentials"]["token"]
 
     return token
 
 # run_query runs a GRAPHQL query against the Tableau metadata API
 # arguments are a session token (obtained with login function) and the query text
 # it uses the API_SERVER environment variable to connect to the server; see docker-compose.yml
 
 
 def run_query(token, query):
     uri = "https://{server}/api/metadata/graphql".format(
         server=os.environ["API_SERVER"])
     headers = {
         'content-type': 'application/json',
         'accept': 'application/json',
         'X-Tableau-Auth': token
     }
     x = requests.post(uri, json={'query': query}, headers=headers)
 
     # we print the plain text answer for debugging purposes
     print(x.text)
 
     # we return the plain text answer received
     return x.text
 
 
 # This function is called by Tableau Prep to obtain the expected schema of the data to receive
 def get_output_schema():
     return pd.DataFrame({
         'ds_name': prep_string(),
         'flow_name': prep_string(),
         'owner_name': prep_string(),
         'project_name': prep_string()
     })
 
 
 # This is the function we well name in a Tableau Prep script node
 # It received data on the input, but doesn't use it
 
 def get_published_ds_used_in_flow(input):
 
     # The hardcoded Graphql query
     query = """query published_datasources_certified {
     publishedDatasources {
       name
       isCertified
       downstreamFlows {
         name,
         owner {
           name
         },
         projectName
       }
     }
   }
   """
 
     print("Logging into Tableau Server...")
     token = login()
     print("Session token is: " + token)
     print("")
     print("Running the following query:")
     print(query)
     print("")
     print("Answer below:")
 
     # here we get text
     json_string = run_query(token, query)
 
     # we parse the result as a json structure
     response_as_json = json.loads(json_string)
 
     # we print the json structure
     print(json.dumps(response_as_json, sort_keys=True, indent=4))
 
     # navigating the json structure to find the starting node we need
     list_of_published_ds = response_as_json["data"]["publishedDatasources"]
 
     # this array will contain the data we will return to Tableau Prep
     resultset = []
 
     # navigating the json structure and collecting data
     for ds in list_of_published_ds:
         for flow in ds["downstreamFlows"]:
             # when we find a downstream flow, we create one entry into the resultset
             resultset.append([ds["name"], flow["name"],
                               flow["owner"]["name"], flow["projectName"]])
 
     # print the resultset for debugging purposes
     print(resultset)
 
     # we turn this python array into a pandas dataframe
     df = pd.DataFrame(data=resultset, columns=[
                       "ds_name", "flow_name", "owner_name", "project_name"])
 
     # we return the dataframe to Tableau Prep
     return(df)
 def get_output_schema_bea97b3a58e648258274adfc99cd41f5(df = pd.DataFrame()):
     import inspect
     if len(inspect.getfullargspec(get_output_schema).args) == 0:
         return get_output_schema()
     else:
         return get_output_schema(df)
 result_schema_output = get_output_schema_bea97b3a58e648258274adfc99cd41f5(pd.DataFrame(_arg1))
 return result_schema_output.to_dict(orient='split') if isinstance(result_schema_output, pd.DataFrame) else result_schema_output

2021-01-28,13:47:53 [DEBUG] (base_handler.py:base_handler:115): Checking if need to handle authentication
2021-01-28,13:47:53 [DEBUG] (base_handler.py:base_handler:115): Handling authentication
2021-01-28,13:47:53 [INFO] (base_handler.py:base_handler:115): Authentication is not a required feature for API "v1"
2021-01-28,13:47:53 [DEBUG] (base_handler.py:base_handler:115): Checking request headers for authentication data
2021-01-28,13:47:53 [INFO] (base_handler.py:base_handler:115): Authorization header not found
2021-01-28,13:47:53 [DEBUG] (base_handler.py:base_handler:115): authentication not required, username and password are none
2021-01-28,13:47:53 [DEBUG] (base_handler.py:base_handler:115): Checking if need to handle authentication
2021-01-28,13:47:53 [DEBUG] (base_handler.py:base_handler:115): Handling authentication
2021-01-28,13:47:53 [INFO] (base_handler.py:base_handler:115): Authentication is not a required feature for API "v1"
2021-01-28,13:47:53 [DEBUG] (base_handler.py:base_handler:115): Checking request headers for authentication data
2021-01-28,13:47:53 [INFO] (base_handler.py:base_handler:115): Authorization header not found
2021-01-28,13:47:53 [DEBUG] (base_handler.py:base_handler:115): authentication not required, username and password are none
2021-01-28,13:47:53 [DEBUG] (state.py:state:511): Collecting Access-Control-Allow-Origin from state file ...
2021-01-28,13:47:53 [DEBUG] (state.py:state:613): Loading option 'Access-Control-Allow-Origin' from section [Service Info]...
2021-01-28,13:47:53 [DEBUG] (state.py:state:635): Returning value ''
2021-01-28,13:47:53 [DEBUG] (state.py:state:613): Loading option 'Access-Control-Allow-Headers' from section [Service Info]...
2021-01-28,13:47:53 [DEBUG] (state.py:state:635): Returning value ''
2021-01-28,13:47:53 [DEBUG] (state.py:state:613): Loading option 'Access-Control-Allow-Methods' from section [Service Info]...
2021-01-28,13:47:53 [DEBUG] (state.py:state:635): Returning value ''
2021-01-28,13:47:53 [DEBUG] (base_handler.py:base_handler:115): Processing POST request '{'data': {'_arg1': {'ds_name': ['prep_string_type']}}, 'script': 'import pandas as pd\ndef get_output_schema():\n\treturn \'5e1663ee-aeb8-40e2-9e10-d7644bc9e928\'\ndef prep_string():\n\treturn [\'prep_string_type\']\ndef prep_bool():\n\treturn [\'prep_bool_type\']\ndef prep_int():\n\treturn [\'prep_int_type\']\ndef prep_decimal():\n    return [\'prep_decimal_type\']\ndef prep_date():\n\treturn [\'prep_date_type\']\ndef prep_datetime():\n\treturn [\'prep_datetime_type\']\n# os is used to retrieve environment variables\n# requests is used to make HTTP requests out to Tableau Server\n# json is used to parse the answer received from the Tableau metadata API\n# pandas is used to build a dataframe and return data to Tableau Prep\n\nimport os\nimport requests\nimport json\nimport pandas as pd\n\n\n# login will perform a login into Tableau Server and return a session token\n# it uses the API_SERVER, API_SECRET_TOKEN and API_TOKEN_NAME environment variables\n# see docker-compose.yml for these environment variables\n\ndef login():\n    body = {"credentials": {"personalAccessTokenName": os.environ[\'API_TOKEN_NAME\'],\n                            "personalAccessTokenSecret": os.environ[\'API_SECRET_TOKEN\'],\n                            "site": {"contentUrl": ""}}}\n\n    print("Performing login")\n\n    url = "https://{server}/api/3.9/auth/signin".format(\n        server=os.environ["API_SERVER"])\n\n    headers = {\n        \'accept\': \'application/json\',\n        \'content-type\': \'application/json\'\n    }\n\n    # making the request\n    x = requests.post(url, json=body, headers=headers)\n    # parsing the login response\n    response = json.loads(x.text)\n    # if everything goes well, session token is found here:\n    token = response["credentials"]["token"]\n\n    return token\n\n# run_query runs a GRAPHQL query against the Tableau metadata API\n# arguments are a session token (obtained with login function) and the query text\n# it uses the API_SERVER environment variable to connect to the server; see docker-compose.yml\n\n\ndef run_query(token, query):\n    uri = "https://{server}/api/metadata/graphql".format(\n        server=os.environ["API_SERVER"])\n    headers = {\n        \'content-type\': \'application/json\',\n        \'accept\': \'application/json\',\n        \'X-Tableau-Auth\': token\n    }\n    x = requests.post(uri, json={\'query\': query}, headers=headers)\n\n    # we print the plain text answer for debugging purposes\n    print(x.text)\n\n    # we return the plain text answer received\n    return x.text\n\n\n# This function is called by Tableau Prep to obtain the expected schema of the data to receive\ndef get_output_schema():\n    return pd.DataFrame({\n        \'ds_name\': prep_string(),\n        \'flow_name\': prep_string(),\n        \'owner_name\': prep_string(),\n        \'project_name\': prep_string()\n    })\n\n\n# This is the function we well name in a Tableau Prep script node\n# It received data on the input, but doesn\'t use it\n\ndef get_published_ds_used_in_flow(input):\n\n    # The hardcoded Graphql query\n    query = """query published_datasources_certified {\n    publishedDatasources {\n      name\n      isCertified\n      downstreamFlows {\n        name,\n        owner {\n          name\n        },\n        projectName\n      }\n    }\n  }\n  """\n\n    print("Logging into Tableau Server...")\n    token = login()\n    print("Session token is: " + token)\n    print("")\n    print("Running the following query:")\n    print(query)\n    print("")\n    print("Answer below:")\n\n    # here we get text\n    json_string = run_query(token, query)\n\n    # we parse the result as a json structure\n    response_as_json = json.loads(json_string)\n\n    # we print the json structure\n    print(json.dumps(response_as_json, sort_keys=True, indent=4))\n\n    # navigating the json structure to find the starting node we need\n    list_of_published_ds = response_as_json["data"]["publishedDatasources"]\n\n    # this array will contain the data we will return to Tableau Prep\n    resultset = []\n\n    # navigating the json structure and collecting data\n    for ds in list_of_published_ds:\n        for flow in ds["downstreamFlows"]:\n            # when we find a downstream flow, we create one entry into the resultset\n            resultset.append([ds["name"], flow["name"],\n                              flow["owner"]["name"], flow["projectName"]])\n\n    # print the resultset for debugging purposes\n    print(resultset)\n\n    # we turn this python array into a pandas dataframe\n    df = pd.DataFrame(data=resultset, columns=[\n                      "ds_name", "flow_name", "owner_name", "project_name"])\n\n    # we return the dataframe to Tableau Prep\n    return(df)\ndef get_output_schema_bea97b3a58e648258274adfc99cd41f5(df = pd.DataFrame()):\n    import inspect\n    if len(inspect.getfullargspec(get_output_schema).args) == 0:\n        return get_output_schema()\n    else:\n        return get_output_schema(df)\nresult_schema_output = get_output_schema_bea97b3a58e648258274adfc99cd41f5(pd.DataFrame(_arg1))\nreturn result_schema_output.to_dict(orient=\'split\') if isinstance(result_schema_output, pd.DataFrame) else result_schema_output'}'...
2021-01-28,13:47:53 [INFO] (base_handler.py:base_handler:115): function to evaluate=def _user_script(tabpy, _arg1):
 import pandas as pd
 def get_output_schema():
 	return '5e1663ee-aeb8-40e2-9e10-d7644bc9e928'
 def prep_string():
 	return ['prep_string_type']
 def prep_bool():
 	return ['prep_bool_type']
 def prep_int():
 	return ['prep_int_type']
 def prep_decimal():
     return ['prep_decimal_type']
 def prep_date():
 	return ['prep_date_type']
 def prep_datetime():
 	return ['prep_datetime_type']
 # os is used to retrieve environment variables
 # requests is used to make HTTP requests out to Tableau Server
 # json is used to parse the answer received from the Tableau metadata API
 # pandas is used to build a dataframe and return data to Tableau Prep
 
 import os
 import requests
 import json
 import pandas as pd
 
 
 # login will perform a login into Tableau Server and return a session token
 # it uses the API_SERVER, API_SECRET_TOKEN and API_TOKEN_NAME environment variables
 # see docker-compose.yml for these environment variables
 
 def login():
     body = {"credentials": {"personalAccessTokenName": os.environ['API_TOKEN_NAME'],
                             "personalAccessTokenSecret": os.environ['API_SECRET_TOKEN'],
                             "site": {"contentUrl": ""}}}
 
     print("Performing login")
 
     url = "https://{server}/api/3.9/auth/signin".format(
         server=os.environ["API_SERVER"])
 
     headers = {
         'accept': 'application/json',
         'content-type': 'application/json'
     }
 
     # making the request
     x = requests.post(url, json=body, headers=headers)
     # parsing the login response
     response = json.loads(x.text)
     # if everything goes well, session token is found here:
     token = response["credentials"]["token"]
 
     return token
 
 # run_query runs a GRAPHQL query against the Tableau metadata API
 # arguments are a session token (obtained with login function) and the query text
 # it uses the API_SERVER environment variable to connect to the server; see docker-compose.yml
 
 
 def run_query(token, query):
     uri = "https://{server}/api/metadata/graphql".format(
         server=os.environ["API_SERVER"])
     headers = {
         'content-type': 'application/json',
         'accept': 'application/json',
         'X-Tableau-Auth': token
     }
     x = requests.post(uri, json={'query': query}, headers=headers)
 
     # we print the plain text answer for debugging purposes
     print(x.text)
 
     # we return the plain text answer received
     return x.text
 
 
 # This function is called by Tableau Prep to obtain the expected schema of the data to receive
 def get_output_schema():
     return pd.DataFrame({
         'ds_name': prep_string(),
         'flow_name': prep_string(),
         'owner_name': prep_string(),
         'project_name': prep_string()
     })
 
 
 # This is the function we well name in a Tableau Prep script node
 # It received data on the input, but doesn't use it
 
 def get_published_ds_used_in_flow(input):
 
     # The hardcoded Graphql query
     query = """query published_datasources_certified {
     publishedDatasources {
       name
       isCertified
       downstreamFlows {
         name,
         owner {
           name
         },
         projectName
       }
     }
   }
   """
 
     print("Logging into Tableau Server...")
     token = login()
     print("Session token is: " + token)
     print("")
     print("Running the following query:")
     print(query)
     print("")
     print("Answer below:")
 
     # here we get text
     json_string = run_query(token, query)
 
     # we parse the result as a json structure
     response_as_json = json.loads(json_string)
 
     # we print the json structure
     print(json.dumps(response_as_json, sort_keys=True, indent=4))
 
     # navigating the json structure to find the starting node we need
     list_of_published_ds = response_as_json["data"]["publishedDatasources"]
 
     # this array will contain the data we will return to Tableau Prep
     resultset = []
 
     # navigating the json structure and collecting data
     for ds in list_of_published_ds:
         for flow in ds["downstreamFlows"]:
             # when we find a downstream flow, we create one entry into the resultset
             resultset.append([ds["name"], flow["name"],
                               flow["owner"]["name"], flow["projectName"]])
 
     # print the resultset for debugging purposes
     print(resultset)
 
     # we turn this python array into a pandas dataframe
     df = pd.DataFrame(data=resultset, columns=[
                       "ds_name", "flow_name", "owner_name", "project_name"])
 
     # we return the dataframe to Tableau Prep
     return(df)
 def get_output_schema_bea97b3a58e648258274adfc99cd41f5(df = pd.DataFrame()):
     import inspect
     if len(inspect.getfullargspec(get_output_schema).args) == 0:
         return get_output_schema()
     else:
         return get_output_schema(df)
 result_schema_output = get_output_schema_bea97b3a58e648258274adfc99cd41f5(pd.DataFrame(_arg1))
 return result_schema_output.to_dict(orient='split') if isinstance(result_schema_output, pd.DataFrame) else result_schema_output

2021-01-28,13:47:53 [DEBUG] (state.py:state:511): Collecting Access-Control-Allow-Origin from state file ...
2021-01-28,13:47:53 [DEBUG] (state.py:state:613): Loading option 'Access-Control-Allow-Origin' from section [Service Info]...
2021-01-28,13:47:53 [DEBUG] (state.py:state:635): Returning value ''
2021-01-28,13:47:53 [DEBUG] (state.py:state:613): Loading option 'Access-Control-Allow-Headers' from section [Service Info]...
2021-01-28,13:47:53 [DEBUG] (state.py:state:635): Returning value ''
2021-01-28,13:47:53 [DEBUG] (state.py:state:613): Loading option 'Access-Control-Allow-Methods' from section [Service Info]...
2021-01-28,13:47:53 [DEBUG] (state.py:state:635): Returning value ''
2021-01-28,13:47:53 [DEBUG] (base_handler.py:base_handler:115): Processing POST request '{'data': {'_arg1': {'ds_name': ['prep_string_type']}}, 'script': 'import pandas as pd\ndef get_output_schema():\n\treturn \'5e1663ee-aeb8-40e2-9e10-d7644bc9e928\'\ndef prep_string():\n\treturn [\'prep_string_type\']\ndef prep_bool():\n\treturn [\'prep_bool_type\']\ndef prep_int():\n\treturn [\'prep_int_type\']\ndef prep_decimal():\n    return [\'prep_decimal_type\']\ndef prep_date():\n\treturn [\'prep_date_type\']\ndef prep_datetime():\n\treturn [\'prep_datetime_type\']\n# os is used to retrieve environment variables\n# requests is used to make HTTP requests out to Tableau Server\n# json is used to parse the answer received from the Tableau metadata API\n# pandas is used to build a dataframe and return data to Tableau Prep\n\nimport os\nimport requests\nimport json\nimport pandas as pd\n\n\n# login will perform a login into Tableau Server and return a session token\n# it uses the API_SERVER, API_SECRET_TOKEN and API_TOKEN_NAME environment variables\n# see docker-compose.yml for these environment variables\n\ndef login():\n    body = {"credentials": {"personalAccessTokenName": os.environ[\'API_TOKEN_NAME\'],\n                            "personalAccessTokenSecret": os.environ[\'API_SECRET_TOKEN\'],\n                            "site": {"contentUrl": ""}}}\n\n    print("Performing login")\n\n    url = "https://{server}/api/3.9/auth/signin".format(\n        server=os.environ["API_SERVER"])\n\n    headers = {\n        \'accept\': \'application/json\',\n        \'content-type\': \'application/json\'\n    }\n\n    # making the request\n    x = requests.post(url, json=body, headers=headers)\n    # parsing the login response\n    response = json.loads(x.text)\n    # if everything goes well, session token is found here:\n    token = response["credentials"]["token"]\n\n    return token\n\n# run_query runs a GRAPHQL query against the Tableau metadata API\n# arguments are a session token (obtained with login function) and the query text\n# it uses the API_SERVER environment variable to connect to the server; see docker-compose.yml\n\n\ndef run_query(token, query):\n    uri = "https://{server}/api/metadata/graphql".format(\n        server=os.environ["API_SERVER"])\n    headers = {\n        \'content-type\': \'application/json\',\n        \'accept\': \'application/json\',\n        \'X-Tableau-Auth\': token\n    }\n    x = requests.post(uri, json={\'query\': query}, headers=headers)\n\n    # we print the plain text answer for debugging purposes\n    print(x.text)\n\n    # we return the plain text answer received\n    return x.text\n\n\n# This function is called by Tableau Prep to obtain the expected schema of the data to receive\ndef get_output_schema():\n    return pd.DataFrame({\n        \'ds_name\': prep_string(),\n        \'flow_name\': prep_string(),\n        \'owner_name\': prep_string(),\n        \'project_name\': prep_string()\n    })\n\n\n# This is the function we well name in a Tableau Prep script node\n# It received data on the input, but doesn\'t use it\n\ndef get_published_ds_used_in_flow(input):\n\n    # The hardcoded Graphql query\n    query = """query published_datasources_certified {\n    publishedDatasources {\n      name\n      isCertified\n      downstreamFlows {\n        name,\n        owner {\n          name\n        },\n        projectName\n      }\n    }\n  }\n  """\n\n    print("Logging into Tableau Server...")\n    token = login()\n    print("Session token is: " + token)\n    print("")\n    print("Running the following query:")\n    print(query)\n    print("")\n    print("Answer below:")\n\n    # here we get text\n    json_string = run_query(token, query)\n\n    # we parse the result as a json structure\n    response_as_json = json.loads(json_string)\n\n    # we print the json structure\n    print(json.dumps(response_as_json, sort_keys=True, indent=4))\n\n    # navigating the json structure to find the starting node we need\n    list_of_published_ds = response_as_json["data"]["publishedDatasources"]\n\n    # this array will contain the data we will return to Tableau Prep\n    resultset = []\n\n    # navigating the json structure and collecting data\n    for ds in list_of_published_ds:\n        for flow in ds["downstreamFlows"]:\n            # when we find a downstream flow, we create one entry into the resultset\n            resultset.append([ds["name"], flow["name"],\n                              flow["owner"]["name"], flow["projectName"]])\n\n    # print the resultset for debugging purposes\n    print(resultset)\n\n    # we turn this python array into a pandas dataframe\n    df = pd.DataFrame(data=resultset, columns=[\n                      "ds_name", "flow_name", "owner_name", "project_name"])\n\n    # we return the dataframe to Tableau Prep\n    return(df)\ndef get_output_schema_bea97b3a58e648258274adfc99cd41f5(df = pd.DataFrame()):\n    import inspect\n    if len(inspect.getfullargspec(get_output_schema).args) == 0:\n        return get_output_schema()\n    else:\n        return get_output_schema(df)\nresult_schema_output = get_output_schema_bea97b3a58e648258274adfc99cd41f5(pd.DataFrame(_arg1))\nreturn result_schema_output.to_dict(orient=\'split\') if isinstance(result_schema_output, pd.DataFrame) else result_schema_output'}'...
2021-01-28,13:47:53 [INFO] (base_handler.py:base_handler:115): function to evaluate=def _user_script(tabpy, _arg1):
 import pandas as pd
 def get_output_schema():
 	return '5e1663ee-aeb8-40e2-9e10-d7644bc9e928'
 def prep_string():
 	return ['prep_string_type']
 def prep_bool():
 	return ['prep_bool_type']
 def prep_int():
 	return ['prep_int_type']
 def prep_decimal():
     return ['prep_decimal_type']
 def prep_date():
 	return ['prep_date_type']
 def prep_datetime():
 	return ['prep_datetime_type']
 # os is used to retrieve environment variables
 # requests is used to make HTTP requests out to Tableau Server
 # json is used to parse the answer received from the Tableau metadata API
 # pandas is used to build a dataframe and return data to Tableau Prep
 
 import os
 import requests
 import json
 import pandas as pd
 
 
 # login will perform a login into Tableau Server and return a session token
 # it uses the API_SERVER, API_SECRET_TOKEN and API_TOKEN_NAME environment variables
 # see docker-compose.yml for these environment variables
 
 def login():
     body = {"credentials": {"personalAccessTokenName": os.environ['API_TOKEN_NAME'],
                             "personalAccessTokenSecret": os.environ['API_SECRET_TOKEN'],
                             "site": {"contentUrl": ""}}}
 
     print("Performing login")
 
     url = "https://{server}/api/3.9/auth/signin".format(
         server=os.environ["API_SERVER"])
 
     headers = {
         'accept': 'application/json',
         'content-type': 'application/json'
     }
 
     # making the request
     x = requests.post(url, json=body, headers=headers)
     # parsing the login response
     response = json.loads(x.text)
     # if everything goes well, session token is found here:
     token = response["credentials"]["token"]
 
     return token
 
 # run_query runs a GRAPHQL query against the Tableau metadata API
 # arguments are a session token (obtained with login function) and the query text
 # it uses the API_SERVER environment variable to connect to the server; see docker-compose.yml
 
 
 def run_query(token, query):
     uri = "https://{server}/api/metadata/graphql".format(
         server=os.environ["API_SERVER"])
     headers = {
         'content-type': 'application/json',
         'accept': 'application/json',
         'X-Tableau-Auth': token
     }
     x = requests.post(uri, json={'query': query}, headers=headers)
 
     # we print the plain text answer for debugging purposes
     print(x.text)
 
     # we return the plain text answer received
     return x.text
 
 
 # This function is called by Tableau Prep to obtain the expected schema of the data to receive
 def get_output_schema():
     return pd.DataFrame({
         'ds_name': prep_string(),
         'flow_name': prep_string(),
         'owner_name': prep_string(),
         'project_name': prep_string()
     })
 
 
 # This is the function we well name in a Tableau Prep script node
 # It received data on the input, but doesn't use it
 
 def get_published_ds_used_in_flow(input):
 
     # The hardcoded Graphql query
     query = """query published_datasources_certified {
     publishedDatasources {
       name
       isCertified
       downstreamFlows {
         name,
         owner {
           name
         },
         projectName
       }
     }
   }
   """
 
     print("Logging into Tableau Server...")
     token = login()
     print("Session token is: " + token)
     print("")
     print("Running the following query:")
     print(query)
     print("")
     print("Answer below:")
 
     # here we get text
     json_string = run_query(token, query)
 
     # we parse the result as a json structure
     response_as_json = json.loads(json_string)
 
     # we print the json structure
     print(json.dumps(response_as_json, sort_keys=True, indent=4))
 
     # navigating the json structure to find the starting node we need
     list_of_published_ds = response_as_json["data"]["publishedDatasources"]
 
     # this array will contain the data we will return to Tableau Prep
     resultset = []
 
     # navigating the json structure and collecting data
     for ds in list_of_published_ds:
         for flow in ds["downstreamFlows"]:
             # when we find a downstream flow, we create one entry into the resultset
             resultset.append([ds["name"], flow["name"],
                               flow["owner"]["name"], flow["projectName"]])
 
     # print the resultset for debugging purposes
     print(resultset)
 
     # we turn this python array into a pandas dataframe
     df = pd.DataFrame(data=resultset, columns=[
                       "ds_name", "flow_name", "owner_name", "project_name"])
 
     # we return the dataframe to Tableau Prep
     return(df)
 def get_output_schema_bea97b3a58e648258274adfc99cd41f5(df = pd.DataFrame()):
     import inspect
     if len(inspect.getfullargspec(get_output_schema).args) == 0:
         return get_output_schema()
     else:
         return get_output_schema(df)
 result_schema_output = get_output_schema_bea97b3a58e648258274adfc99cd41f5(pd.DataFrame(_arg1))
 return result_schema_output.to_dict(orient='split') if isinstance(result_schema_output, pd.DataFrame) else result_schema_output

2021-01-28,13:47:53 [INFO] (web.py:web:2239): 200 POST /evaluate (172.18.0.1) 79.22ms
2021-01-28,13:47:53 [INFO] (web.py:web:2239): 200 POST /evaluate (172.18.0.1) 59.31ms
2021-01-28,13:47:53 [DEBUG] (base_handler.py:base_handler:115): Checking if need to handle authentication
2021-01-28,13:47:53 [DEBUG] (base_handler.py:base_handler:115): Handling authentication
2021-01-28,13:47:53 [INFO] (base_handler.py:base_handler:115): Authentication is not a required feature for API "v1"
2021-01-28,13:47:53 [DEBUG] (base_handler.py:base_handler:115): Checking request headers for authentication data
2021-01-28,13:47:53 [INFO] (base_handler.py:base_handler:115): Authorization header not found
2021-01-28,13:47:53 [DEBUG] (base_handler.py:base_handler:115): authentication not required, username and password are none
2021-01-28,13:47:53 [INFO] (web.py:web:2239): 200 POST /evaluate (172.18.0.1) 69.53ms
2021-01-28,13:47:53 [DEBUG] (state.py:state:511): Collecting Access-Control-Allow-Origin from state file ...
2021-01-28,13:47:53 [DEBUG] (state.py:state:613): Loading option 'Access-Control-Allow-Origin' from section [Service Info]...
2021-01-28,13:47:53 [DEBUG] (state.py:state:635): Returning value ''
2021-01-28,13:47:53 [DEBUG] (state.py:state:613): Loading option 'Access-Control-Allow-Headers' from section [Service Info]...
2021-01-28,13:47:53 [DEBUG] (state.py:state:635): Returning value ''
2021-01-28,13:47:53 [DEBUG] (state.py:state:613): Loading option 'Access-Control-Allow-Methods' from section [Service Info]...
2021-01-28,13:47:53 [DEBUG] (state.py:state:635): Returning value ''
2021-01-28,13:47:53 [DEBUG] (base_handler.py:base_handler:115): Processing POST request '{'data': {'_arg1': {'ds_name': ['prep_string_type']}}, 'script': 'import pandas as pd\ndef get_output_schema():\n\treturn \'5e1663ee-aeb8-40e2-9e10-d7644bc9e928\'\ndef prep_string():\n\treturn [\'prep_string_type\']\ndef prep_bool():\n\treturn [\'prep_bool_type\']\ndef prep_int():\n\treturn [\'prep_int_type\']\ndef prep_decimal():\n    return [\'prep_decimal_type\']\ndef prep_date():\n\treturn [\'prep_date_type\']\ndef prep_datetime():\n\treturn [\'prep_datetime_type\']\n# os is used to retrieve environment variables\n# requests is used to make HTTP requests out to Tableau Server\n# json is used to parse the answer received from the Tableau metadata API\n# pandas is used to build a dataframe and return data to Tableau Prep\n\nimport os\nimport requests\nimport json\nimport pandas as pd\n\n\n# login will perform a login into Tableau Server and return a session token\n# it uses the API_SERVER, API_SECRET_TOKEN and API_TOKEN_NAME environment variables\n# see docker-compose.yml for these environment variables\n\ndef login():\n    body = {"credentials": {"personalAccessTokenName": os.environ[\'API_TOKEN_NAME\'],\n                            "personalAccessTokenSecret": os.environ[\'API_SECRET_TOKEN\'],\n                            "site": {"contentUrl": ""}}}\n\n    print("Performing login")\n\n    url = "https://{server}/api/3.9/auth/signin".format(\n        server=os.environ["API_SERVER"])\n\n    headers = {\n        \'accept\': \'application/json\',\n        \'content-type\': \'application/json\'\n    }\n\n    # making the request\n    x = requests.post(url, json=body, headers=headers)\n    # parsing the login response\n    response = json.loads(x.text)\n    # if everything goes well, session token is found here:\n    token = response["credentials"]["token"]\n\n    return token\n\n# run_query runs a GRAPHQL query against the Tableau metadata API\n# arguments are a session token (obtained with login function) and the query text\n# it uses the API_SERVER environment variable to connect to the server; see docker-compose.yml\n\n\ndef run_query(token, query):\n    uri = "https://{server}/api/metadata/graphql".format(\n        server=os.environ["API_SERVER"])\n    headers = {\n        \'content-type\': \'application/json\',\n        \'accept\': \'application/json\',\n        \'X-Tableau-Auth\': token\n    }\n    x = requests.post(uri, json={\'query\': query}, headers=headers)\n\n    # we print the plain text answer for debugging purposes\n    print(x.text)\n\n    # we return the plain text answer received\n    return x.text\n\n\n# This function is called by Tableau Prep to obtain the expected schema of the data to receive\ndef get_output_schema():\n    return pd.DataFrame({\n        \'ds_name\': prep_string(),\n        \'flow_name\': prep_string(),\n        \'owner_name\': prep_string(),\n        \'project_name\': prep_string()\n    })\n\n\n# This is the function we well name in a Tableau Prep script node\n# It received data on the input, but doesn\'t use it\n\ndef get_published_ds_used_in_flow(input):\n\n    # The hardcoded Graphql query\n    query = """query published_datasources_certified {\n    publishedDatasources {\n      name\n      isCertified\n      downstreamFlows {\n        name,\n        owner {\n          name\n        },\n        projectName\n      }\n    }\n  }\n  """\n\n    print("Logging into Tableau Server...")\n    token = login()\n    print("Session token is: " + token)\n    print("")\n    print("Running the following query:")\n    print(query)\n    print("")\n    print("Answer below:")\n\n    # here we get text\n    json_string = run_query(token, query)\n\n    # we parse the result as a json structure\n    response_as_json = json.loads(json_string)\n\n    # we print the json structure\n    print(json.dumps(response_as_json, sort_keys=True, indent=4))\n\n    # navigating the json structure to find the starting node we need\n    list_of_published_ds = response_as_json["data"]["publishedDatasources"]\n\n    # this array will contain the data we will return to Tableau Prep\n    resultset = []\n\n    # navigating the json structure and collecting data\n    for ds in list_of_published_ds:\n        for flow in ds["downstreamFlows"]:\n            # when we find a downstream flow, we create one entry into the resultset\n            resultset.append([ds["name"], flow["name"],\n                              flow["owner"]["name"], flow["projectName"]])\n\n    # print the resultset for debugging purposes\n    print(resultset)\n\n    # we turn this python array into a pandas dataframe\n    df = pd.DataFrame(data=resultset, columns=[\n                      "ds_name", "flow_name", "owner_name", "project_name"])\n\n    # we return the dataframe to Tableau Prep\n    return(df)\ndef get_output_schema_bea97b3a58e648258274adfc99cd41f5(df = pd.DataFrame()):\n    import inspect\n    if len(inspect.getfullargspec(get_output_schema).args) == 0:\n        return get_output_schema()\n    else:\n        return get_output_schema(df)\nresult_schema_output = get_output_schema_bea97b3a58e648258274adfc99cd41f5(pd.DataFrame(_arg1))\nreturn result_schema_output.to_dict(orient=\'split\') if isinstance(result_schema_output, pd.DataFrame) else result_schema_output'}'...
2021-01-28,13:47:53 [INFO] (base_handler.py:base_handler:115): function to evaluate=def _user_script(tabpy, _arg1):
 import pandas as pd
 def get_output_schema():
 	return '5e1663ee-aeb8-40e2-9e10-d7644bc9e928'
 def prep_string():
 	return ['prep_string_type']
 def prep_bool():
 	return ['prep_bool_type']
 def prep_int():
 	return ['prep_int_type']
 def prep_decimal():
     return ['prep_decimal_type']
 def prep_date():
 	return ['prep_date_type']
 def prep_datetime():
 	return ['prep_datetime_type']
 # os is used to retrieve environment variables
 # requests is used to make HTTP requests out to Tableau Server
 # json is used to parse the answer received from the Tableau metadata API
 # pandas is used to build a dataframe and return data to Tableau Prep
 
 import os
 import requests
 import json
 import pandas as pd
 
 
 # login will perform a login into Tableau Server and return a session token
 # it uses the API_SERVER, API_SECRET_TOKEN and API_TOKEN_NAME environment variables
 # see docker-compose.yml for these environment variables
 
 def login():
     body = {"credentials": {"personalAccessTokenName": os.environ['API_TOKEN_NAME'],
                             "personalAccessTokenSecret": os.environ['API_SECRET_TOKEN'],
                             "site": {"contentUrl": ""}}}
 
     print("Performing login")
 
     url = "https://{server}/api/3.9/auth/signin".format(
         server=os.environ["API_SERVER"])
 
     headers = {
         'accept': 'application/json',
         'content-type': 'application/json'
     }
 
     # making the request
     x = requests.post(url, json=body, headers=headers)
     # parsing the login response
     response = json.loads(x.text)
     # if everything goes well, session token is found here:
     token = response["credentials"]["token"]
 
     return token
 
 # run_query runs a GRAPHQL query against the Tableau metadata API
 # arguments are a session token (obtained with login function) and the query text
 # it uses the API_SERVER environment variable to connect to the server; see docker-compose.yml
 
 
 def run_query(token, query):
     uri = "https://{server}/api/metadata/graphql".format(
         server=os.environ["API_SERVER"])
     headers = {
         'content-type': 'application/json',
         'accept': 'application/json',
         'X-Tableau-Auth': token
     }
     x = requests.post(uri, json={'query': query}, headers=headers)
 
     # we print the plain text answer for debugging purposes
     print(x.text)
 
     # we return the plain text answer received
     return x.text
 
 
 # This function is called by Tableau Prep to obtain the expected schema of the data to receive
 def get_output_schema():
     return pd.DataFrame({
         'ds_name': prep_string(),
         'flow_name': prep_string(),
         'owner_name': prep_string(),
         'project_name': prep_string()
     })
 
 
 # This is the function we well name in a Tableau Prep script node
 # It received data on the input, but doesn't use it
 
 def get_published_ds_used_in_flow(input):
 
     # The hardcoded Graphql query
     query = """query published_datasources_certified {
     publishedDatasources {
       name
       isCertified
       downstreamFlows {
         name,
         owner {
           name
         },
         projectName
       }
     }
   }
   """
 
     print("Logging into Tableau Server...")
     token = login()
     print("Session token is: " + token)
     print("")
     print("Running the following query:")
     print(query)
     print("")
     print("Answer below:")
 
     # here we get text
     json_string = run_query(token, query)
 
     # we parse the result as a json structure
     response_as_json = json.loads(json_string)
 
     # we print the json structure
     print(json.dumps(response_as_json, sort_keys=True, indent=4))
 
     # navigating the json structure to find the starting node we need
     list_of_published_ds = response_as_json["data"]["publishedDatasources"]
 
     # this array will contain the data we will return to Tableau Prep
     resultset = []
 
     # navigating the json structure and collecting data
     for ds in list_of_published_ds:
         for flow in ds["downstreamFlows"]:
             # when we find a downstream flow, we create one entry into the resultset
             resultset.append([ds["name"], flow["name"],
                               flow["owner"]["name"], flow["projectName"]])
 
     # print the resultset for debugging purposes
     print(resultset)
 
     # we turn this python array into a pandas dataframe
     df = pd.DataFrame(data=resultset, columns=[
                       "ds_name", "flow_name", "owner_name", "project_name"])
 
     # we return the dataframe to Tableau Prep
     return(df)
 def get_output_schema_bea97b3a58e648258274adfc99cd41f5(df = pd.DataFrame()):
     import inspect
     if len(inspect.getfullargspec(get_output_schema).args) == 0:
         return get_output_schema()
     else:
         return get_output_schema(df)
 result_schema_output = get_output_schema_bea97b3a58e648258274adfc99cd41f5(pd.DataFrame(_arg1))
 return result_schema_output.to_dict(orient='split') if isinstance(result_schema_output, pd.DataFrame) else result_schema_output

2021-01-28,13:47:53 [DEBUG] (base_handler.py:base_handler:115): Checking if need to handle authentication
2021-01-28,13:47:53 [DEBUG] (base_handler.py:base_handler:115): Handling authentication
2021-01-28,13:47:53 [INFO] (base_handler.py:base_handler:115): Authentication is not a required feature for API "v1"
2021-01-28,13:47:53 [DEBUG] (base_handler.py:base_handler:115): Checking request headers for authentication data
2021-01-28,13:47:53 [INFO] (base_handler.py:base_handler:115): Authorization header not found
2021-01-28,13:47:53 [DEBUG] (base_handler.py:base_handler:115): authentication not required, username and password are none
2021-01-28,13:47:53 [DEBUG] (base_handler.py:base_handler:115): Checking if need to handle authentication
2021-01-28,13:47:53 [DEBUG] (base_handler.py:base_handler:115): Handling authentication
2021-01-28,13:47:53 [INFO] (base_handler.py:base_handler:115): Authentication is not a required feature for API "v1"
2021-01-28,13:47:53 [DEBUG] (base_handler.py:base_handler:115): Checking request headers for authentication data
2021-01-28,13:47:53 [INFO] (base_handler.py:base_handler:115): Authorization header not found
2021-01-28,13:47:53 [DEBUG] (base_handler.py:base_handler:115): authentication not required, username and password are none
2021-01-28,13:47:53 [DEBUG] (base_handler.py:base_handler:115): Checking if need to handle authentication
2021-01-28,13:47:53 [DEBUG] (base_handler.py:base_handler:115): Handling authentication
2021-01-28,13:47:53 [INFO] (base_handler.py:base_handler:115): Authentication is not a required feature for API "v1"
2021-01-28,13:47:53 [DEBUG] (base_handler.py:base_handler:115): Checking request headers for authentication data
2021-01-28,13:47:53 [INFO] (base_handler.py:base_handler:115): Authorization header not found
2021-01-28,13:47:53 [DEBUG] (base_handler.py:base_handler:115): authentication not required, username and password are none
2021-01-28,13:47:53 [DEBUG] (base_handler.py:base_handler:115): Checking if need to handle authentication
2021-01-28,13:47:53 [DEBUG] (base_handler.py:base_handler:115): Handling authentication
2021-01-28,13:47:53 [INFO] (base_handler.py:base_handler:115): Authentication is not a required feature for API "v1"
2021-01-28,13:47:53 [DEBUG] (base_handler.py:base_handler:115): Checking request headers for authentication data
2021-01-28,13:47:53 [INFO] (base_handler.py:base_handler:115): Authorization header not found
2021-01-28,13:47:53 [DEBUG] (base_handler.py:base_handler:115): authentication not required, username and password are none
2021-01-28,13:47:53 [DEBUG] (state.py:state:511): Collecting Access-Control-Allow-Origin from state file ...
2021-01-28,13:47:53 [DEBUG] (state.py:state:613): Loading option 'Access-Control-Allow-Origin' from section [Service Info]...
2021-01-28,13:47:53 [DEBUG] (state.py:state:635): Returning value ''
2021-01-28,13:47:53 [DEBUG] (state.py:state:613): Loading option 'Access-Control-Allow-Headers' from section [Service Info]...
2021-01-28,13:47:53 [DEBUG] (state.py:state:635): Returning value ''
2021-01-28,13:47:53 [DEBUG] (state.py:state:613): Loading option 'Access-Control-Allow-Methods' from section [Service Info]...
2021-01-28,13:47:53 [DEBUG] (state.py:state:635): Returning value ''
2021-01-28,13:47:53 [DEBUG] (base_handler.py:base_handler:115): Processing POST request '{'data': {'_arg1': {'ds_name': ['prep_string_type']}}, 'script': 'import pandas as pd\ndef get_output_schema():\n\treturn \'5e1663ee-aeb8-40e2-9e10-d7644bc9e928\'\ndef prep_string():\n\treturn [\'prep_string_type\']\ndef prep_bool():\n\treturn [\'prep_bool_type\']\ndef prep_int():\n\treturn [\'prep_int_type\']\ndef prep_decimal():\n    return [\'prep_decimal_type\']\ndef prep_date():\n\treturn [\'prep_date_type\']\ndef prep_datetime():\n\treturn [\'prep_datetime_type\']\n# os is used to retrieve environment variables\n# requests is used to make HTTP requests out to Tableau Server\n# json is used to parse the answer received from the Tableau metadata API\n# pandas is used to build a dataframe and return data to Tableau Prep\n\nimport os\nimport requests\nimport json\nimport pandas as pd\n\n\n# login will perform a login into Tableau Server and return a session token\n# it uses the API_SERVER, API_SECRET_TOKEN and API_TOKEN_NAME environment variables\n# see docker-compose.yml for these environment variables\n\ndef login():\n    body = {"credentials": {"personalAccessTokenName": os.environ[\'API_TOKEN_NAME\'],\n                            "personalAccessTokenSecret": os.environ[\'API_SECRET_TOKEN\'],\n                            "site": {"contentUrl": ""}}}\n\n    print("Performing login")\n\n    url = "https://{server}/api/3.9/auth/signin".format(\n        server=os.environ["API_SERVER"])\n\n    headers = {\n        \'accept\': \'application/json\',\n        \'content-type\': \'application/json\'\n    }\n\n    # making the request\n    x = requests.post(url, json=body, headers=headers)\n    # parsing the login response\n    response = json.loads(x.text)\n    # if everything goes well, session token is found here:\n    token = response["credentials"]["token"]\n\n    return token\n\n# run_query runs a GRAPHQL query against the Tableau metadata API\n# arguments are a session token (obtained with login function) and the query text\n# it uses the API_SERVER environment variable to connect to the server; see docker-compose.yml\n\n\ndef run_query(token, query):\n    uri = "https://{server}/api/metadata/graphql".format(\n        server=os.environ["API_SERVER"])\n    headers = {\n        \'content-type\': \'application/json\',\n        \'accept\': \'application/json\',\n        \'X-Tableau-Auth\': token\n    }\n    x = requests.post(uri, json={\'query\': query}, headers=headers)\n\n    # we print the plain text answer for debugging purposes\n    print(x.text)\n\n    # we return the plain text answer received\n    return x.text\n\n\n# This function is called by Tableau Prep to obtain the expected schema of the data to receive\ndef get_output_schema():\n    return pd.DataFrame({\n        \'ds_name\': prep_string(),\n        \'flow_name\': prep_string(),\n        \'owner_name\': prep_string(),\n        \'project_name\': prep_string()\n    })\n\n\n# This is the function we well name in a Tableau Prep script node\n# It received data on the input, but doesn\'t use it\n\ndef get_published_ds_used_in_flow(input):\n\n    # The hardcoded Graphql query\n    query = """query published_datasources_certified {\n    publishedDatasources {\n      name\n      isCertified\n      downstreamFlows {\n        name,\n        owner {\n          name\n        },\n        projectName\n      }\n    }\n  }\n  """\n\n    print("Logging into Tableau Server...")\n    token = login()\n    print("Session token is: " + token)\n    print("")\n    print("Running the following query:")\n    print(query)\n    print("")\n    print("Answer below:")\n\n    # here we get text\n    json_string = run_query(token, query)\n\n    # we parse the result as a json structure\n    response_as_json = json.loads(json_string)\n\n    # we print the json structure\n    print(json.dumps(response_as_json, sort_keys=True, indent=4))\n\n    # navigating the json structure to find the starting node we need\n    list_of_published_ds = response_as_json["data"]["publishedDatasources"]\n\n    # this array will contain the data we will return to Tableau Prep\n    resultset = []\n\n    # navigating the json structure and collecting data\n    for ds in list_of_published_ds:\n        for flow in ds["downstreamFlows"]:\n            # when we find a downstream flow, we create one entry into the resultset\n            resultset.append([ds["name"], flow["name"],\n                              flow["owner"]["name"], flow["projectName"]])\n\n    # print the resultset for debugging purposes\n    print(resultset)\n\n    # we turn this python array into a pandas dataframe\n    df = pd.DataFrame(data=resultset, columns=[\n                      "ds_name", "flow_name", "owner_name", "project_name"])\n\n    # we return the dataframe to Tableau Prep\n    return(df)\ndef get_output_schema_bea97b3a58e648258274adfc99cd41f5(df = pd.DataFrame()):\n    import inspect\n    if len(inspect.getfullargspec(get_output_schema).args) == 0:\n        return get_output_schema()\n    else:\n        return get_output_schema(df)\nresult_schema_output = get_output_schema_bea97b3a58e648258274adfc99cd41f5(pd.DataFrame(_arg1))\nreturn result_schema_output.to_dict(orient=\'split\') if isinstance(result_schema_output, pd.DataFrame) else result_schema_output'}'...
2021-01-28,13:47:53 [INFO] (base_handler.py:base_handler:115): function to evaluate=def _user_script(tabpy, _arg1):
 import pandas as pd
 def get_output_schema():
 	return '5e1663ee-aeb8-40e2-9e10-d7644bc9e928'
 def prep_string():
 	return ['prep_string_type']
 def prep_bool():
 	return ['prep_bool_type']
 def prep_int():
 	return ['prep_int_type']
 def prep_decimal():
     return ['prep_decimal_type']
 def prep_date():
 	return ['prep_date_type']
 def prep_datetime():
 	return ['prep_datetime_type']
 # os is used to retrieve environment variables
 # requests is used to make HTTP requests out to Tableau Server
 # json is used to parse the answer received from the Tableau metadata API
 # pandas is used to build a dataframe and return data to Tableau Prep
 
 import os
 import requests
 import json
 import pandas as pd
 
 
 # login will perform a login into Tableau Server and return a session token
 # it uses the API_SERVER, API_SECRET_TOKEN and API_TOKEN_NAME environment variables
 # see docker-compose.yml for these environment variables
 
 def login():
     body = {"credentials": {"personalAccessTokenName": os.environ['API_TOKEN_NAME'],
                             "personalAccessTokenSecret": os.environ['API_SECRET_TOKEN'],
                             "site": {"contentUrl": ""}}}
 
     print("Performing login")
 
     url = "https://{server}/api/3.9/auth/signin".format(
         server=os.environ["API_SERVER"])
 
     headers = {
         'accept': 'application/json',
         'content-type': 'application/json'
     }
 
     # making the request
     x = requests.post(url, json=body, headers=headers)
     # parsing the login response
     response = json.loads(x.text)
     # if everything goes well, session token is found here:
     token = response["credentials"]["token"]
 
     return token
 
 # run_query runs a GRAPHQL query against the Tableau metadata API
 # arguments are a session token (obtained with login function) and the query text
 # it uses the API_SERVER environment variable to connect to the server; see docker-compose.yml
 
 
 def run_query(token, query):
     uri = "https://{server}/api/metadata/graphql".format(
         server=os.environ["API_SERVER"])
     headers = {
         'content-type': 'application/json',
         'accept': 'application/json',
         'X-Tableau-Auth': token
     }
     x = requests.post(uri, json={'query': query}, headers=headers)
 
     # we print the plain text answer for debugging purposes
     print(x.text)
 
     # we return the plain text answer received
     return x.text
 
 
 # This function is called by Tableau Prep to obtain the expected schema of the data to receive
 def get_output_schema():
     return pd.DataFrame({
         'ds_name': prep_string(),
         'flow_name': prep_string(),
         'owner_name': prep_string(),
         'project_name': prep_string()
     })
 
 
 # This is the function we well name in a Tableau Prep script node
 # It received data on the input, but doesn't use it
 
 def get_published_ds_used_in_flow(input):
 
     # The hardcoded Graphql query
     query = """query published_datasources_certified {
     publishedDatasources {
       name
       isCertified
       downstreamFlows {
         name,
         owner {
           name
         },
         projectName
       }
     }
   }
   """
 
     print("Logging into Tableau Server...")
     token = login()
     print("Session token is: " + token)
     print("")
     print("Running the following query:")
     print(query)
     print("")
     print("Answer below:")
 
     # here we get text
     json_string = run_query(token, query)
 
     # we parse the result as a json structure
     response_as_json = json.loads(json_string)
 
     # we print the json structure
     print(json.dumps(response_as_json, sort_keys=True, indent=4))
 
     # navigating the json structure to find the starting node we need
     list_of_published_ds = response_as_json["data"]["publishedDatasources"]
 
     # this array will contain the data we will return to Tableau Prep
     resultset = []
 
     # navigating the json structure and collecting data
     for ds in list_of_published_ds:
         for flow in ds["downstreamFlows"]:
             # when we find a downstream flow, we create one entry into the resultset
             resultset.append([ds["name"], flow["name"],
                               flow["owner"]["name"], flow["projectName"]])
 
     # print the resultset for debugging purposes
     print(resultset)
 
     # we turn this python array into a pandas dataframe
     df = pd.DataFrame(data=resultset, columns=[
                       "ds_name", "flow_name", "owner_name", "project_name"])
 
     # we return the dataframe to Tableau Prep
     return(df)
 def get_output_schema_bea97b3a58e648258274adfc99cd41f5(df = pd.DataFrame()):
     import inspect
     if len(inspect.getfullargspec(get_output_schema).args) == 0:
         return get_output_schema()
     else:
         return get_output_schema(df)
 result_schema_output = get_output_schema_bea97b3a58e648258274adfc99cd41f5(pd.DataFrame(_arg1))
 return result_schema_output.to_dict(orient='split') if isinstance(result_schema_output, pd.DataFrame) else result_schema_output

2021-01-28,13:47:53 [DEBUG] (state.py:state:511): Collecting Access-Control-Allow-Origin from state file ...
2021-01-28,13:47:53 [DEBUG] (state.py:state:613): Loading option 'Access-Control-Allow-Origin' from section [Service Info]...
2021-01-28,13:47:53 [DEBUG] (state.py:state:635): Returning value ''
2021-01-28,13:47:53 [DEBUG] (state.py:state:613): Loading option 'Access-Control-Allow-Headers' from section [Service Info]...
2021-01-28,13:47:53 [DEBUG] (state.py:state:635): Returning value ''
2021-01-28,13:47:53 [DEBUG] (state.py:state:613): Loading option 'Access-Control-Allow-Methods' from section [Service Info]...
2021-01-28,13:47:53 [DEBUG] (state.py:state:635): Returning value ''
2021-01-28,13:47:53 [DEBUG] (base_handler.py:base_handler:115): Processing POST request '{'data': {'_arg1': {'ds_name': ['prep_string_type']}}, 'script': 'import pandas as pd\ndef get_output_schema():\n\treturn \'5e1663ee-aeb8-40e2-9e10-d7644bc9e928\'\ndef prep_string():\n\treturn [\'prep_string_type\']\ndef prep_bool():\n\treturn [\'prep_bool_type\']\ndef prep_int():\n\treturn [\'prep_int_type\']\ndef prep_decimal():\n    return [\'prep_decimal_type\']\ndef prep_date():\n\treturn [\'prep_date_type\']\ndef prep_datetime():\n\treturn [\'prep_datetime_type\']\n# os is used to retrieve environment variables\n# requests is used to make HTTP requests out to Tableau Server\n# json is used to parse the answer received from the Tableau metadata API\n# pandas is used to build a dataframe and return data to Tableau Prep\n\nimport os\nimport requests\nimport json\nimport pandas as pd\n\n\n# login will perform a login into Tableau Server and return a session token\n# it uses the API_SERVER, API_SECRET_TOKEN and API_TOKEN_NAME environment variables\n# see docker-compose.yml for these environment variables\n\ndef login():\n    body = {"credentials": {"personalAccessTokenName": os.environ[\'API_TOKEN_NAME\'],\n                            "personalAccessTokenSecret": os.environ[\'API_SECRET_TOKEN\'],\n                            "site": {"contentUrl": ""}}}\n\n    print("Performing login")\n\n    url = "https://{server}/api/3.9/auth/signin".format(\n        server=os.environ["API_SERVER"])\n\n    headers = {\n        \'accept\': \'application/json\',\n        \'content-type\': \'application/json\'\n    }\n\n    # making the request\n    x = requests.post(url, json=body, headers=headers)\n    # parsing the login response\n    response = json.loads(x.text)\n    # if everything goes well, session token is found here:\n    token = response["credentials"]["token"]\n\n    return token\n\n# run_query runs a GRAPHQL query against the Tableau metadata API\n# arguments are a session token (obtained with login function) and the query text\n# it uses the API_SERVER environment variable to connect to the server; see docker-compose.yml\n\n\ndef run_query(token, query):\n    uri = "https://{server}/api/metadata/graphql".format(\n        server=os.environ["API_SERVER"])\n    headers = {\n        \'content-type\': \'application/json\',\n        \'accept\': \'application/json\',\n        \'X-Tableau-Auth\': token\n    }\n    x = requests.post(uri, json={\'query\': query}, headers=headers)\n\n    # we print the plain text answer for debugging purposes\n    print(x.text)\n\n    # we return the plain text answer received\n    return x.text\n\n\n# This function is called by Tableau Prep to obtain the expected schema of the data to receive\ndef get_output_schema():\n    return pd.DataFrame({\n        \'ds_name\': prep_string(),\n        \'flow_name\': prep_string(),\n        \'owner_name\': prep_string(),\n        \'project_name\': prep_string()\n    })\n\n\n# This is the function we well name in a Tableau Prep script node\n# It received data on the input, but doesn\'t use it\n\ndef get_published_ds_used_in_flow(input):\n\n    # The hardcoded Graphql query\n    query = """query published_datasources_certified {\n    publishedDatasources {\n      name\n      isCertified\n      downstreamFlows {\n        name,\n        owner {\n          name\n        },\n        projectName\n      }\n    }\n  }\n  """\n\n    print("Logging into Tableau Server...")\n    token = login()\n    print("Session token is: " + token)\n    print("")\n    print("Running the following query:")\n    print(query)\n    print("")\n    print("Answer below:")\n\n    # here we get text\n    json_string = run_query(token, query)\n\n    # we parse the result as a json structure\n    response_as_json = json.loads(json_string)\n\n    # we print the json structure\n    print(json.dumps(response_as_json, sort_keys=True, indent=4))\n\n    # navigating the json structure to find the starting node we need\n    list_of_published_ds = response_as_json["data"]["publishedDatasources"]\n\n    # this array will contain the data we will return to Tableau Prep\n    resultset = []\n\n    # navigating the json structure and collecting data\n    for ds in list_of_published_ds:\n        for flow in ds["downstreamFlows"]:\n            # when we find a downstream flow, we create one entry into the resultset\n            resultset.append([ds["name"], flow["name"],\n                              flow["owner"]["name"], flow["projectName"]])\n\n    # print the resultset for debugging purposes\n    print(resultset)\n\n    # we turn this python array into a pandas dataframe\n    df = pd.DataFrame(data=resultset, columns=[\n                      "ds_name", "flow_name", "owner_name", "project_name"])\n\n    # we return the dataframe to Tableau Prep\n    return(df)\ndef get_output_schema_bea97b3a58e648258274adfc99cd41f5(df = pd.DataFrame()):\n    import inspect\n    if len(inspect.getfullargspec(get_output_schema).args) == 0:\n        return get_output_schema()\n    else:\n        return get_output_schema(df)\nresult_schema_output = get_output_schema_bea97b3a58e648258274adfc99cd41f5(pd.DataFrame(_arg1))\nreturn result_schema_output.to_dict(orient=\'split\') if isinstance(result_schema_output, pd.DataFrame) else result_schema_output'}'...
2021-01-28,13:47:53 [INFO] (base_handler.py:base_handler:115): function to evaluate=def _user_script(tabpy, _arg1):
 import pandas as pd
 def get_output_schema():
 	return '5e1663ee-aeb8-40e2-9e10-d7644bc9e928'
 def prep_string():
 	return ['prep_string_type']
 def prep_bool():
 	return ['prep_bool_type']
 def prep_int():
 	return ['prep_int_type']
 def prep_decimal():
     return ['prep_decimal_type']
 def prep_date():
 	return ['prep_date_type']
 def prep_datetime():
 	return ['prep_datetime_type']
 # os is used to retrieve environment variables
 # requests is used to make HTTP requests out to Tableau Server
 # json is used to parse the answer received from the Tableau metadata API
 # pandas is used to build a dataframe and return data to Tableau Prep
 
 import os
 import requests
 import json
 import pandas as pd
 
 
 # login will perform a login into Tableau Server and return a session token
 # it uses the API_SERVER, API_SECRET_TOKEN and API_TOKEN_NAME environment variables
 # see docker-compose.yml for these environment variables
 
 def login():
     body = {"credentials": {"personalAccessTokenName": os.environ['API_TOKEN_NAME'],
                             "personalAccessTokenSecret": os.environ['API_SECRET_TOKEN'],
                             "site": {"contentUrl": ""}}}
 
     print("Performing login")
 
     url = "https://{server}/api/3.9/auth/signin".format(
         server=os.environ["API_SERVER"])
 
     headers = {
         'accept': 'application/json',
         'content-type': 'application/json'
     }
 
     # making the request
     x = requests.post(url, json=body, headers=headers)
     # parsing the login response
     response = json.loads(x.text)
     # if everything goes well, session token is found here:
     token = response["credentials"]["token"]
 
     return token
 
 # run_query runs a GRAPHQL query against the Tableau metadata API
 # arguments are a session token (obtained with login function) and the query text
 # it uses the API_SERVER environment variable to connect to the server; see docker-compose.yml
 
 
 def run_query(token, query):
     uri = "https://{server}/api/metadata/graphql".format(
         server=os.environ["API_SERVER"])
     headers = {
         'content-type': 'application/json',
         'accept': 'application/json',
         'X-Tableau-Auth': token
     }
     x = requests.post(uri, json={'query': query}, headers=headers)
 
     # we print the plain text answer for debugging purposes
     print(x.text)
 
     # we return the plain text answer received
     return x.text
 
 
 # This function is called by Tableau Prep to obtain the expected schema of the data to receive
 def get_output_schema():
     return pd.DataFrame({
         'ds_name': prep_string(),
         'flow_name': prep_string(),
         'owner_name': prep_string(),
         'project_name': prep_string()
     })
 
 
 # This is the function we well name in a Tableau Prep script node
 # It received data on the input, but doesn't use it
 
 def get_published_ds_used_in_flow(input):
 
     # The hardcoded Graphql query
     query = """query published_datasources_certified {
     publishedDatasources {
       name
       isCertified
       downstreamFlows {
         name,
         owner {
           name
         },
         projectName
       }
     }
   }
   """
 
     print("Logging into Tableau Server...")
     token = login()
     print("Session token is: " + token)
     print("")
     print("Running the following query:")
     print(query)
     print("")
     print("Answer below:")
 
     # here we get text
     json_string = run_query(token, query)
 
     # we parse the result as a json structure
     response_as_json = json.loads(json_string)
 
     # we print the json structure
     print(json.dumps(response_as_json, sort_keys=True, indent=4))
 
     # navigating the json structure to find the starting node we need
     list_of_published_ds = response_as_json["data"]["publishedDatasources"]
 
     # this array will contain the data we will return to Tableau Prep
     resultset = []
 
     # navigating the json structure and collecting data
     for ds in list_of_published_ds:
         for flow in ds["downstreamFlows"]:
             # when we find a downstream flow, we create one entry into the resultset
             resultset.append([ds["name"], flow["name"],
                               flow["owner"]["name"], flow["projectName"]])
 
     # print the resultset for debugging purposes
     print(resultset)
 
     # we turn this python array into a pandas dataframe
     df = pd.DataFrame(data=resultset, columns=[
                       "ds_name", "flow_name", "owner_name", "project_name"])
 
     # we return the dataframe to Tableau Prep
     return(df)
 def get_output_schema_bea97b3a58e648258274adfc99cd41f5(df = pd.DataFrame()):
     import inspect
     if len(inspect.getfullargspec(get_output_schema).args) == 0:
         return get_output_schema()
     else:
         return get_output_schema(df)
 result_schema_output = get_output_schema_bea97b3a58e648258274adfc99cd41f5(pd.DataFrame(_arg1))
 return result_schema_output.to_dict(orient='split') if isinstance(result_schema_output, pd.DataFrame) else result_schema_output

2021-01-28,13:47:53 [DEBUG] (state.py:state:511): Collecting Access-Control-Allow-Origin from state file ...
2021-01-28,13:47:53 [DEBUG] (state.py:state:613): Loading option 'Access-Control-Allow-Origin' from section [Service Info]...
2021-01-28,13:47:53 [DEBUG] (state.py:state:635): Returning value ''
2021-01-28,13:47:53 [DEBUG] (state.py:state:613): Loading option 'Access-Control-Allow-Headers' from section [Service Info]...
2021-01-28,13:47:53 [DEBUG] (state.py:state:635): Returning value ''
2021-01-28,13:47:53 [DEBUG] (state.py:state:613): Loading option 'Access-Control-Allow-Methods' from section [Service Info]...
2021-01-28,13:47:53 [DEBUG] (state.py:state:635): Returning value ''
2021-01-28,13:47:53 [DEBUG] (base_handler.py:base_handler:115): Processing POST request '{'data': {'_arg1': {'ds_name': ['prep_string_type']}}, 'script': 'import pandas as pd\ndef get_output_schema():\n\treturn \'5e1663ee-aeb8-40e2-9e10-d7644bc9e928\'\ndef prep_string():\n\treturn [\'prep_string_type\']\ndef prep_bool():\n\treturn [\'prep_bool_type\']\ndef prep_int():\n\treturn [\'prep_int_type\']\ndef prep_decimal():\n    return [\'prep_decimal_type\']\ndef prep_date():\n\treturn [\'prep_date_type\']\ndef prep_datetime():\n\treturn [\'prep_datetime_type\']\n# os is used to retrieve environment variables\n# requests is used to make HTTP requests out to Tableau Server\n# json is used to parse the answer received from the Tableau metadata API\n# pandas is used to build a dataframe and return data to Tableau Prep\n\nimport os\nimport requests\nimport json\nimport pandas as pd\n\n\n# login will perform a login into Tableau Server and return a session token\n# it uses the API_SERVER, API_SECRET_TOKEN and API_TOKEN_NAME environment variables\n# see docker-compose.yml for these environment variables\n\ndef login():\n    body = {"credentials": {"personalAccessTokenName": os.environ[\'API_TOKEN_NAME\'],\n                            "personalAccessTokenSecret": os.environ[\'API_SECRET_TOKEN\'],\n                            "site": {"contentUrl": ""}}}\n\n    print("Performing login")\n\n    url = "https://{server}/api/3.9/auth/signin".format(\n        server=os.environ["API_SERVER"])\n\n    headers = {\n        \'accept\': \'application/json\',\n        \'content-type\': \'application/json\'\n    }\n\n    # making the request\n    x = requests.post(url, json=body, headers=headers)\n    # parsing the login response\n    response = json.loads(x.text)\n    # if everything goes well, session token is found here:\n    token = response["credentials"]["token"]\n\n    return token\n\n# run_query runs a GRAPHQL query against the Tableau metadata API\n# arguments are a session token (obtained with login function) and the query text\n# it uses the API_SERVER environment variable to connect to the server; see docker-compose.yml\n\n\ndef run_query(token, query):\n    uri = "https://{server}/api/metadata/graphql".format(\n        server=os.environ["API_SERVER"])\n    headers = {\n        \'content-type\': \'application/json\',\n        \'accept\': \'application/json\',\n        \'X-Tableau-Auth\': token\n    }\n    x = requests.post(uri, json={\'query\': query}, headers=headers)\n\n    # we print the plain text answer for debugging purposes\n    print(x.text)\n\n    # we return the plain text answer received\n    return x.text\n\n\n# This function is called by Tableau Prep to obtain the expected schema of the data to receive\ndef get_output_schema():\n    return pd.DataFrame({\n        \'ds_name\': prep_string(),\n        \'flow_name\': prep_string(),\n        \'owner_name\': prep_string(),\n        \'project_name\': prep_string()\n    })\n\n\n# This is the function we well name in a Tableau Prep script node\n# It received data on the input, but doesn\'t use it\n\ndef get_published_ds_used_in_flow(input):\n\n    # The hardcoded Graphql query\n    query = """query published_datasources_certified {\n    publishedDatasources {\n      name\n      isCertified\n      downstreamFlows {\n        name,\n        owner {\n          name\n        },\n        projectName\n      }\n    }\n  }\n  """\n\n    print("Logging into Tableau Server...")\n    token = login()\n    print("Session token is: " + token)\n    print("")\n    print("Running the following query:")\n    print(query)\n    print("")\n    print("Answer below:")\n\n    # here we get text\n    json_string = run_query(token, query)\n\n    # we parse the result as a json structure\n    response_as_json = json.loads(json_string)\n\n    # we print the json structure\n    print(json.dumps(response_as_json, sort_keys=True, indent=4))\n\n    # navigating the json structure to find the starting node we need\n    list_of_published_ds = response_as_json["data"]["publishedDatasources"]\n\n    # this array will contain the data we will return to Tableau Prep\n    resultset = []\n\n    # navigating the json structure and collecting data\n    for ds in list_of_published_ds:\n        for flow in ds["downstreamFlows"]:\n            # when we find a downstream flow, we create one entry into the resultset\n            resultset.append([ds["name"], flow["name"],\n                              flow["owner"]["name"], flow["projectName"]])\n\n    # print the resultset for debugging purposes\n    print(resultset)\n\n    # we turn this python array into a pandas dataframe\n    df = pd.DataFrame(data=resultset, columns=[\n                      "ds_name", "flow_name", "owner_name", "project_name"])\n\n    # we return the dataframe to Tableau Prep\n    return(df)\ndef get_output_schema_bea97b3a58e648258274adfc99cd41f5(df = pd.DataFrame()):\n    import inspect\n    if len(inspect.getfullargspec(get_output_schema).args) == 0:\n        return get_output_schema()\n    else:\n        return get_output_schema(df)\nresult_schema_output = get_output_schema_bea97b3a58e648258274adfc99cd41f5(pd.DataFrame(_arg1))\nreturn result_schema_output.to_dict(orient=\'split\') if isinstance(result_schema_output, pd.DataFrame) else result_schema_output'}'...
2021-01-28,13:47:53 [INFO] (base_handler.py:base_handler:115): function to evaluate=def _user_script(tabpy, _arg1):
 import pandas as pd
 def get_output_schema():
 	return '5e1663ee-aeb8-40e2-9e10-d7644bc9e928'
 def prep_string():
 	return ['prep_string_type']
 def prep_bool():
 	return ['prep_bool_type']
 def prep_int():
 	return ['prep_int_type']
 def prep_decimal():
     return ['prep_decimal_type']
 def prep_date():
 	return ['prep_date_type']
 def prep_datetime():
 	return ['prep_datetime_type']
 # os is used to retrieve environment variables
 # requests is used to make HTTP requests out to Tableau Server
 # json is used to parse the answer received from the Tableau metadata API
 # pandas is used to build a dataframe and return data to Tableau Prep
 
 import os
 import requests
 import json
 import pandas as pd
 
 
 # login will perform a login into Tableau Server and return a session token
 # it uses the API_SERVER, API_SECRET_TOKEN and API_TOKEN_NAME environment variables
 # see docker-compose.yml for these environment variables
 
 def login():
     body = {"credentials": {"personalAccessTokenName": os.environ['API_TOKEN_NAME'],
                             "personalAccessTokenSecret": os.environ['API_SECRET_TOKEN'],
                             "site": {"contentUrl": ""}}}
 
     print("Performing login")
 
     url = "https://{server}/api/3.9/auth/signin".format(
         server=os.environ["API_SERVER"])
 
     headers = {
         'accept': 'application/json',
         'content-type': 'application/json'
     }
 
     # making the request
     x = requests.post(url, json=body, headers=headers)
     # parsing the login response
     response = json.loads(x.text)
     # if everything goes well, session token is found here:
     token = response["credentials"]["token"]
 
     return token
 
 # run_query runs a GRAPHQL query against the Tableau metadata API
 # arguments are a session token (obtained with login function) and the query text
 # it uses the API_SERVER environment variable to connect to the server; see docker-compose.yml
 
 
 def run_query(token, query):
     uri = "https://{server}/api/metadata/graphql".format(
         server=os.environ["API_SERVER"])
     headers = {
         'content-type': 'application/json',
         'accept': 'application/json',
         'X-Tableau-Auth': token
     }
     x = requests.post(uri, json={'query': query}, headers=headers)
 
     # we print the plain text answer for debugging purposes
     print(x.text)
 
     # we return the plain text answer received
     return x.text
 
 
 # This function is called by Tableau Prep to obtain the expected schema of the data to receive
 def get_output_schema():
     return pd.DataFrame({
         'ds_name': prep_string(),
         'flow_name': prep_string(),
         'owner_name': prep_string(),
         'project_name': prep_string()
     })
 
 
 # This is the function we well name in a Tableau Prep script node
 # It received data on the input, but doesn't use it
 
 def get_published_ds_used_in_flow(input):
 
     # The hardcoded Graphql query
     query = """query published_datasources_certified {
     publishedDatasources {
       name
       isCertified
       downstreamFlows {
         name,
         owner {
           name
         },
         projectName
       }
     }
   }
   """
 
     print("Logging into Tableau Server...")
     token = login()
     print("Session token is: " + token)
     print("")
     print("Running the following query:")
     print(query)
     print("")
     print("Answer below:")
 
     # here we get text
     json_string = run_query(token, query)
 
     # we parse the result as a json structure
     response_as_json = json.loads(json_string)
 
     # we print the json structure
     print(json.dumps(response_as_json, sort_keys=True, indent=4))
 
     # navigating the json structure to find the starting node we need
     list_of_published_ds = response_as_json["data"]["publishedDatasources"]
 
     # this array will contain the data we will return to Tableau Prep
     resultset = []
 
     # navigating the json structure and collecting data
     for ds in list_of_published_ds:
         for flow in ds["downstreamFlows"]:
             # when we find a downstream flow, we create one entry into the resultset
             resultset.append([ds["name"], flow["name"],
                               flow["owner"]["name"], flow["projectName"]])
 
     # print the resultset for debugging purposes
     print(resultset)
 
     # we turn this python array into a pandas dataframe
     df = pd.DataFrame(data=resultset, columns=[
                       "ds_name", "flow_name", "owner_name", "project_name"])
 
     # we return the dataframe to Tableau Prep
     return(df)
 def get_output_schema_bea97b3a58e648258274adfc99cd41f5(df = pd.DataFrame()):
     import inspect
     if len(inspect.getfullargspec(get_output_schema).args) == 0:
         return get_output_schema()
     else:
         return get_output_schema(df)
 result_schema_output = get_output_schema_bea97b3a58e648258274adfc99cd41f5(pd.DataFrame(_arg1))
 return result_schema_output.to_dict(orient='split') if isinstance(result_schema_output, pd.DataFrame) else result_schema_output

2021-01-28,13:47:53 [DEBUG] (state.py:state:511): Collecting Access-Control-Allow-Origin from state file ...
2021-01-28,13:47:53 [DEBUG] (state.py:state:613): Loading option 'Access-Control-Allow-Origin' from section [Service Info]...
2021-01-28,13:47:53 [DEBUG] (state.py:state:635): Returning value ''
2021-01-28,13:47:53 [DEBUG] (state.py:state:613): Loading option 'Access-Control-Allow-Headers' from section [Service Info]...
2021-01-28,13:47:53 [DEBUG] (state.py:state:635): Returning value ''
2021-01-28,13:47:53 [DEBUG] (state.py:state:613): Loading option 'Access-Control-Allow-Methods' from section [Service Info]...
2021-01-28,13:47:53 [DEBUG] (state.py:state:635): Returning value ''
2021-01-28,13:47:53 [DEBUG] (base_handler.py:base_handler:115): Processing POST request '{'data': {'_arg1': {'ds_name': ['prep_string_type']}}, 'script': 'import pandas as pd\ndef get_output_schema():\n\treturn \'5e1663ee-aeb8-40e2-9e10-d7644bc9e928\'\ndef prep_string():\n\treturn [\'prep_string_type\']\ndef prep_bool():\n\treturn [\'prep_bool_type\']\ndef prep_int():\n\treturn [\'prep_int_type\']\ndef prep_decimal():\n    return [\'prep_decimal_type\']\ndef prep_date():\n\treturn [\'prep_date_type\']\ndef prep_datetime():\n\treturn [\'prep_datetime_type\']\n# os is used to retrieve environment variables\n# requests is used to make HTTP requests out to Tableau Server\n# json is used to parse the answer received from the Tableau metadata API\n# pandas is used to build a dataframe and return data to Tableau Prep\n\nimport os\nimport requests\nimport json\nimport pandas as pd\n\n\n# login will perform a login into Tableau Server and return a session token\n# it uses the API_SERVER, API_SECRET_TOKEN and API_TOKEN_NAME environment variables\n# see docker-compose.yml for these environment variables\n\ndef login():\n    body = {"credentials": {"personalAccessTokenName": os.environ[\'API_TOKEN_NAME\'],\n                            "personalAccessTokenSecret": os.environ[\'API_SECRET_TOKEN\'],\n                            "site": {"contentUrl": ""}}}\n\n    print("Performing login")\n\n    url = "https://{server}/api/3.9/auth/signin".format(\n        server=os.environ["API_SERVER"])\n\n    headers = {\n        \'accept\': \'application/json\',\n        \'content-type\': \'application/json\'\n    }\n\n    # making the request\n    x = requests.post(url, json=body, headers=headers)\n    # parsing the login response\n    response = json.loads(x.text)\n    # if everything goes well, session token is found here:\n    token = response["credentials"]["token"]\n\n    return token\n\n# run_query runs a GRAPHQL query against the Tableau metadata API\n# arguments are a session token (obtained with login function) and the query text\n# it uses the API_SERVER environment variable to connect to the server; see docker-compose.yml\n\n\ndef run_query(token, query):\n    uri = "https://{server}/api/metadata/graphql".format(\n        server=os.environ["API_SERVER"])\n    headers = {\n        \'content-type\': \'application/json\',\n        \'accept\': \'application/json\',\n        \'X-Tableau-Auth\': token\n    }\n    x = requests.post(uri, json={\'query\': query}, headers=headers)\n\n    # we print the plain text answer for debugging purposes\n    print(x.text)\n\n    # we return the plain text answer received\n    return x.text\n\n\n# This function is called by Tableau Prep to obtain the expected schema of the data to receive\ndef get_output_schema():\n    return pd.DataFrame({\n        \'ds_name\': prep_string(),\n        \'flow_name\': prep_string(),\n        \'owner_name\': prep_string(),\n        \'project_name\': prep_string()\n    })\n\n\n# This is the function we well name in a Tableau Prep script node\n# It received data on the input, but doesn\'t use it\n\ndef get_published_ds_used_in_flow(input):\n\n    # The hardcoded Graphql query\n    query = """query published_datasources_certified {\n    publishedDatasources {\n      name\n      isCertified\n      downstreamFlows {\n        name,\n        owner {\n          name\n        },\n        projectName\n      }\n    }\n  }\n  """\n\n    print("Logging into Tableau Server...")\n    token = login()\n    print("Session token is: " + token)\n    print("")\n    print("Running the following query:")\n    print(query)\n    print("")\n    print("Answer below:")\n\n    # here we get text\n    json_string = run_query(token, query)\n\n    # we parse the result as a json structure\n    response_as_json = json.loads(json_string)\n\n    # we print the json structure\n    print(json.dumps(response_as_json, sort_keys=True, indent=4))\n\n    # navigating the json structure to find the starting node we need\n    list_of_published_ds = response_as_json["data"]["publishedDatasources"]\n\n    # this array will contain the data we will return to Tableau Prep\n    resultset = []\n\n    # navigating the json structure and collecting data\n    for ds in list_of_published_ds:\n        for flow in ds["downstreamFlows"]:\n            # when we find a downstream flow, we create one entry into the resultset\n            resultset.append([ds["name"], flow["name"],\n                              flow["owner"]["name"], flow["projectName"]])\n\n    # print the resultset for debugging purposes\n    print(resultset)\n\n    # we turn this python array into a pandas dataframe\n    df = pd.DataFrame(data=resultset, columns=[\n                      "ds_name", "flow_name", "owner_name", "project_name"])\n\n    # we return the dataframe to Tableau Prep\n    return(df)\ndef get_output_schema_bea97b3a58e648258274adfc99cd41f5(df = pd.DataFrame()):\n    import inspect\n    if len(inspect.getfullargspec(get_output_schema).args) == 0:\n        return get_output_schema()\n    else:\n        return get_output_schema(df)\nresult_schema_output = get_output_schema_bea97b3a58e648258274adfc99cd41f5(pd.DataFrame(_arg1))\nreturn result_schema_output.to_dict(orient=\'split\') if isinstance(result_schema_output, pd.DataFrame) else result_schema_output'}'...
2021-01-28,13:47:53 [INFO] (base_handler.py:base_handler:115): function to evaluate=def _user_script(tabpy, _arg1):
 import pandas as pd
 def get_output_schema():
 	return '5e1663ee-aeb8-40e2-9e10-d7644bc9e928'
 def prep_string():
 	return ['prep_string_type']
 def prep_bool():
 	return ['prep_bool_type']
 def prep_int():
 	return ['prep_int_type']
 def prep_decimal():
     return ['prep_decimal_type']
 def prep_date():
 	return ['prep_date_type']
 def prep_datetime():
 	return ['prep_datetime_type']
 # os is used to retrieve environment variables
 # requests is used to make HTTP requests out to Tableau Server
 # json is used to parse the answer received from the Tableau metadata API
 # pandas is used to build a dataframe and return data to Tableau Prep
 
 import os
 import requests
 import json
 import pandas as pd
 
 
 # login will perform a login into Tableau Server and return a session token
 # it uses the API_SERVER, API_SECRET_TOKEN and API_TOKEN_NAME environment variables
 # see docker-compose.yml for these environment variables
 
 def login():
     body = {"credentials": {"personalAccessTokenName": os.environ['API_TOKEN_NAME'],
                             "personalAccessTokenSecret": os.environ['API_SECRET_TOKEN'],
                             "site": {"contentUrl": ""}}}
 
     print("Performing login")
 
     url = "https://{server}/api/3.9/auth/signin".format(
         server=os.environ["API_SERVER"])
 
     headers = {
         'accept': 'application/json',
         'content-type': 'application/json'
     }
 
     # making the request
     x = requests.post(url, json=body, headers=headers)
     # parsing the login response
     response = json.loads(x.text)
     # if everything goes well, session token is found here:
     token = response["credentials"]["token"]
 
     return token
 
 # run_query runs a GRAPHQL query against the Tableau metadata API
 # arguments are a session token (obtained with login function) and the query text
 # it uses the API_SERVER environment variable to connect to the server; see docker-compose.yml
 
 
 def run_query(token, query):
     uri = "https://{server}/api/metadata/graphql".format(
         server=os.environ["API_SERVER"])
     headers = {
         'content-type': 'application/json',
         'accept': 'application/json',
         'X-Tableau-Auth': token
     }
     x = requests.post(uri, json={'query': query}, headers=headers)
 
     # we print the plain text answer for debugging purposes
     print(x.text)
 
     # we return the plain text answer received
     return x.text
 
 
 # This function is called by Tableau Prep to obtain the expected schema of the data to receive
 def get_output_schema():
     return pd.DataFrame({
         'ds_name': prep_string(),
         'flow_name': prep_string(),
         'owner_name': prep_string(),
         'project_name': prep_string()
     })
 
 
 # This is the function we well name in a Tableau Prep script node
 # It received data on the input, but doesn't use it
 
 def get_published_ds_used_in_flow(input):
 
     # The hardcoded Graphql query
     query = """query published_datasources_certified {
     publishedDatasources {
       name
       isCertified
       downstreamFlows {
         name,
         owner {
           name
         },
         projectName
       }
     }
   }
   """
 
     print("Logging into Tableau Server...")
     token = login()
     print("Session token is: " + token)
     print("")
     print("Running the following query:")
     print(query)
     print("")
     print("Answer below:")
 
     # here we get text
     json_string = run_query(token, query)
 
     # we parse the result as a json structure
     response_as_json = json.loads(json_string)
 
     # we print the json structure
     print(json.dumps(response_as_json, sort_keys=True, indent=4))
 
     # navigating the json structure to find the starting node we need
     list_of_published_ds = response_as_json["data"]["publishedDatasources"]
 
     # this array will contain the data we will return to Tableau Prep
     resultset = []
 
     # navigating the json structure and collecting data
     for ds in list_of_published_ds:
         for flow in ds["downstreamFlows"]:
             # when we find a downstream flow, we create one entry into the resultset
             resultset.append([ds["name"], flow["name"],
                               flow["owner"]["name"], flow["projectName"]])
 
     # print the resultset for debugging purposes
     print(resultset)
 
     # we turn this python array into a pandas dataframe
     df = pd.DataFrame(data=resultset, columns=[
                       "ds_name", "flow_name", "owner_name", "project_name"])
 
     # we return the dataframe to Tableau Prep
     return(df)
 def get_output_schema_bea97b3a58e648258274adfc99cd41f5(df = pd.DataFrame()):
     import inspect
     if len(inspect.getfullargspec(get_output_schema).args) == 0:
         return get_output_schema()
     else:
         return get_output_schema(df)
 result_schema_output = get_output_schema_bea97b3a58e648258274adfc99cd41f5(pd.DataFrame(_arg1))
 return result_schema_output.to_dict(orient='split') if isinstance(result_schema_output, pd.DataFrame) else result_schema_output

2021-01-28,13:47:53 [INFO] (web.py:web:2239): 200 POST /evaluate (172.18.0.1) 124.82ms
2021-01-28,13:47:53 [INFO] (web.py:web:2239): 200 POST /evaluate (172.18.0.1) 91.74ms
2021-01-28,13:47:53 [INFO] (web.py:web:2239): 200 POST /evaluate (172.18.0.1) 86.00ms
2021-01-28,13:47:53 [INFO] (web.py:web:2239): 200 POST /evaluate (172.18.0.1) 79.86ms
2021-01-28,13:47:53 [INFO] (web.py:web:2239): 200 POST /evaluate (172.18.0.1) 75.42ms
2021-01-28,13:47:53 [DEBUG] (base_handler.py:base_handler:115): Checking if need to handle authentication
2021-01-28,13:47:53 [DEBUG] (base_handler.py:base_handler:115): Handling authentication
2021-01-28,13:47:53 [INFO] (base_handler.py:base_handler:115): Authentication is not a required feature for API "v1"
2021-01-28,13:47:53 [DEBUG] (base_handler.py:base_handler:115): Checking request headers for authentication data
2021-01-28,13:47:53 [INFO] (base_handler.py:base_handler:115): Authorization header not found
2021-01-28,13:47:53 [DEBUG] (base_handler.py:base_handler:115): authentication not required, username and password are none
2021-01-28,13:47:53 [DEBUG] (base_handler.py:base_handler:115): Checking if need to handle authentication
2021-01-28,13:47:53 [DEBUG] (base_handler.py:base_handler:115): Handling authentication
2021-01-28,13:47:53 [INFO] (base_handler.py:base_handler:115): Authentication is not a required feature for API "v1"
2021-01-28,13:47:53 [DEBUG] (base_handler.py:base_handler:115): Checking request headers for authentication data
2021-01-28,13:47:53 [INFO] (base_handler.py:base_handler:115): Authorization header not found
2021-01-28,13:47:53 [DEBUG] (base_handler.py:base_handler:115): authentication not required, username and password are none
2021-01-28,13:47:53 [DEBUG] (state.py:state:511): Collecting Access-Control-Allow-Origin from state file ...
2021-01-28,13:47:53 [DEBUG] (state.py:state:613): Loading option 'Access-Control-Allow-Origin' from section [Service Info]...
2021-01-28,13:47:53 [DEBUG] (state.py:state:635): Returning value ''
2021-01-28,13:47:53 [DEBUG] (state.py:state:613): Loading option 'Access-Control-Allow-Headers' from section [Service Info]...
2021-01-28,13:47:53 [DEBUG] (state.py:state:635): Returning value ''
2021-01-28,13:47:53 [DEBUG] (state.py:state:613): Loading option 'Access-Control-Allow-Methods' from section [Service Info]...
2021-01-28,13:47:53 [DEBUG] (state.py:state:635): Returning value ''
2021-01-28,13:47:53 [DEBUG] (base_handler.py:base_handler:115): Processing POST request '{'data': {'_arg1': {'ds_name': ['prep_string_type']}}, 'script': 'import pandas as pd\ndef get_output_schema():\n\treturn \'5e1663ee-aeb8-40e2-9e10-d7644bc9e928\'\ndef prep_string():\n\treturn [\'prep_string_type\']\ndef prep_bool():\n\treturn [\'prep_bool_type\']\ndef prep_int():\n\treturn [\'prep_int_type\']\ndef prep_decimal():\n    return [\'prep_decimal_type\']\ndef prep_date():\n\treturn [\'prep_date_type\']\ndef prep_datetime():\n\treturn [\'prep_datetime_type\']\n# os is used to retrieve environment variables\n# requests is used to make HTTP requests out to Tableau Server\n# json is used to parse the answer received from the Tableau metadata API\n# pandas is used to build a dataframe and return data to Tableau Prep\n\nimport os\nimport requests\nimport json\nimport pandas as pd\n\n\n# login will perform a login into Tableau Server and return a session token\n# it uses the API_SERVER, API_SECRET_TOKEN and API_TOKEN_NAME environment variables\n# see docker-compose.yml for these environment variables\n\ndef login():\n    body = {"credentials": {"personalAccessTokenName": os.environ[\'API_TOKEN_NAME\'],\n                            "personalAccessTokenSecret": os.environ[\'API_SECRET_TOKEN\'],\n                            "site": {"contentUrl": ""}}}\n\n    print("Performing login")\n\n    url = "https://{server}/api/3.9/auth/signin".format(\n        server=os.environ["API_SERVER"])\n\n    headers = {\n        \'accept\': \'application/json\',\n        \'content-type\': \'application/json\'\n    }\n\n    # making the request\n    x = requests.post(url, json=body, headers=headers)\n    # parsing the login response\n    response = json.loads(x.text)\n    # if everything goes well, session token is found here:\n    token = response["credentials"]["token"]\n\n    return token\n\n# run_query runs a GRAPHQL query against the Tableau metadata API\n# arguments are a session token (obtained with login function) and the query text\n# it uses the API_SERVER environment variable to connect to the server; see docker-compose.yml\n\n\ndef run_query(token, query):\n    uri = "https://{server}/api/metadata/graphql".format(\n        server=os.environ["API_SERVER"])\n    headers = {\n        \'content-type\': \'application/json\',\n        \'accept\': \'application/json\',\n        \'X-Tableau-Auth\': token\n    }\n    x = requests.post(uri, json={\'query\': query}, headers=headers)\n\n    # we print the plain text answer for debugging purposes\n    print(x.text)\n\n    # we return the plain text answer received\n    return x.text\n\n\n# This function is called by Tableau Prep to obtain the expected schema of the data to receive\ndef get_output_schema():\n    return pd.DataFrame({\n        \'ds_name\': prep_string(),\n        \'flow_name\': prep_string(),\n        \'owner_name\': prep_string(),\n        \'project_name\': prep_string()\n    })\n\n\n# This is the function we well name in a Tableau Prep script node\n# It received data on the input, but doesn\'t use it\n\ndef get_published_ds_used_in_flow(input):\n\n    # The hardcoded Graphql query\n    query = """query published_datasources_certified {\n    publishedDatasources {\n      name\n      isCertified\n      downstreamFlows {\n        name,\n        owner {\n          name\n        },\n        projectName\n      }\n    }\n  }\n  """\n\n    print("Logging into Tableau Server...")\n    token = login()\n    print("Session token is: " + token)\n    print("")\n    print("Running the following query:")\n    print(query)\n    print("")\n    print("Answer below:")\n\n    # here we get text\n    json_string = run_query(token, query)\n\n    # we parse the result as a json structure\n    response_as_json = json.loads(json_string)\n\n    # we print the json structure\n    print(json.dumps(response_as_json, sort_keys=True, indent=4))\n\n    # navigating the json structure to find the starting node we need\n    list_of_published_ds = response_as_json["data"]["publishedDatasources"]\n\n    # this array will contain the data we will return to Tableau Prep\n    resultset = []\n\n    # navigating the json structure and collecting data\n    for ds in list_of_published_ds:\n        for flow in ds["downstreamFlows"]:\n            # when we find a downstream flow, we create one entry into the resultset\n            resultset.append([ds["name"], flow["name"],\n                              flow["owner"]["name"], flow["projectName"]])\n\n    # print the resultset for debugging purposes\n    print(resultset)\n\n    # we turn this python array into a pandas dataframe\n    df = pd.DataFrame(data=resultset, columns=[\n                      "ds_name", "flow_name", "owner_name", "project_name"])\n\n    # we return the dataframe to Tableau Prep\n    return(df)\ndef get_output_schema_bea97b3a58e648258274adfc99cd41f5(df = pd.DataFrame()):\n    import inspect\n    if len(inspect.getfullargspec(get_output_schema).args) == 0:\n        return get_output_schema()\n    else:\n        return get_output_schema(df)\nresult_schema_output = get_output_schema_bea97b3a58e648258274adfc99cd41f5(pd.DataFrame(_arg1))\nreturn result_schema_output.to_dict(orient=\'split\') if isinstance(result_schema_output, pd.DataFrame) else result_schema_output'}'...
2021-01-28,13:47:53 [INFO] (base_handler.py:base_handler:115): function to evaluate=def _user_script(tabpy, _arg1):
 import pandas as pd
 def get_output_schema():
 	return '5e1663ee-aeb8-40e2-9e10-d7644bc9e928'
 def prep_string():
 	return ['prep_string_type']
 def prep_bool():
 	return ['prep_bool_type']
 def prep_int():
 	return ['prep_int_type']
 def prep_decimal():
     return ['prep_decimal_type']
 def prep_date():
 	return ['prep_date_type']
 def prep_datetime():
 	return ['prep_datetime_type']
 # os is used to retrieve environment variables
 # requests is used to make HTTP requests out to Tableau Server
 # json is used to parse the answer received from the Tableau metadata API
 # pandas is used to build a dataframe and return data to Tableau Prep
 
 import os
 import requests
 import json
 import pandas as pd
 
 
 # login will perform a login into Tableau Server and return a session token
 # it uses the API_SERVER, API_SECRET_TOKEN and API_TOKEN_NAME environment variables
 # see docker-compose.yml for these environment variables
 
 def login():
     body = {"credentials": {"personalAccessTokenName": os.environ['API_TOKEN_NAME'],
                             "personalAccessTokenSecret": os.environ['API_SECRET_TOKEN'],
                             "site": {"contentUrl": ""}}}
 
     print("Performing login")
 
     url = "https://{server}/api/3.9/auth/signin".format(
         server=os.environ["API_SERVER"])
 
     headers = {
         'accept': 'application/json',
         'content-type': 'application/json'
     }
 
     # making the request
     x = requests.post(url, json=body, headers=headers)
     # parsing the login response
     response = json.loads(x.text)
     # if everything goes well, session token is found here:
     token = response["credentials"]["token"]
 
     return token
 
 # run_query runs a GRAPHQL query against the Tableau metadata API
 # arguments are a session token (obtained with login function) and the query text
 # it uses the API_SERVER environment variable to connect to the server; see docker-compose.yml
 
 
 def run_query(token, query):
     uri = "https://{server}/api/metadata/graphql".format(
         server=os.environ["API_SERVER"])
     headers = {
         'content-type': 'application/json',
         'accept': 'application/json',
         'X-Tableau-Auth': token
     }
     x = requests.post(uri, json={'query': query}, headers=headers)
 
     # we print the plain text answer for debugging purposes
     print(x.text)
 
     # we return the plain text answer received
     return x.text
 
 
 # This function is called by Tableau Prep to obtain the expected schema of the data to receive
 def get_output_schema():
     return pd.DataFrame({
         'ds_name': prep_string(),
         'flow_name': prep_string(),
         'owner_name': prep_string(),
         'project_name': prep_string()
     })
 
 
 # This is the function we well name in a Tableau Prep script node
 # It received data on the input, but doesn't use it
 
 def get_published_ds_used_in_flow(input):
 
     # The hardcoded Graphql query
     query = """query published_datasources_certified {
     publishedDatasources {
       name
       isCertified
       downstreamFlows {
         name,
         owner {
           name
         },
         projectName
       }
     }
   }
   """
 
     print("Logging into Tableau Server...")
     token = login()
     print("Session token is: " + token)
     print("")
     print("Running the following query:")
     print(query)
     print("")
     print("Answer below:")
 
     # here we get text
     json_string = run_query(token, query)
 
     # we parse the result as a json structure
     response_as_json = json.loads(json_string)
 
     # we print the json structure
     print(json.dumps(response_as_json, sort_keys=True, indent=4))
 
     # navigating the json structure to find the starting node we need
     list_of_published_ds = response_as_json["data"]["publishedDatasources"]
 
     # this array will contain the data we will return to Tableau Prep
     resultset = []
 
     # navigating the json structure and collecting data
     for ds in list_of_published_ds:
         for flow in ds["downstreamFlows"]:
             # when we find a downstream flow, we create one entry into the resultset
             resultset.append([ds["name"], flow["name"],
                               flow["owner"]["name"], flow["projectName"]])
 
     # print the resultset for debugging purposes
     print(resultset)
 
     # we turn this python array into a pandas dataframe
     df = pd.DataFrame(data=resultset, columns=[
                       "ds_name", "flow_name", "owner_name", "project_name"])
 
     # we return the dataframe to Tableau Prep
     return(df)
 def get_output_schema_bea97b3a58e648258274adfc99cd41f5(df = pd.DataFrame()):
     import inspect
     if len(inspect.getfullargspec(get_output_schema).args) == 0:
         return get_output_schema()
     else:
         return get_output_schema(df)
 result_schema_output = get_output_schema_bea97b3a58e648258274adfc99cd41f5(pd.DataFrame(_arg1))
 return result_schema_output.to_dict(orient='split') if isinstance(result_schema_output, pd.DataFrame) else result_schema_output

2021-01-28,13:47:53 [DEBUG] (state.py:state:511): Collecting Access-Control-Allow-Origin from state file ...
2021-01-28,13:47:53 [DEBUG] (state.py:state:613): Loading option 'Access-Control-Allow-Origin' from section [Service Info]...
2021-01-28,13:47:53 [DEBUG] (state.py:state:635): Returning value ''
2021-01-28,13:47:53 [DEBUG] (state.py:state:613): Loading option 'Access-Control-Allow-Headers' from section [Service Info]...
2021-01-28,13:47:53 [DEBUG] (state.py:state:635): Returning value ''
2021-01-28,13:47:53 [DEBUG] (state.py:state:613): Loading option 'Access-Control-Allow-Methods' from section [Service Info]...
2021-01-28,13:47:53 [DEBUG] (state.py:state:635): Returning value ''
2021-01-28,13:47:53 [DEBUG] (base_handler.py:base_handler:115): Processing POST request '{'data': {'_arg1': {'ds_name': ['prep_string_type']}}, 'script': 'import pandas as pd\ndef get_output_schema():\n\treturn \'5e1663ee-aeb8-40e2-9e10-d7644bc9e928\'\ndef prep_string():\n\treturn [\'prep_string_type\']\ndef prep_bool():\n\treturn [\'prep_bool_type\']\ndef prep_int():\n\treturn [\'prep_int_type\']\ndef prep_decimal():\n    return [\'prep_decimal_type\']\ndef prep_date():\n\treturn [\'prep_date_type\']\ndef prep_datetime():\n\treturn [\'prep_datetime_type\']\n# os is used to retrieve environment variables\n# requests is used to make HTTP requests out to Tableau Server\n# json is used to parse the answer received from the Tableau metadata API\n# pandas is used to build a dataframe and return data to Tableau Prep\n\nimport os\nimport requests\nimport json\nimport pandas as pd\n\n\n# login will perform a login into Tableau Server and return a session token\n# it uses the API_SERVER, API_SECRET_TOKEN and API_TOKEN_NAME environment variables\n# see docker-compose.yml for these environment variables\n\ndef login():\n    body = {"credentials": {"personalAccessTokenName": os.environ[\'API_TOKEN_NAME\'],\n                            "personalAccessTokenSecret": os.environ[\'API_SECRET_TOKEN\'],\n                            "site": {"contentUrl": ""}}}\n\n    print("Performing login")\n\n    url = "https://{server}/api/3.9/auth/signin".format(\n        server=os.environ["API_SERVER"])\n\n    headers = {\n        \'accept\': \'application/json\',\n        \'content-type\': \'application/json\'\n    }\n\n    # making the request\n    x = requests.post(url, json=body, headers=headers)\n    # parsing the login response\n    response = json.loads(x.text)\n    # if everything goes well, session token is found here:\n    token = response["credentials"]["token"]\n\n    return token\n\n# run_query runs a GRAPHQL query against the Tableau metadata API\n# arguments are a session token (obtained with login function) and the query text\n# it uses the API_SERVER environment variable to connect to the server; see docker-compose.yml\n\n\ndef run_query(token, query):\n    uri = "https://{server}/api/metadata/graphql".format(\n        server=os.environ["API_SERVER"])\n    headers = {\n        \'content-type\': \'application/json\',\n        \'accept\': \'application/json\',\n        \'X-Tableau-Auth\': token\n    }\n    x = requests.post(uri, json={\'query\': query}, headers=headers)\n\n    # we print the plain text answer for debugging purposes\n    print(x.text)\n\n    # we return the plain text answer received\n    return x.text\n\n\n# This function is called by Tableau Prep to obtain the expected schema of the data to receive\ndef get_output_schema():\n    return pd.DataFrame({\n        \'ds_name\': prep_string(),\n        \'flow_name\': prep_string(),\n        \'owner_name\': prep_string(),\n        \'project_name\': prep_string()\n    })\n\n\n# This is the function we well name in a Tableau Prep script node\n# It received data on the input, but doesn\'t use it\n\ndef get_published_ds_used_in_flow(input):\n\n    # The hardcoded Graphql query\n    query = """query published_datasources_certified {\n    publishedDatasources {\n      name\n      isCertified\n      downstreamFlows {\n        name,\n        owner {\n          name\n        },\n        projectName\n      }\n    }\n  }\n  """\n\n    print("Logging into Tableau Server...")\n    token = login()\n    print("Session token is: " + token)\n    print("")\n    print("Running the following query:")\n    print(query)\n    print("")\n    print("Answer below:")\n\n    # here we get text\n    json_string = run_query(token, query)\n\n    # we parse the result as a json structure\n    response_as_json = json.loads(json_string)\n\n    # we print the json structure\n    print(json.dumps(response_as_json, sort_keys=True, indent=4))\n\n    # navigating the json structure to find the starting node we need\n    list_of_published_ds = response_as_json["data"]["publishedDatasources"]\n\n    # this array will contain the data we will return to Tableau Prep\n    resultset = []\n\n    # navigating the json structure and collecting data\n    for ds in list_of_published_ds:\n        for flow in ds["downstreamFlows"]:\n            # when we find a downstream flow, we create one entry into the resultset\n            resultset.append([ds["name"], flow["name"],\n                              flow["owner"]["name"], flow["projectName"]])\n\n    # print the resultset for debugging purposes\n    print(resultset)\n\n    # we turn this python array into a pandas dataframe\n    df = pd.DataFrame(data=resultset, columns=[\n                      "ds_name", "flow_name", "owner_name", "project_name"])\n\n    # we return the dataframe to Tableau Prep\n    return(df)\ndef get_output_schema_bea97b3a58e648258274adfc99cd41f5(df = pd.DataFrame()):\n    import inspect\n    if len(inspect.getfullargspec(get_output_schema).args) == 0:\n        return get_output_schema()\n    else:\n        return get_output_schema(df)\nresult_schema_output = get_output_schema_bea97b3a58e648258274adfc99cd41f5(pd.DataFrame(_arg1))\nreturn result_schema_output.to_dict(orient=\'split\') if isinstance(result_schema_output, pd.DataFrame) else result_schema_output'}'...
2021-01-28,13:47:53 [INFO] (base_handler.py:base_handler:115): function to evaluate=def _user_script(tabpy, _arg1):
 import pandas as pd
 def get_output_schema():
 	return '5e1663ee-aeb8-40e2-9e10-d7644bc9e928'
 def prep_string():
 	return ['prep_string_type']
 def prep_bool():
 	return ['prep_bool_type']
 def prep_int():
 	return ['prep_int_type']
 def prep_decimal():
     return ['prep_decimal_type']
 def prep_date():
 	return ['prep_date_type']
 def prep_datetime():
 	return ['prep_datetime_type']
 # os is used to retrieve environment variables
 # requests is used to make HTTP requests out to Tableau Server
 # json is used to parse the answer received from the Tableau metadata API
 # pandas is used to build a dataframe and return data to Tableau Prep
 
 import os
 import requests
 import json
 import pandas as pd
 
 
 # login will perform a login into Tableau Server and return a session token
 # it uses the API_SERVER, API_SECRET_TOKEN and API_TOKEN_NAME environment variables
 # see docker-compose.yml for these environment variables
 
 def login():
     body = {"credentials": {"personalAccessTokenName": os.environ['API_TOKEN_NAME'],
                             "personalAccessTokenSecret": os.environ['API_SECRET_TOKEN'],
                             "site": {"contentUrl": ""}}}
 
     print("Performing login")
 
     url = "https://{server}/api/3.9/auth/signin".format(
         server=os.environ["API_SERVER"])
 
     headers = {
         'accept': 'application/json',
         'content-type': 'application/json'
     }
 
     # making the request
     x = requests.post(url, json=body, headers=headers)
     # parsing the login response
     response = json.loads(x.text)
     # if everything goes well, session token is found here:
     token = response["credentials"]["token"]
 
     return token
 
 # run_query runs a GRAPHQL query against the Tableau metadata API
 # arguments are a session token (obtained with login function) and the query text
 # it uses the API_SERVER environment variable to connect to the server; see docker-compose.yml
 
 
 def run_query(token, query):
     uri = "https://{server}/api/metadata/graphql".format(
         server=os.environ["API_SERVER"])
     headers = {
         'content-type': 'application/json',
         'accept': 'application/json',
         'X-Tableau-Auth': token
     }
     x = requests.post(uri, json={'query': query}, headers=headers)
 
     # we print the plain text answer for debugging purposes
     print(x.text)
 
     # we return the plain text answer received
     return x.text
 
 
 # This function is called by Tableau Prep to obtain the expected schema of the data to receive
 def get_output_schema():
     return pd.DataFrame({
         'ds_name': prep_string(),
         'flow_name': prep_string(),
         'owner_name': prep_string(),
         'project_name': prep_string()
     })
 
 
 # This is the function we well name in a Tableau Prep script node
 # It received data on the input, but doesn't use it
 
 def get_published_ds_used_in_flow(input):
 
     # The hardcoded Graphql query
     query = """query published_datasources_certified {
     publishedDatasources {
       name
       isCertified
       downstreamFlows {
         name,
         owner {
           name
         },
         projectName
       }
     }
   }
   """
 
     print("Logging into Tableau Server...")
     token = login()
     print("Session token is: " + token)
     print("")
     print("Running the following query:")
     print(query)
     print("")
     print("Answer below:")
 
     # here we get text
     json_string = run_query(token, query)
 
     # we parse the result as a json structure
     response_as_json = json.loads(json_string)
 
     # we print the json structure
     print(json.dumps(response_as_json, sort_keys=True, indent=4))
 
     # navigating the json structure to find the starting node we need
     list_of_published_ds = response_as_json["data"]["publishedDatasources"]
 
     # this array will contain the data we will return to Tableau Prep
     resultset = []
 
     # navigating the json structure and collecting data
     for ds in list_of_published_ds:
         for flow in ds["downstreamFlows"]:
             # when we find a downstream flow, we create one entry into the resultset
             resultset.append([ds["name"], flow["name"],
                               flow["owner"]["name"], flow["projectName"]])
 
     # print the resultset for debugging purposes
     print(resultset)
 
     # we turn this python array into a pandas dataframe
     df = pd.DataFrame(data=resultset, columns=[
                       "ds_name", "flow_name", "owner_name", "project_name"])
 
     # we return the dataframe to Tableau Prep
     return(df)
 def get_output_schema_bea97b3a58e648258274adfc99cd41f5(df = pd.DataFrame()):
     import inspect
     if len(inspect.getfullargspec(get_output_schema).args) == 0:
         return get_output_schema()
     else:
         return get_output_schema(df)
 result_schema_output = get_output_schema_bea97b3a58e648258274adfc99cd41f5(pd.DataFrame(_arg1))
 return result_schema_output.to_dict(orient='split') if isinstance(result_schema_output, pd.DataFrame) else result_schema_output

2021-01-28,13:47:53 [INFO] (web.py:web:2239): 200 POST /evaluate (172.18.0.1) 67.32ms
2021-01-28,13:47:53 [INFO] (web.py:web:2239): 200 POST /evaluate (172.18.0.1) 58.09ms
2021-01-28,13:47:58 [DEBUG] (base_handler.py:base_handler:115): Checking if need to handle authentication
2021-01-28,13:47:58 [DEBUG] (base_handler.py:base_handler:115): Handling authentication
2021-01-28,13:47:58 [INFO] (base_handler.py:base_handler:115): Authentication is not a required feature for API "v1"
2021-01-28,13:47:58 [DEBUG] (base_handler.py:base_handler:115): Checking request headers for authentication data
2021-01-28,13:47:58 [INFO] (base_handler.py:base_handler:115): Authorization header not found
2021-01-28,13:47:58 [DEBUG] (base_handler.py:base_handler:115): authentication not required, username and password are none
2021-01-28,13:47:58 [DEBUG] (state.py:state:511): Collecting Access-Control-Allow-Origin from state file ...
2021-01-28,13:47:58 [DEBUG] (state.py:state:613): Loading option 'Access-Control-Allow-Origin' from section [Service Info]...
2021-01-28,13:47:58 [DEBUG] (state.py:state:635): Returning value ''
2021-01-28,13:47:58 [DEBUG] (state.py:state:613): Loading option 'Access-Control-Allow-Headers' from section [Service Info]...
2021-01-28,13:47:58 [DEBUG] (state.py:state:635): Returning value ''
2021-01-28,13:47:58 [DEBUG] (state.py:state:613): Loading option 'Access-Control-Allow-Methods' from section [Service Info]...
2021-01-28,13:47:58 [DEBUG] (state.py:state:635): Returning value ''
2021-01-28,13:47:58 [DEBUG] (base_handler.py:base_handler:115): Processing POST request '{'data': {'_arg1': {'ds_name': ['prep_string_type']}}, 'script': 'import pandas as pd\ndef get_output_schema():\n\treturn \'5e1663ee-aeb8-40e2-9e10-d7644bc9e928\'\ndef prep_string():\n\treturn [\'prep_string_type\']\ndef prep_bool():\n\treturn [\'prep_bool_type\']\ndef prep_int():\n\treturn [\'prep_int_type\']\ndef prep_decimal():\n    return [\'prep_decimal_type\']\ndef prep_date():\n\treturn [\'prep_date_type\']\ndef prep_datetime():\n\treturn [\'prep_datetime_type\']\n# os is used to retrieve environment variables\n# requests is used to make HTTP requests out to Tableau Server\n# json is used to parse the answer received from the Tableau metadata API\n# pandas is used to build a dataframe and return data to Tableau Prep\n\nimport os\nimport requests\nimport json\nimport pandas as pd\n\n\n# login will perform a login into Tableau Server and return a session token\n# it uses the API_SERVER, API_SECRET_TOKEN and API_TOKEN_NAME environment variables\n# see docker-compose.yml for these environment variables\n\ndef login():\n    body = {"credentials": {"personalAccessTokenName": os.environ[\'API_TOKEN_NAME\'],\n                            "personalAccessTokenSecret": os.environ[\'API_SECRET_TOKEN\'],\n                            "site": {"contentUrl": ""}}}\n\n    print("Performing login")\n\n    url = "https://{server}/api/3.9/auth/signin".format(\n        server=os.environ["API_SERVER"])\n\n    headers = {\n        \'accept\': \'application/json\',\n        \'content-type\': \'application/json\'\n    }\n\n    # making the request\n    x = requests.post(url, json=body, headers=headers)\n    # parsing the login response\n    response = json.loads(x.text)\n    # if everything goes well, session token is found here:\n    token = response["credentials"]["token"]\n\n    return token\n\n# run_query runs a GRAPHQL query against the Tableau metadata API\n# arguments are a session token (obtained with login function) and the query text\n# it uses the API_SERVER environment variable to connect to the server; see docker-compose.yml\n\n\ndef run_query(token, query):\n    uri = "https://{server}/api/metadata/graphql".format(\n        server=os.environ["API_SERVER"])\n    headers = {\n        \'content-type\': \'application/json\',\n        \'accept\': \'application/json\',\n        \'X-Tableau-Auth\': token\n    }\n    x = requests.post(uri, json={\'query\': query}, headers=headers)\n\n    # we print the plain text answer for debugging purposes\n    print(x.text)\n\n    # we return the plain text answer received\n    return x.text\n\n\n# This function is called by Tableau Prep to obtain the expected schema of the data to receive\ndef get_output_schema():\n    return pd.DataFrame({\n        \'ds_name\': prep_string(),\n        \'flow_name\': prep_string(),\n        \'owner_name\': prep_string(),\n        \'project_name\': prep_string()\n    })\n\n\n# This is the function we well name in a Tableau Prep script node\n# It received data on the input, but doesn\'t use it\n\ndef get_published_ds_used_in_flow(input):\n\n    # The hardcoded Graphql query\n    query = """query published_datasources_certified {\n    publishedDatasources {\n      name\n      isCertified\n      downstreamFlows {\n        name,\n        owner {\n          name\n        },\n        projectName\n      }\n    }\n  }\n  """\n\n    print("Logging into Tableau Server...")\n    token = login()\n    print("Session token is: " + token)\n    print("")\n    print("Running the following query:")\n    print(query)\n    print("")\n    print("Answer below:")\n\n    # here we get text\n    json_string = run_query(token, query)\n\n    # we parse the result as a json structure\n    response_as_json = json.loads(json_string)\n\n    # we print the json structure\n    print(json.dumps(response_as_json, sort_keys=True, indent=4))\n\n    # navigating the json structure to find the starting node we need\n    list_of_published_ds = response_as_json["data"]["publishedDatasources"]\n\n    # this array will contain the data we will return to Tableau Prep\n    resultset = []\n\n    # navigating the json structure and collecting data\n    for ds in list_of_published_ds:\n        for flow in ds["downstreamFlows"]:\n            # when we find a downstream flow, we create one entry into the resultset\n            resultset.append([ds["name"], flow["name"],\n                              flow["owner"]["name"], flow["projectName"]])\n\n    # print the resultset for debugging purposes\n    print(resultset)\n\n    # we turn this python array into a pandas dataframe\n    df = pd.DataFrame(data=resultset, columns=[\n                      "ds_name", "flow_name", "owner_name", "project_name"])\n\n    # we return the dataframe to Tableau Prep\n    return(df)\ndef get_output_schema_bea97b3a58e648258274adfc99cd41f5(df = pd.DataFrame()):\n    import inspect\n    if len(inspect.getfullargspec(get_output_schema).args) == 0:\n        return get_output_schema()\n    else:\n        return get_output_schema(df)\nresult_schema_output = get_output_schema_bea97b3a58e648258274adfc99cd41f5(pd.DataFrame(_arg1))\nreturn result_schema_output.to_dict(orient=\'split\') if isinstance(result_schema_output, pd.DataFrame) else result_schema_output'}'...
2021-01-28,13:47:58 [INFO] (base_handler.py:base_handler:115): function to evaluate=def _user_script(tabpy, _arg1):
 import pandas as pd
 def get_output_schema():
 	return '5e1663ee-aeb8-40e2-9e10-d7644bc9e928'
 def prep_string():
 	return ['prep_string_type']
 def prep_bool():
 	return ['prep_bool_type']
 def prep_int():
 	return ['prep_int_type']
 def prep_decimal():
     return ['prep_decimal_type']
 def prep_date():
 	return ['prep_date_type']
 def prep_datetime():
 	return ['prep_datetime_type']
 # os is used to retrieve environment variables
 # requests is used to make HTTP requests out to Tableau Server
 # json is used to parse the answer received from the Tableau metadata API
 # pandas is used to build a dataframe and return data to Tableau Prep
 
 import os
 import requests
 import json
 import pandas as pd
 
 
 # login will perform a login into Tableau Server and return a session token
 # it uses the API_SERVER, API_SECRET_TOKEN and API_TOKEN_NAME environment variables
 # see docker-compose.yml for these environment variables
 
 def login():
     body = {"credentials": {"personalAccessTokenName": os.environ['API_TOKEN_NAME'],
                             "personalAccessTokenSecret": os.environ['API_SECRET_TOKEN'],
                             "site": {"contentUrl": ""}}}
 
     print("Performing login")
 
     url = "https://{server}/api/3.9/auth/signin".format(
         server=os.environ["API_SERVER"])
 
     headers = {
         'accept': 'application/json',
         'content-type': 'application/json'
     }
 
     # making the request
     x = requests.post(url, json=body, headers=headers)
     # parsing the login response
     response = json.loads(x.text)
     # if everything goes well, session token is found here:
     token = response["credentials"]["token"]
 
     return token
 
 # run_query runs a GRAPHQL query against the Tableau metadata API
 # arguments are a session token (obtained with login function) and the query text
 # it uses the API_SERVER environment variable to connect to the server; see docker-compose.yml
 
 
 def run_query(token, query):
     uri = "https://{server}/api/metadata/graphql".format(
         server=os.environ["API_SERVER"])
     headers = {
         'content-type': 'application/json',
         'accept': 'application/json',
         'X-Tableau-Auth': token
     }
     x = requests.post(uri, json={'query': query}, headers=headers)
 
     # we print the plain text answer for debugging purposes
     print(x.text)
 
     # we return the plain text answer received
     return x.text
 
 
 # This function is called by Tableau Prep to obtain the expected schema of the data to receive
 def get_output_schema():
     return pd.DataFrame({
         'ds_name': prep_string(),
         'flow_name': prep_string(),
         'owner_name': prep_string(),
         'project_name': prep_string()
     })
 
 
 # This is the function we well name in a Tableau Prep script node
 # It received data on the input, but doesn't use it
 
 def get_published_ds_used_in_flow(input):
 
     # The hardcoded Graphql query
     query = """query published_datasources_certified {
     publishedDatasources {
       name
       isCertified
       downstreamFlows {
         name,
         owner {
           name
         },
         projectName
       }
     }
   }
   """
 
     print("Logging into Tableau Server...")
     token = login()
     print("Session token is: " + token)
     print("")
     print("Running the following query:")
     print(query)
     print("")
     print("Answer below:")
 
     # here we get text
     json_string = run_query(token, query)
 
     # we parse the result as a json structure
     response_as_json = json.loads(json_string)
 
     # we print the json structure
     print(json.dumps(response_as_json, sort_keys=True, indent=4))
 
     # navigating the json structure to find the starting node we need
     list_of_published_ds = response_as_json["data"]["publishedDatasources"]
 
     # this array will contain the data we will return to Tableau Prep
     resultset = []
 
     # navigating the json structure and collecting data
     for ds in list_of_published_ds:
         for flow in ds["downstreamFlows"]:
             # when we find a downstream flow, we create one entry into the resultset
             resultset.append([ds["name"], flow["name"],
                               flow["owner"]["name"], flow["projectName"]])
 
     # print the resultset for debugging purposes
     print(resultset)
 
     # we turn this python array into a pandas dataframe
     df = pd.DataFrame(data=resultset, columns=[
                       "ds_name", "flow_name", "owner_name", "project_name"])
 
     # we return the dataframe to Tableau Prep
     return(df)
 def get_output_schema_bea97b3a58e648258274adfc99cd41f5(df = pd.DataFrame()):
     import inspect
     if len(inspect.getfullargspec(get_output_schema).args) == 0:
         return get_output_schema()
     else:
         return get_output_schema(df)
 result_schema_output = get_output_schema_bea97b3a58e648258274adfc99cd41f5(pd.DataFrame(_arg1))
 return result_schema_output.to_dict(orient='split') if isinstance(result_schema_output, pd.DataFrame) else result_schema_output

2021-01-28,13:47:58 [DEBUG] (base_handler.py:base_handler:115): Checking if need to handle authentication
2021-01-28,13:47:58 [DEBUG] (base_handler.py:base_handler:115): Handling authentication
2021-01-28,13:47:58 [INFO] (base_handler.py:base_handler:115): Authentication is not a required feature for API "v1"
2021-01-28,13:47:58 [DEBUG] (base_handler.py:base_handler:115): Checking request headers for authentication data
2021-01-28,13:47:58 [INFO] (base_handler.py:base_handler:115): Authorization header not found
2021-01-28,13:47:58 [DEBUG] (base_handler.py:base_handler:115): authentication not required, username and password are none
2021-01-28,13:47:58 [DEBUG] (state.py:state:511): Collecting Access-Control-Allow-Origin from state file ...
2021-01-28,13:47:58 [DEBUG] (state.py:state:613): Loading option 'Access-Control-Allow-Origin' from section [Service Info]...
2021-01-28,13:47:58 [DEBUG] (state.py:state:635): Returning value ''
2021-01-28,13:47:58 [DEBUG] (state.py:state:613): Loading option 'Access-Control-Allow-Headers' from section [Service Info]...
2021-01-28,13:47:58 [DEBUG] (state.py:state:635): Returning value ''
2021-01-28,13:47:58 [DEBUG] (state.py:state:613): Loading option 'Access-Control-Allow-Methods' from section [Service Info]...
2021-01-28,13:47:58 [DEBUG] (state.py:state:635): Returning value ''
2021-01-28,13:47:58 [DEBUG] (base_handler.py:base_handler:115): Processing POST request '{'data': {'_arg1': {'ds_name': ['prep_string_type']}}, 'script': 'import pandas as pd\ndef get_output_schema():\n\treturn \'5e1663ee-aeb8-40e2-9e10-d7644bc9e928\'\ndef prep_string():\n\treturn [\'prep_string_type\']\ndef prep_bool():\n\treturn [\'prep_bool_type\']\ndef prep_int():\n\treturn [\'prep_int_type\']\ndef prep_decimal():\n    return [\'prep_decimal_type\']\ndef prep_date():\n\treturn [\'prep_date_type\']\ndef prep_datetime():\n\treturn [\'prep_datetime_type\']\n# os is used to retrieve environment variables\n# requests is used to make HTTP requests out to Tableau Server\n# json is used to parse the answer received from the Tableau metadata API\n# pandas is used to build a dataframe and return data to Tableau Prep\n\nimport os\nimport requests\nimport json\nimport pandas as pd\n\n\n# login will perform a login into Tableau Server and return a session token\n# it uses the API_SERVER, API_SECRET_TOKEN and API_TOKEN_NAME environment variables\n# see docker-compose.yml for these environment variables\n\ndef login():\n    body = {"credentials": {"personalAccessTokenName": os.environ[\'API_TOKEN_NAME\'],\n                            "personalAccessTokenSecret": os.environ[\'API_SECRET_TOKEN\'],\n                            "site": {"contentUrl": ""}}}\n\n    print("Performing login")\n\n    url = "https://{server}/api/3.9/auth/signin".format(\n        server=os.environ["API_SERVER"])\n\n    headers = {\n        \'accept\': \'application/json\',\n        \'content-type\': \'application/json\'\n    }\n\n    # making the request\n    x = requests.post(url, json=body, headers=headers)\n    # parsing the login response\n    response = json.loads(x.text)\n    # if everything goes well, session token is found here:\n    token = response["credentials"]["token"]\n\n    return token\n\n# run_query runs a GRAPHQL query against the Tableau metadata API\n# arguments are a session token (obtained with login function) and the query text\n# it uses the API_SERVER environment variable to connect to the server; see docker-compose.yml\n\n\ndef run_query(token, query):\n    uri = "https://{server}/api/metadata/graphql".format(\n        server=os.environ["API_SERVER"])\n    headers = {\n        \'content-type\': \'application/json\',\n        \'accept\': \'application/json\',\n        \'X-Tableau-Auth\': token\n    }\n    x = requests.post(uri, json={\'query\': query}, headers=headers)\n\n    # we print the plain text answer for debugging purposes\n    print(x.text)\n\n    # we return the plain text answer received\n    return x.text\n\n\n# This function is called by Tableau Prep to obtain the expected schema of the data to receive\ndef get_output_schema():\n    return pd.DataFrame({\n        \'ds_name\': prep_string(),\n        \'flow_name\': prep_string(),\n        \'owner_name\': prep_string(),\n        \'project_name\': prep_string()\n    })\n\n\n# This is the function we well name in a Tableau Prep script node\n# It received data on the input, but doesn\'t use it\n\ndef get_published_ds_used_in_flow(input):\n\n    # The hardcoded Graphql query\n    query = """query published_datasources_certified {\n    publishedDatasources {\n      name\n      isCertified\n      downstreamFlows {\n        name,\n        owner {\n          name\n        },\n        projectName\n      }\n    }\n  }\n  """\n\n    print("Logging into Tableau Server...")\n    token = login()\n    print("Session token is: " + token)\n    print("")\n    print("Running the following query:")\n    print(query)\n    print("")\n    print("Answer below:")\n\n    # here we get text\n    json_string = run_query(token, query)\n\n    # we parse the result as a json structure\n    response_as_json = json.loads(json_string)\n\n    # we print the json structure\n    print(json.dumps(response_as_json, sort_keys=True, indent=4))\n\n    # navigating the json structure to find the starting node we need\n    list_of_published_ds = response_as_json["data"]["publishedDatasources"]\n\n    # this array will contain the data we will return to Tableau Prep\n    resultset = []\n\n    # navigating the json structure and collecting data\n    for ds in list_of_published_ds:\n        for flow in ds["downstreamFlows"]:\n            # when we find a downstream flow, we create one entry into the resultset\n            resultset.append([ds["name"], flow["name"],\n                              flow["owner"]["name"], flow["projectName"]])\n\n    # print the resultset for debugging purposes\n    print(resultset)\n\n    # we turn this python array into a pandas dataframe\n    df = pd.DataFrame(data=resultset, columns=[\n                      "ds_name", "flow_name", "owner_name", "project_name"])\n\n    # we return the dataframe to Tableau Prep\n    return(df)\ndef get_output_schema_bea97b3a58e648258274adfc99cd41f5(df = pd.DataFrame()):\n    import inspect\n    if len(inspect.getfullargspec(get_output_schema).args) == 0:\n        return get_output_schema()\n    else:\n        return get_output_schema(df)\nresult_schema_output = get_output_schema_bea97b3a58e648258274adfc99cd41f5(pd.DataFrame(_arg1))\nreturn result_schema_output.to_dict(orient=\'split\') if isinstance(result_schema_output, pd.DataFrame) else result_schema_output'}'...
2021-01-28,13:47:58 [INFO] (base_handler.py:base_handler:115): function to evaluate=def _user_script(tabpy, _arg1):
 import pandas as pd
 def get_output_schema():
 	return '5e1663ee-aeb8-40e2-9e10-d7644bc9e928'
 def prep_string():
 	return ['prep_string_type']
 def prep_bool():
 	return ['prep_bool_type']
 def prep_int():
 	return ['prep_int_type']
 def prep_decimal():
     return ['prep_decimal_type']
 def prep_date():
 	return ['prep_date_type']
 def prep_datetime():
 	return ['prep_datetime_type']
 # os is used to retrieve environment variables
 # requests is used to make HTTP requests out to Tableau Server
 # json is used to parse the answer received from the Tableau metadata API
 # pandas is used to build a dataframe and return data to Tableau Prep
 
 import os
 import requests
 import json
 import pandas as pd
 
 
 # login will perform a login into Tableau Server and return a session token
 # it uses the API_SERVER, API_SECRET_TOKEN and API_TOKEN_NAME environment variables
 # see docker-compose.yml for these environment variables
 
 def login():
     body = {"credentials": {"personalAccessTokenName": os.environ['API_TOKEN_NAME'],
                             "personalAccessTokenSecret": os.environ['API_SECRET_TOKEN'],
                             "site": {"contentUrl": ""}}}
 
     print("Performing login")
 
     url = "https://{server}/api/3.9/auth/signin".format(
         server=os.environ["API_SERVER"])
 
     headers = {
         'accept': 'application/json',
         'content-type': 'application/json'
     }
 
     # making the request
     x = requests.post(url, json=body, headers=headers)
     # parsing the login response
     response = json.loads(x.text)
     # if everything goes well, session token is found here:
     token = response["credentials"]["token"]
 
     return token
 
 # run_query runs a GRAPHQL query against the Tableau metadata API
 # arguments are a session token (obtained with login function) and the query text
 # it uses the API_SERVER environment variable to connect to the server; see docker-compose.yml
 
 
 def run_query(token, query):
     uri = "https://{server}/api/metadata/graphql".format(
         server=os.environ["API_SERVER"])
     headers = {
         'content-type': 'application/json',
         'accept': 'application/json',
         'X-Tableau-Auth': token
     }
     x = requests.post(uri, json={'query': query}, headers=headers)
 
     # we print the plain text answer for debugging purposes
     print(x.text)
 
     # we return the plain text answer received
     return x.text
 
 
 # This function is called by Tableau Prep to obtain the expected schema of the data to receive
 def get_output_schema():
     return pd.DataFrame({
         'ds_name': prep_string(),
         'flow_name': prep_string(),
         'owner_name': prep_string(),
         'project_name': prep_string()
     })
 
 
 # This is the function we well name in a Tableau Prep script node
 # It received data on the input, but doesn't use it
 
 def get_published_ds_used_in_flow(input):
 
     # The hardcoded Graphql query
     query = """query published_datasources_certified {
     publishedDatasources {
       name
       isCertified
       downstreamFlows {
         name,
         owner {
           name
         },
         projectName
       }
     }
   }
   """
 
     print("Logging into Tableau Server...")
     token = login()
     print("Session token is: " + token)
     print("")
     print("Running the following query:")
     print(query)
     print("")
     print("Answer below:")
 
     # here we get text
     json_string = run_query(token, query)
 
     # we parse the result as a json structure
     response_as_json = json.loads(json_string)
 
     # we print the json structure
     print(json.dumps(response_as_json, sort_keys=True, indent=4))
 
     # navigating the json structure to find the starting node we need
     list_of_published_ds = response_as_json["data"]["publishedDatasources"]
 
     # this array will contain the data we will return to Tableau Prep
     resultset = []
 
     # navigating the json structure and collecting data
     for ds in list_of_published_ds:
         for flow in ds["downstreamFlows"]:
             # when we find a downstream flow, we create one entry into the resultset
             resultset.append([ds["name"], flow["name"],
                               flow["owner"]["name"], flow["projectName"]])
 
     # print the resultset for debugging purposes
     print(resultset)
 
     # we turn this python array into a pandas dataframe
     df = pd.DataFrame(data=resultset, columns=[
                       "ds_name", "flow_name", "owner_name", "project_name"])
 
     # we return the dataframe to Tableau Prep
     return(df)
 def get_output_schema_bea97b3a58e648258274adfc99cd41f5(df = pd.DataFrame()):
     import inspect
     if len(inspect.getfullargspec(get_output_schema).args) == 0:
         return get_output_schema()
     else:
         return get_output_schema(df)
 result_schema_output = get_output_schema_bea97b3a58e648258274adfc99cd41f5(pd.DataFrame(_arg1))
 return result_schema_output.to_dict(orient='split') if isinstance(result_schema_output, pd.DataFrame) else result_schema_output

2021-01-28,13:47:58 [INFO] (web.py:web:2239): 200 POST /evaluate (172.18.0.1) 60.40ms
2021-01-28,13:47:58 [DEBUG] (base_handler.py:base_handler:115): Checking if need to handle authentication
2021-01-28,13:47:58 [DEBUG] (base_handler.py:base_handler:115): Handling authentication
2021-01-28,13:47:58 [INFO] (base_handler.py:base_handler:115): Authentication is not a required feature for API "v1"
2021-01-28,13:47:58 [DEBUG] (base_handler.py:base_handler:115): Checking request headers for authentication data
2021-01-28,13:47:58 [INFO] (base_handler.py:base_handler:115): Authorization header not found
2021-01-28,13:47:58 [DEBUG] (base_handler.py:base_handler:115): authentication not required, username and password are none
2021-01-28,13:47:58 [INFO] (web.py:web:2239): 200 POST /evaluate (172.18.0.1) 37.39ms
2021-01-28,13:47:58 [DEBUG] (state.py:state:511): Collecting Access-Control-Allow-Origin from state file ...
2021-01-28,13:47:58 [DEBUG] (state.py:state:613): Loading option 'Access-Control-Allow-Origin' from section [Service Info]...
2021-01-28,13:47:58 [DEBUG] (state.py:state:635): Returning value ''
2021-01-28,13:47:58 [DEBUG] (state.py:state:613): Loading option 'Access-Control-Allow-Headers' from section [Service Info]...
2021-01-28,13:47:58 [DEBUG] (state.py:state:635): Returning value ''
2021-01-28,13:47:58 [DEBUG] (state.py:state:613): Loading option 'Access-Control-Allow-Methods' from section [Service Info]...
2021-01-28,13:47:58 [DEBUG] (state.py:state:635): Returning value ''
2021-01-28,13:47:58 [DEBUG] (base_handler.py:base_handler:115): Processing POST request '{'data': {'_arg1': {'ds_name': ['prep_string_type']}}, 'script': 'import pandas as pd\ndef get_output_schema():\n\treturn \'5e1663ee-aeb8-40e2-9e10-d7644bc9e928\'\ndef prep_string():\n\treturn [\'prep_string_type\']\ndef prep_bool():\n\treturn [\'prep_bool_type\']\ndef prep_int():\n\treturn [\'prep_int_type\']\ndef prep_decimal():\n    return [\'prep_decimal_type\']\ndef prep_date():\n\treturn [\'prep_date_type\']\ndef prep_datetime():\n\treturn [\'prep_datetime_type\']\n# os is used to retrieve environment variables\n# requests is used to make HTTP requests out to Tableau Server\n# json is used to parse the answer received from the Tableau metadata API\n# pandas is used to build a dataframe and return data to Tableau Prep\n\nimport os\nimport requests\nimport json\nimport pandas as pd\n\n\n# login will perform a login into Tableau Server and return a session token\n# it uses the API_SERVER, API_SECRET_TOKEN and API_TOKEN_NAME environment variables\n# see docker-compose.yml for these environment variables\n\ndef login():\n    body = {"credentials": {"personalAccessTokenName": os.environ[\'API_TOKEN_NAME\'],\n                            "personalAccessTokenSecret": os.environ[\'API_SECRET_TOKEN\'],\n                            "site": {"contentUrl": ""}}}\n\n    print("Performing login")\n\n    url = "https://{server}/api/3.9/auth/signin".format(\n        server=os.environ["API_SERVER"])\n\n    headers = {\n        \'accept\': \'application/json\',\n        \'content-type\': \'application/json\'\n    }\n\n    # making the request\n    x = requests.post(url, json=body, headers=headers)\n    # parsing the login response\n    response = json.loads(x.text)\n    # if everything goes well, session token is found here:\n    token = response["credentials"]["token"]\n\n    return token\n\n# run_query runs a GRAPHQL query against the Tableau metadata API\n# arguments are a session token (obtained with login function) and the query text\n# it uses the API_SERVER environment variable to connect to the server; see docker-compose.yml\n\n\ndef run_query(token, query):\n    uri = "https://{server}/api/metadata/graphql".format(\n        server=os.environ["API_SERVER"])\n    headers = {\n        \'content-type\': \'application/json\',\n        \'accept\': \'application/json\',\n        \'X-Tableau-Auth\': token\n    }\n    x = requests.post(uri, json={\'query\': query}, headers=headers)\n\n    # we print the plain text answer for debugging purposes\n    print(x.text)\n\n    # we return the plain text answer received\n    return x.text\n\n\n# This function is called by Tableau Prep to obtain the expected schema of the data to receive\ndef get_output_schema():\n    return pd.DataFrame({\n        \'ds_name\': prep_string(),\n        \'flow_name\': prep_string(),\n        \'owner_name\': prep_string(),\n        \'project_name\': prep_string()\n    })\n\n\n# This is the function we well name in a Tableau Prep script node\n# It received data on the input, but doesn\'t use it\n\ndef get_published_ds_used_in_flow(input):\n\n    # The hardcoded Graphql query\n    query = """query published_datasources_certified {\n    publishedDatasources {\n      name\n      isCertified\n      downstreamFlows {\n        name,\n        owner {\n          name\n        },\n        projectName\n      }\n    }\n  }\n  """\n\n    print("Logging into Tableau Server...")\n    token = login()\n    print("Session token is: " + token)\n    print("")\n    print("Running the following query:")\n    print(query)\n    print("")\n    print("Answer below:")\n\n    # here we get text\n    json_string = run_query(token, query)\n\n    # we parse the result as a json structure\n    response_as_json = json.loads(json_string)\n\n    # we print the json structure\n    print(json.dumps(response_as_json, sort_keys=True, indent=4))\n\n    # navigating the json structure to find the starting node we need\n    list_of_published_ds = response_as_json["data"]["publishedDatasources"]\n\n    # this array will contain the data we will return to Tableau Prep\n    resultset = []\n\n    # navigating the json structure and collecting data\n    for ds in list_of_published_ds:\n        for flow in ds["downstreamFlows"]:\n            # when we find a downstream flow, we create one entry into the resultset\n            resultset.append([ds["name"], flow["name"],\n                              flow["owner"]["name"], flow["projectName"]])\n\n    # print the resultset for debugging purposes\n    print(resultset)\n\n    # we turn this python array into a pandas dataframe\n    df = pd.DataFrame(data=resultset, columns=[\n                      "ds_name", "flow_name", "owner_name", "project_name"])\n\n    # we return the dataframe to Tableau Prep\n    return(df)\ndef get_output_schema_bea97b3a58e648258274adfc99cd41f5(df = pd.DataFrame()):\n    import inspect\n    if len(inspect.getfullargspec(get_output_schema).args) == 0:\n        return get_output_schema()\n    else:\n        return get_output_schema(df)\nresult_schema_output = get_output_schema_bea97b3a58e648258274adfc99cd41f5(pd.DataFrame(_arg1))\nreturn result_schema_output.to_dict(orient=\'split\') if isinstance(result_schema_output, pd.DataFrame) else result_schema_output'}'...
2021-01-28,13:47:58 [INFO] (base_handler.py:base_handler:115): function to evaluate=def _user_script(tabpy, _arg1):
 import pandas as pd
 def get_output_schema():
 	return '5e1663ee-aeb8-40e2-9e10-d7644bc9e928'
 def prep_string():
 	return ['prep_string_type']
 def prep_bool():
 	return ['prep_bool_type']
 def prep_int():
 	return ['prep_int_type']
 def prep_decimal():
     return ['prep_decimal_type']
 def prep_date():
 	return ['prep_date_type']
 def prep_datetime():
 	return ['prep_datetime_type']
 # os is used to retrieve environment variables
 # requests is used to make HTTP requests out to Tableau Server
 # json is used to parse the answer received from the Tableau metadata API
 # pandas is used to build a dataframe and return data to Tableau Prep
 
 import os
 import requests
 import json
 import pandas as pd
 
 
 # login will perform a login into Tableau Server and return a session token
 # it uses the API_SERVER, API_SECRET_TOKEN and API_TOKEN_NAME environment variables
 # see docker-compose.yml for these environment variables
 
 def login():
     body = {"credentials": {"personalAccessTokenName": os.environ['API_TOKEN_NAME'],
                             "personalAccessTokenSecret": os.environ['API_SECRET_TOKEN'],
                             "site": {"contentUrl": ""}}}
 
     print("Performing login")
 
     url = "https://{server}/api/3.9/auth/signin".format(
         server=os.environ["API_SERVER"])
 
     headers = {
         'accept': 'application/json',
         'content-type': 'application/json'
     }
 
     # making the request
     x = requests.post(url, json=body, headers=headers)
     # parsing the login response
     response = json.loads(x.text)
     # if everything goes well, session token is found here:
     token = response["credentials"]["token"]
 
     return token
 
 # run_query runs a GRAPHQL query against the Tableau metadata API
 # arguments are a session token (obtained with login function) and the query text
 # it uses the API_SERVER environment variable to connect to the server; see docker-compose.yml
 
 
 def run_query(token, query):
     uri = "https://{server}/api/metadata/graphql".format(
         server=os.environ["API_SERVER"])
     headers = {
         'content-type': 'application/json',
         'accept': 'application/json',
         'X-Tableau-Auth': token
     }
     x = requests.post(uri, json={'query': query}, headers=headers)
 
     # we print the plain text answer for debugging purposes
     print(x.text)
 
     # we return the plain text answer received
     return x.text
 
 
 # This function is called by Tableau Prep to obtain the expected schema of the data to receive
 def get_output_schema():
     return pd.DataFrame({
         'ds_name': prep_string(),
         'flow_name': prep_string(),
         'owner_name': prep_string(),
         'project_name': prep_string()
     })
 
 
 # This is the function we well name in a Tableau Prep script node
 # It received data on the input, but doesn't use it
 
 def get_published_ds_used_in_flow(input):
 
     # The hardcoded Graphql query
     query = """query published_datasources_certified {
     publishedDatasources {
       name
       isCertified
       downstreamFlows {
         name,
         owner {
           name
         },
         projectName
       }
     }
   }
   """
 
     print("Logging into Tableau Server...")
     token = login()
     print("Session token is: " + token)
     print("")
     print("Running the following query:")
     print(query)
     print("")
     print("Answer below:")
 
     # here we get text
     json_string = run_query(token, query)
 
     # we parse the result as a json structure
     response_as_json = json.loads(json_string)
 
     # we print the json structure
     print(json.dumps(response_as_json, sort_keys=True, indent=4))
 
     # navigating the json structure to find the starting node we need
     list_of_published_ds = response_as_json["data"]["publishedDatasources"]
 
     # this array will contain the data we will return to Tableau Prep
     resultset = []
 
     # navigating the json structure and collecting data
     for ds in list_of_published_ds:
         for flow in ds["downstreamFlows"]:
             # when we find a downstream flow, we create one entry into the resultset
             resultset.append([ds["name"], flow["name"],
                               flow["owner"]["name"], flow["projectName"]])
 
     # print the resultset for debugging purposes
     print(resultset)
 
     # we turn this python array into a pandas dataframe
     df = pd.DataFrame(data=resultset, columns=[
                       "ds_name", "flow_name", "owner_name", "project_name"])
 
     # we return the dataframe to Tableau Prep
     return(df)
 def get_output_schema_bea97b3a58e648258274adfc99cd41f5(df = pd.DataFrame()):
     import inspect
     if len(inspect.getfullargspec(get_output_schema).args) == 0:
         return get_output_schema()
     else:
         return get_output_schema(df)
 result_schema_output = get_output_schema_bea97b3a58e648258274adfc99cd41f5(pd.DataFrame(_arg1))
 return result_schema_output.to_dict(orient='split') if isinstance(result_schema_output, pd.DataFrame) else result_schema_output

2021-01-28,13:47:58 [DEBUG] (base_handler.py:base_handler:115): Checking if need to handle authentication
2021-01-28,13:47:58 [DEBUG] (base_handler.py:base_handler:115): Handling authentication
2021-01-28,13:47:58 [INFO] (base_handler.py:base_handler:115): Authentication is not a required feature for API "v1"
2021-01-28,13:47:58 [DEBUG] (base_handler.py:base_handler:115): Checking request headers for authentication data
2021-01-28,13:47:58 [INFO] (base_handler.py:base_handler:115): Authorization header not found
2021-01-28,13:47:58 [DEBUG] (base_handler.py:base_handler:115): authentication not required, username and password are none
2021-01-28,13:47:58 [DEBUG] (state.py:state:511): Collecting Access-Control-Allow-Origin from state file ...
2021-01-28,13:47:58 [DEBUG] (state.py:state:613): Loading option 'Access-Control-Allow-Origin' from section [Service Info]...
2021-01-28,13:47:58 [DEBUG] (state.py:state:635): Returning value ''
2021-01-28,13:47:58 [DEBUG] (state.py:state:613): Loading option 'Access-Control-Allow-Headers' from section [Service Info]...
2021-01-28,13:47:58 [DEBUG] (state.py:state:635): Returning value ''
2021-01-28,13:47:58 [DEBUG] (state.py:state:613): Loading option 'Access-Control-Allow-Methods' from section [Service Info]...
2021-01-28,13:47:58 [DEBUG] (state.py:state:635): Returning value ''
2021-01-28,13:47:58 [DEBUG] (base_handler.py:base_handler:115): Processing POST request '{'data': {'_arg1': {'ds_name': ['prep_string_type']}}, 'script': 'import pandas as pd\ndef get_output_schema():\n\treturn \'5e1663ee-aeb8-40e2-9e10-d7644bc9e928\'\ndef prep_string():\n\treturn [\'prep_string_type\']\ndef prep_bool():\n\treturn [\'prep_bool_type\']\ndef prep_int():\n\treturn [\'prep_int_type\']\ndef prep_decimal():\n    return [\'prep_decimal_type\']\ndef prep_date():\n\treturn [\'prep_date_type\']\ndef prep_datetime():\n\treturn [\'prep_datetime_type\']\n# os is used to retrieve environment variables\n# requests is used to make HTTP requests out to Tableau Server\n# json is used to parse the answer received from the Tableau metadata API\n# pandas is used to build a dataframe and return data to Tableau Prep\n\nimport os\nimport requests\nimport json\nimport pandas as pd\n\n\n# login will perform a login into Tableau Server and return a session token\n# it uses the API_SERVER, API_SECRET_TOKEN and API_TOKEN_NAME environment variables\n# see docker-compose.yml for these environment variables\n\ndef login():\n    body = {"credentials": {"personalAccessTokenName": os.environ[\'API_TOKEN_NAME\'],\n                            "personalAccessTokenSecret": os.environ[\'API_SECRET_TOKEN\'],\n                            "site": {"contentUrl": ""}}}\n\n    print("Performing login")\n\n    url = "https://{server}/api/3.9/auth/signin".format(\n        server=os.environ["API_SERVER"])\n\n    headers = {\n        \'accept\': \'application/json\',\n        \'content-type\': \'application/json\'\n    }\n\n    # making the request\n    x = requests.post(url, json=body, headers=headers)\n    # parsing the login response\n    response = json.loads(x.text)\n    # if everything goes well, session token is found here:\n    token = response["credentials"]["token"]\n\n    return token\n\n# run_query runs a GRAPHQL query against the Tableau metadata API\n# arguments are a session token (obtained with login function) and the query text\n# it uses the API_SERVER environment variable to connect to the server; see docker-compose.yml\n\n\ndef run_query(token, query):\n    uri = "https://{server}/api/metadata/graphql".format(\n        server=os.environ["API_SERVER"])\n    headers = {\n        \'content-type\': \'application/json\',\n        \'accept\': \'application/json\',\n        \'X-Tableau-Auth\': token\n    }\n    x = requests.post(uri, json={\'query\': query}, headers=headers)\n\n    # we print the plain text answer for debugging purposes\n    print(x.text)\n\n    # we return the plain text answer received\n    return x.text\n\n\n# This function is called by Tableau Prep to obtain the expected schema of the data to receive\ndef get_output_schema():\n    return pd.DataFrame({\n        \'ds_name\': prep_string(),\n        \'flow_name\': prep_string(),\n        \'owner_name\': prep_string(),\n        \'project_name\': prep_string()\n    })\n\n\n# This is the function we well name in a Tableau Prep script node\n# It received data on the input, but doesn\'t use it\n\ndef get_published_ds_used_in_flow(input):\n\n    # The hardcoded Graphql query\n    query = """query published_datasources_certified {\n    publishedDatasources {\n      name\n      isCertified\n      downstreamFlows {\n        name,\n        owner {\n          name\n        },\n        projectName\n      }\n    }\n  }\n  """\n\n    print("Logging into Tableau Server...")\n    token = login()\n    print("Session token is: " + token)\n    print("")\n    print("Running the following query:")\n    print(query)\n    print("")\n    print("Answer below:")\n\n    # here we get text\n    json_string = run_query(token, query)\n\n    # we parse the result as a json structure\n    response_as_json = json.loads(json_string)\n\n    # we print the json structure\n    print(json.dumps(response_as_json, sort_keys=True, indent=4))\n\n    # navigating the json structure to find the starting node we need\n    list_of_published_ds = response_as_json["data"]["publishedDatasources"]\n\n    # this array will contain the data we will return to Tableau Prep\n    resultset = []\n\n    # navigating the json structure and collecting data\n    for ds in list_of_published_ds:\n        for flow in ds["downstreamFlows"]:\n            # when we find a downstream flow, we create one entry into the resultset\n            resultset.append([ds["name"], flow["name"],\n                              flow["owner"]["name"], flow["projectName"]])\n\n    # print the resultset for debugging purposes\n    print(resultset)\n\n    # we turn this python array into a pandas dataframe\n    df = pd.DataFrame(data=resultset, columns=[\n                      "ds_name", "flow_name", "owner_name", "project_name"])\n\n    # we return the dataframe to Tableau Prep\n    return(df)\ndef get_output_schema_bea97b3a58e648258274adfc99cd41f5(df = pd.DataFrame()):\n    import inspect\n    if len(inspect.getfullargspec(get_output_schema).args) == 0:\n        return get_output_schema()\n    else:\n        return get_output_schema(df)\nresult_schema_output = get_output_schema_bea97b3a58e648258274adfc99cd41f5(pd.DataFrame(_arg1))\nreturn result_schema_output.to_dict(orient=\'split\') if isinstance(result_schema_output, pd.DataFrame) else result_schema_output'}'...
2021-01-28,13:47:58 [INFO] (base_handler.py:base_handler:115): function to evaluate=def _user_script(tabpy, _arg1):
 import pandas as pd
 def get_output_schema():
 	return '5e1663ee-aeb8-40e2-9e10-d7644bc9e928'
 def prep_string():
 	return ['prep_string_type']
 def prep_bool():
 	return ['prep_bool_type']
 def prep_int():
 	return ['prep_int_type']
 def prep_decimal():
     return ['prep_decimal_type']
 def prep_date():
 	return ['prep_date_type']
 def prep_datetime():
 	return ['prep_datetime_type']
 # os is used to retrieve environment variables
 # requests is used to make HTTP requests out to Tableau Server
 # json is used to parse the answer received from the Tableau metadata API
 # pandas is used to build a dataframe and return data to Tableau Prep
 
 import os
 import requests
 import json
 import pandas as pd
 
 
 # login will perform a login into Tableau Server and return a session token
 # it uses the API_SERVER, API_SECRET_TOKEN and API_TOKEN_NAME environment variables
 # see docker-compose.yml for these environment variables
 
 def login():
     body = {"credentials": {"personalAccessTokenName": os.environ['API_TOKEN_NAME'],
                             "personalAccessTokenSecret": os.environ['API_SECRET_TOKEN'],
                             "site": {"contentUrl": ""}}}
 
     print("Performing login")
 
     url = "https://{server}/api/3.9/auth/signin".format(
         server=os.environ["API_SERVER"])
 
     headers = {
         'accept': 'application/json',
         'content-type': 'application/json'
     }
 
     # making the request
     x = requests.post(url, json=body, headers=headers)
     # parsing the login response
     response = json.loads(x.text)
     # if everything goes well, session token is found here:
     token = response["credentials"]["token"]
 
     return token
 
 # run_query runs a GRAPHQL query against the Tableau metadata API
 # arguments are a session token (obtained with login function) and the query text
 # it uses the API_SERVER environment variable to connect to the server; see docker-compose.yml
 
 
 def run_query(token, query):
     uri = "https://{server}/api/metadata/graphql".format(
         server=os.environ["API_SERVER"])
     headers = {
         'content-type': 'application/json',
         'accept': 'application/json',
         'X-Tableau-Auth': token
     }
     x = requests.post(uri, json={'query': query}, headers=headers)
 
     # we print the plain text answer for debugging purposes
     print(x.text)
 
     # we return the plain text answer received
     return x.text
 
 
 # This function is called by Tableau Prep to obtain the expected schema of the data to receive
 def get_output_schema():
     return pd.DataFrame({
         'ds_name': prep_string(),
         'flow_name': prep_string(),
         'owner_name': prep_string(),
         'project_name': prep_string()
     })
 
 
 # This is the function we well name in a Tableau Prep script node
 # It received data on the input, but doesn't use it
 
 def get_published_ds_used_in_flow(input):
 
     # The hardcoded Graphql query
     query = """query published_datasources_certified {
     publishedDatasources {
       name
       isCertified
       downstreamFlows {
         name,
         owner {
           name
         },
         projectName
       }
     }
   }
   """
 
     print("Logging into Tableau Server...")
     token = login()
     print("Session token is: " + token)
     print("")
     print("Running the following query:")
     print(query)
     print("")
     print("Answer below:")
 
     # here we get text
     json_string = run_query(token, query)
 
     # we parse the result as a json structure
     response_as_json = json.loads(json_string)
 
     # we print the json structure
     print(json.dumps(response_as_json, sort_keys=True, indent=4))
 
     # navigating the json structure to find the starting node we need
     list_of_published_ds = response_as_json["data"]["publishedDatasources"]
 
     # this array will contain the data we will return to Tableau Prep
     resultset = []
 
     # navigating the json structure and collecting data
     for ds in list_of_published_ds:
         for flow in ds["downstreamFlows"]:
             # when we find a downstream flow, we create one entry into the resultset
             resultset.append([ds["name"], flow["name"],
                               flow["owner"]["name"], flow["projectName"]])
 
     # print the resultset for debugging purposes
     print(resultset)
 
     # we turn this python array into a pandas dataframe
     df = pd.DataFrame(data=resultset, columns=[
                       "ds_name", "flow_name", "owner_name", "project_name"])
 
     # we return the dataframe to Tableau Prep
     return(df)
 def get_output_schema_bea97b3a58e648258274adfc99cd41f5(df = pd.DataFrame()):
     import inspect
     if len(inspect.getfullargspec(get_output_schema).args) == 0:
         return get_output_schema()
     else:
         return get_output_schema(df)
 result_schema_output = get_output_schema_bea97b3a58e648258274adfc99cd41f5(pd.DataFrame(_arg1))
 return result_schema_output.to_dict(orient='split') if isinstance(result_schema_output, pd.DataFrame) else result_schema_output

2021-01-28,13:47:58 [INFO] (web.py:web:2239): 200 POST /evaluate (172.18.0.1) 49.56ms
2021-01-28,13:47:58 [INFO] (web.py:web:2239): 200 POST /evaluate (172.18.0.1) 25.74ms
2021-01-28,13:48:03 [DEBUG] (base_handler.py:base_handler:115): Checking if need to handle authentication
2021-01-28,13:48:03 [DEBUG] (base_handler.py:base_handler:115): Handling authentication
2021-01-28,13:48:03 [INFO] (base_handler.py:base_handler:115): Authentication is not a required feature for API "v1"
2021-01-28,13:48:03 [DEBUG] (base_handler.py:base_handler:115): Checking request headers for authentication data
2021-01-28,13:48:03 [INFO] (base_handler.py:base_handler:115): Authorization header not found
2021-01-28,13:48:03 [DEBUG] (base_handler.py:base_handler:115): authentication not required, username and password are none
2021-01-28,13:48:03 [DEBUG] (state.py:state:511): Collecting Access-Control-Allow-Origin from state file ...
2021-01-28,13:48:03 [DEBUG] (state.py:state:613): Loading option 'Access-Control-Allow-Origin' from section [Service Info]...
2021-01-28,13:48:03 [DEBUG] (state.py:state:635): Returning value ''
2021-01-28,13:48:03 [DEBUG] (state.py:state:613): Loading option 'Access-Control-Allow-Headers' from section [Service Info]...
2021-01-28,13:48:03 [DEBUG] (state.py:state:635): Returning value ''
2021-01-28,13:48:03 [DEBUG] (state.py:state:613): Loading option 'Access-Control-Allow-Methods' from section [Service Info]...
2021-01-28,13:48:03 [DEBUG] (state.py:state:635): Returning value ''
2021-01-28,13:48:03 [DEBUG] (base_handler.py:base_handler:115): Processing POST request '{'data': {'_arg1': {'dummy': ['prep_string_type']}}, 'script': 'import pandas as pd\ndef get_output_schema():\n\treturn \'5e1663ee-aeb8-40e2-9e10-d7644bc9e928\'\ndef prep_string():\n\treturn [\'prep_string_type\']\ndef prep_bool():\n\treturn [\'prep_bool_type\']\ndef prep_int():\n\treturn [\'prep_int_type\']\ndef prep_decimal():\n    return [\'prep_decimal_type\']\ndef prep_date():\n\treturn [\'prep_date_type\']\ndef prep_datetime():\n\treturn [\'prep_datetime_type\']\n# os is used to retrieve environment variables\n# requests is used to make HTTP requests out to Tableau Server\n# json is used to parse the answer received from the Tableau metadata API\n# pandas is used to build a dataframe and return data to Tableau Prep\n\nimport os\nimport requests\nimport json\nimport pandas as pd\n\n\n# login will perform a login into Tableau Server and return a session token\n# it uses the API_SERVER, API_SECRET_TOKEN and API_TOKEN_NAME environment variables\n# see docker-compose.yml for these environment variables\n\ndef login():\n    body = {"credentials": {"personalAccessTokenName": os.environ[\'API_TOKEN_NAME\'],\n                            "personalAccessTokenSecret": os.environ[\'API_SECRET_TOKEN\'],\n                            "site": {"contentUrl": ""}}}\n\n    print("Performing login")\n\n    url = "https://{server}/api/3.9/auth/signin".format(\n        server=os.environ["API_SERVER"])\n\n    headers = {\n        \'accept\': \'application/json\',\n        \'content-type\': \'application/json\'\n    }\n\n    # making the request\n    x = requests.post(url, json=body, headers=headers)\n    # parsing the login response\n    response = json.loads(x.text)\n    # if everything goes well, session token is found here:\n    token = response["credentials"]["token"]\n\n    return token\n\n# run_query runs a GRAPHQL query against the Tableau metadata API\n# arguments are a session token (obtained with login function) and the query text\n# it uses the API_SERVER environment variable to connect to the server; see docker-compose.yml\n\n\ndef run_query(token, query):\n    uri = "https://{server}/api/metadata/graphql".format(\n        server=os.environ["API_SERVER"])\n    headers = {\n        \'content-type\': \'application/json\',\n        \'accept\': \'application/json\',\n        \'X-Tableau-Auth\': token\n    }\n    x = requests.post(uri, json={\'query\': query}, headers=headers)\n\n    # we print the plain text answer for debugging purposes\n    print(x.text)\n\n    # we return the plain text answer received\n    return x.text\n\n\n# This function is called by Tableau Prep to obtain the expected schema of the data to receive\ndef get_output_schema():\n    return pd.DataFrame({\n        \'ds_name\': prep_string(),\n        \'flow_name\': prep_string(),\n        \'owner_name\': prep_string(),\n        \'project_name\': prep_string()\n    })\n\n\n# This is the function we well name in a Tableau Prep script node\n# It received data on the input, but doesn\'t use it\n\ndef get_published_ds_used_in_flow(input):\n\n    # The hardcoded Graphql query\n    query = """query published_datasources_certified {\n    publishedDatasources {\n      name\n      isCertified\n      downstreamFlows {\n        name,\n        owner {\n          name\n        },\n        projectName\n      }\n    }\n  }\n  """\n\n    print("Logging into Tableau Server...")\n    token = login()\n    print("Session token is: " + token)\n    print("")\n    print("Running the following query:")\n    print(query)\n    print("")\n    print("Answer below:")\n\n    # here we get text\n    json_string = run_query(token, query)\n\n    # we parse the result as a json structure\n    response_as_json = json.loads(json_string)\n\n    # we print the json structure\n    print(json.dumps(response_as_json, sort_keys=True, indent=4))\n\n    # navigating the json structure to find the starting node we need\n    list_of_published_ds = response_as_json["data"]["publishedDatasources"]\n\n    # this array will contain the data we will return to Tableau Prep\n    resultset = []\n\n    # navigating the json structure and collecting data\n    for ds in list_of_published_ds:\n        for flow in ds["downstreamFlows"]:\n            # when we find a downstream flow, we create one entry into the resultset\n            resultset.append([ds["name"], flow["name"],\n                              flow["owner"]["name"], flow["projectName"]])\n\n    # print the resultset for debugging purposes\n    print(resultset)\n\n    # we turn this python array into a pandas dataframe\n    df = pd.DataFrame(data=resultset, columns=[\n                      "ds_name", "flow_name", "owner_name", "project_name"])\n\n    # we return the dataframe to Tableau Prep\n    return(df)\ndef get_output_schema_bea97b3a58e648258274adfc99cd41f5(df = pd.DataFrame()):\n    import inspect\n    if len(inspect.getfullargspec(get_output_schema).args) == 0:\n        return get_output_schema()\n    else:\n        return get_output_schema(df)\nresult_schema_output = get_output_schema_bea97b3a58e648258274adfc99cd41f5(pd.DataFrame(_arg1))\nreturn result_schema_output.to_dict(orient=\'split\') if isinstance(result_schema_output, pd.DataFrame) else result_schema_output'}'...
2021-01-28,13:48:03 [INFO] (base_handler.py:base_handler:115): function to evaluate=def _user_script(tabpy, _arg1):
 import pandas as pd
 def get_output_schema():
 	return '5e1663ee-aeb8-40e2-9e10-d7644bc9e928'
 def prep_string():
 	return ['prep_string_type']
 def prep_bool():
 	return ['prep_bool_type']
 def prep_int():
 	return ['prep_int_type']
 def prep_decimal():
     return ['prep_decimal_type']
 def prep_date():
 	return ['prep_date_type']
 def prep_datetime():
 	return ['prep_datetime_type']
 # os is used to retrieve environment variables
 # requests is used to make HTTP requests out to Tableau Server
 # json is used to parse the answer received from the Tableau metadata API
 # pandas is used to build a dataframe and return data to Tableau Prep
 
 import os
 import requests
 import json
 import pandas as pd
 
 
 # login will perform a login into Tableau Server and return a session token
 # it uses the API_SERVER, API_SECRET_TOKEN and API_TOKEN_NAME environment variables
 # see docker-compose.yml for these environment variables
 
 def login():
     body = {"credentials": {"personalAccessTokenName": os.environ['API_TOKEN_NAME'],
                             "personalAccessTokenSecret": os.environ['API_SECRET_TOKEN'],
                             "site": {"contentUrl": ""}}}
 
     print("Performing login")
 
     url = "https://{server}/api/3.9/auth/signin".format(
         server=os.environ["API_SERVER"])
 
     headers = {
         'accept': 'application/json',
         'content-type': 'application/json'
     }
 
     # making the request
     x = requests.post(url, json=body, headers=headers)
     # parsing the login response
     response = json.loads(x.text)
     # if everything goes well, session token is found here:
     token = response["credentials"]["token"]
 
     return token
 
 # run_query runs a GRAPHQL query against the Tableau metadata API
 # arguments are a session token (obtained with login function) and the query text
 # it uses the API_SERVER environment variable to connect to the server; see docker-compose.yml
 
 
 def run_query(token, query):
     uri = "https://{server}/api/metadata/graphql".format(
         server=os.environ["API_SERVER"])
     headers = {
         'content-type': 'application/json',
         'accept': 'application/json',
         'X-Tableau-Auth': token
     }
     x = requests.post(uri, json={'query': query}, headers=headers)
 
     # we print the plain text answer for debugging purposes
     print(x.text)
 
     # we return the plain text answer received
     return x.text
 
 
 # This function is called by Tableau Prep to obtain the expected schema of the data to receive
 def get_output_schema():
     return pd.DataFrame({
         'ds_name': prep_string(),
         'flow_name': prep_string(),
         'owner_name': prep_string(),
         'project_name': prep_string()
     })
 
 
 # This is the function we well name in a Tableau Prep script node
 # It received data on the input, but doesn't use it
 
 def get_published_ds_used_in_flow(input):
 
     # The hardcoded Graphql query
     query = """query published_datasources_certified {
     publishedDatasources {
       name
       isCertified
       downstreamFlows {
         name,
         owner {
           name
         },
         projectName
       }
     }
   }
   """
 
     print("Logging into Tableau Server...")
     token = login()
     print("Session token is: " + token)
     print("")
     print("Running the following query:")
     print(query)
     print("")
     print("Answer below:")
 
     # here we get text
     json_string = run_query(token, query)
 
     # we parse the result as a json structure
     response_as_json = json.loads(json_string)
 
     # we print the json structure
     print(json.dumps(response_as_json, sort_keys=True, indent=4))
 
     # navigating the json structure to find the starting node we need
     list_of_published_ds = response_as_json["data"]["publishedDatasources"]
 
     # this array will contain the data we will return to Tableau Prep
     resultset = []
 
     # navigating the json structure and collecting data
     for ds in list_of_published_ds:
         for flow in ds["downstreamFlows"]:
             # when we find a downstream flow, we create one entry into the resultset
             resultset.append([ds["name"], flow["name"],
                               flow["owner"]["name"], flow["projectName"]])
 
     # print the resultset for debugging purposes
     print(resultset)
 
     # we turn this python array into a pandas dataframe
     df = pd.DataFrame(data=resultset, columns=[
                       "ds_name", "flow_name", "owner_name", "project_name"])
 
     # we return the dataframe to Tableau Prep
     return(df)
 def get_output_schema_bea97b3a58e648258274adfc99cd41f5(df = pd.DataFrame()):
     import inspect
     if len(inspect.getfullargspec(get_output_schema).args) == 0:
         return get_output_schema()
     else:
         return get_output_schema(df)
 result_schema_output = get_output_schema_bea97b3a58e648258274adfc99cd41f5(pd.DataFrame(_arg1))
 return result_schema_output.to_dict(orient='split') if isinstance(result_schema_output, pd.DataFrame) else result_schema_output

2021-01-28,13:48:03 [DEBUG] (base_handler.py:base_handler:115): Checking if need to handle authentication
2021-01-28,13:48:03 [DEBUG] (base_handler.py:base_handler:115): Handling authentication
2021-01-28,13:48:03 [INFO] (base_handler.py:base_handler:115): Authentication is not a required feature for API "v1"
2021-01-28,13:48:03 [DEBUG] (base_handler.py:base_handler:115): Checking request headers for authentication data
2021-01-28,13:48:03 [INFO] (base_handler.py:base_handler:115): Authorization header not found
2021-01-28,13:48:03 [DEBUG] (base_handler.py:base_handler:115): authentication not required, username and password are none
2021-01-28,13:48:03 [DEBUG] (state.py:state:511): Collecting Access-Control-Allow-Origin from state file ...
2021-01-28,13:48:03 [DEBUG] (state.py:state:613): Loading option 'Access-Control-Allow-Origin' from section [Service Info]...
2021-01-28,13:48:03 [DEBUG] (state.py:state:635): Returning value ''
2021-01-28,13:48:03 [DEBUG] (state.py:state:613): Loading option 'Access-Control-Allow-Headers' from section [Service Info]...
2021-01-28,13:48:03 [DEBUG] (state.py:state:635): Returning value ''
2021-01-28,13:48:03 [DEBUG] (state.py:state:613): Loading option 'Access-Control-Allow-Methods' from section [Service Info]...
2021-01-28,13:48:03 [DEBUG] (state.py:state:635): Returning value ''
2021-01-28,13:48:03 [DEBUG] (base_handler.py:base_handler:115): Processing POST request '{'data': {'_arg1': {'dummy': ['prep_string_type']}}, 'script': 'import pandas as pd\ndef get_output_schema():\n\treturn \'5e1663ee-aeb8-40e2-9e10-d7644bc9e928\'\ndef prep_string():\n\treturn [\'prep_string_type\']\ndef prep_bool():\n\treturn [\'prep_bool_type\']\ndef prep_int():\n\treturn [\'prep_int_type\']\ndef prep_decimal():\n    return [\'prep_decimal_type\']\ndef prep_date():\n\treturn [\'prep_date_type\']\ndef prep_datetime():\n\treturn [\'prep_datetime_type\']\n# os is used to retrieve environment variables\n# requests is used to make HTTP requests out to Tableau Server\n# json is used to parse the answer received from the Tableau metadata API\n# pandas is used to build a dataframe and return data to Tableau Prep\n\nimport os\nimport requests\nimport json\nimport pandas as pd\n\n\n# login will perform a login into Tableau Server and return a session token\n# it uses the API_SERVER, API_SECRET_TOKEN and API_TOKEN_NAME environment variables\n# see docker-compose.yml for these environment variables\n\ndef login():\n    body = {"credentials": {"personalAccessTokenName": os.environ[\'API_TOKEN_NAME\'],\n                            "personalAccessTokenSecret": os.environ[\'API_SECRET_TOKEN\'],\n                            "site": {"contentUrl": ""}}}\n\n    print("Performing login")\n\n    url = "https://{server}/api/3.9/auth/signin".format(\n        server=os.environ["API_SERVER"])\n\n    headers = {\n        \'accept\': \'application/json\',\n        \'content-type\': \'application/json\'\n    }\n\n    # making the request\n    x = requests.post(url, json=body, headers=headers)\n    # parsing the login response\n    response = json.loads(x.text)\n    # if everything goes well, session token is found here:\n    token = response["credentials"]["token"]\n\n    return token\n\n# run_query runs a GRAPHQL query against the Tableau metadata API\n# arguments are a session token (obtained with login function) and the query text\n# it uses the API_SERVER environment variable to connect to the server; see docker-compose.yml\n\n\ndef run_query(token, query):\n    uri = "https://{server}/api/metadata/graphql".format(\n        server=os.environ["API_SERVER"])\n    headers = {\n        \'content-type\': \'application/json\',\n        \'accept\': \'application/json\',\n        \'X-Tableau-Auth\': token\n    }\n    x = requests.post(uri, json={\'query\': query}, headers=headers)\n\n    # we print the plain text answer for debugging purposes\n    print(x.text)\n\n    # we return the plain text answer received\n    return x.text\n\n\n# This function is called by Tableau Prep to obtain the expected schema of the data to receive\ndef get_output_schema():\n    return pd.DataFrame({\n        \'ds_name\': prep_string(),\n        \'flow_name\': prep_string(),\n        \'owner_name\': prep_string(),\n        \'project_name\': prep_string()\n    })\n\n\n# This is the function we well name in a Tableau Prep script node\n# It received data on the input, but doesn\'t use it\n\ndef get_published_ds_used_in_flow(input):\n\n    # The hardcoded Graphql query\n    query = """query published_datasources_certified {\n    publishedDatasources {\n      name\n      isCertified\n      downstreamFlows {\n        name,\n        owner {\n          name\n        },\n        projectName\n      }\n    }\n  }\n  """\n\n    print("Logging into Tableau Server...")\n    token = login()\n    print("Session token is: " + token)\n    print("")\n    print("Running the following query:")\n    print(query)\n    print("")\n    print("Answer below:")\n\n    # here we get text\n    json_string = run_query(token, query)\n\n    # we parse the result as a json structure\n    response_as_json = json.loads(json_string)\n\n    # we print the json structure\n    print(json.dumps(response_as_json, sort_keys=True, indent=4))\n\n    # navigating the json structure to find the starting node we need\n    list_of_published_ds = response_as_json["data"]["publishedDatasources"]\n\n    # this array will contain the data we will return to Tableau Prep\n    resultset = []\n\n    # navigating the json structure and collecting data\n    for ds in list_of_published_ds:\n        for flow in ds["downstreamFlows"]:\n            # when we find a downstream flow, we create one entry into the resultset\n            resultset.append([ds["name"], flow["name"],\n                              flow["owner"]["name"], flow["projectName"]])\n\n    # print the resultset for debugging purposes\n    print(resultset)\n\n    # we turn this python array into a pandas dataframe\n    df = pd.DataFrame(data=resultset, columns=[\n                      "ds_name", "flow_name", "owner_name", "project_name"])\n\n    # we return the dataframe to Tableau Prep\n    return(df)\ndef get_output_schema_bea97b3a58e648258274adfc99cd41f5(df = pd.DataFrame()):\n    import inspect\n    if len(inspect.getfullargspec(get_output_schema).args) == 0:\n        return get_output_schema()\n    else:\n        return get_output_schema(df)\nresult_schema_output = get_output_schema_bea97b3a58e648258274adfc99cd41f5(pd.DataFrame(_arg1))\nreturn result_schema_output.to_dict(orient=\'split\') if isinstance(result_schema_output, pd.DataFrame) else result_schema_output'}'...
2021-01-28,13:48:03 [INFO] (base_handler.py:base_handler:115): function to evaluate=def _user_script(tabpy, _arg1):
 import pandas as pd
 def get_output_schema():
 	return '5e1663ee-aeb8-40e2-9e10-d7644bc9e928'
 def prep_string():
 	return ['prep_string_type']
 def prep_bool():
 	return ['prep_bool_type']
 def prep_int():
 	return ['prep_int_type']
 def prep_decimal():
     return ['prep_decimal_type']
 def prep_date():
 	return ['prep_date_type']
 def prep_datetime():
 	return ['prep_datetime_type']
 # os is used to retrieve environment variables
 # requests is used to make HTTP requests out to Tableau Server
 # json is used to parse the answer received from the Tableau metadata API
 # pandas is used to build a dataframe and return data to Tableau Prep
 
 import os
 import requests
 import json
 import pandas as pd
 
 
 # login will perform a login into Tableau Server and return a session token
 # it uses the API_SERVER, API_SECRET_TOKEN and API_TOKEN_NAME environment variables
 # see docker-compose.yml for these environment variables
 
 def login():
     body = {"credentials": {"personalAccessTokenName": os.environ['API_TOKEN_NAME'],
                             "personalAccessTokenSecret": os.environ['API_SECRET_TOKEN'],
                             "site": {"contentUrl": ""}}}
 
     print("Performing login")
 
     url = "https://{server}/api/3.9/auth/signin".format(
         server=os.environ["API_SERVER"])
 
     headers = {
         'accept': 'application/json',
         'content-type': 'application/json'
     }
 
     # making the request
     x = requests.post(url, json=body, headers=headers)
     # parsing the login response
     response = json.loads(x.text)
     # if everything goes well, session token is found here:
     token = response["credentials"]["token"]
 
     return token
 
 # run_query runs a GRAPHQL query against the Tableau metadata API
 # arguments are a session token (obtained with login function) and the query text
 # it uses the API_SERVER environment variable to connect to the server; see docker-compose.yml
 
 
 def run_query(token, query):
     uri = "https://{server}/api/metadata/graphql".format(
         server=os.environ["API_SERVER"])
     headers = {
         'content-type': 'application/json',
         'accept': 'application/json',
         'X-Tableau-Auth': token
     }
     x = requests.post(uri, json={'query': query}, headers=headers)
 
     # we print the plain text answer for debugging purposes
     print(x.text)
 
     # we return the plain text answer received
     return x.text
 
 
 # This function is called by Tableau Prep to obtain the expected schema of the data to receive
 def get_output_schema():
     return pd.DataFrame({
         'ds_name': prep_string(),
         'flow_name': prep_string(),
         'owner_name': prep_string(),
         'project_name': prep_string()
     })
 
 
 # This is the function we well name in a Tableau Prep script node
 # It received data on the input, but doesn't use it
 
 def get_published_ds_used_in_flow(input):
 
     # The hardcoded Graphql query
     query = """query published_datasources_certified {
     publishedDatasources {
       name
       isCertified
       downstreamFlows {
         name,
         owner {
           name
         },
         projectName
       }
     }
   }
   """
 
     print("Logging into Tableau Server...")
     token = login()
     print("Session token is: " + token)
     print("")
     print("Running the following query:")
     print(query)
     print("")
     print("Answer below:")
 
     # here we get text
     json_string = run_query(token, query)
 
     # we parse the result as a json structure
     response_as_json = json.loads(json_string)
 
     # we print the json structure
     print(json.dumps(response_as_json, sort_keys=True, indent=4))
 
     # navigating the json structure to find the starting node we need
     list_of_published_ds = response_as_json["data"]["publishedDatasources"]
 
     # this array will contain the data we will return to Tableau Prep
     resultset = []
 
     # navigating the json structure and collecting data
     for ds in list_of_published_ds:
         for flow in ds["downstreamFlows"]:
             # when we find a downstream flow, we create one entry into the resultset
             resultset.append([ds["name"], flow["name"],
                               flow["owner"]["name"], flow["projectName"]])
 
     # print the resultset for debugging purposes
     print(resultset)
 
     # we turn this python array into a pandas dataframe
     df = pd.DataFrame(data=resultset, columns=[
                       "ds_name", "flow_name", "owner_name", "project_name"])
 
     # we return the dataframe to Tableau Prep
     return(df)
 def get_output_schema_bea97b3a58e648258274adfc99cd41f5(df = pd.DataFrame()):
     import inspect
     if len(inspect.getfullargspec(get_output_schema).args) == 0:
         return get_output_schema()
     else:
         return get_output_schema(df)
 result_schema_output = get_output_schema_bea97b3a58e648258274adfc99cd41f5(pd.DataFrame(_arg1))
 return result_schema_output.to_dict(orient='split') if isinstance(result_schema_output, pd.DataFrame) else result_schema_output

2021-01-28,13:48:03 [INFO] (web.py:web:2239): 200 POST /evaluate (172.18.0.1) 61.77ms
2021-01-28,13:48:03 [INFO] (web.py:web:2239): 200 POST /evaluate (172.18.0.1) 32.53ms
2021-01-28,13:48:03 [DEBUG] (base_handler.py:base_handler:115): Checking if need to handle authentication
2021-01-28,13:48:03 [DEBUG] (base_handler.py:base_handler:115): Handling authentication
2021-01-28,13:48:03 [INFO] (base_handler.py:base_handler:115): Authentication is not a required feature for API "v1"
2021-01-28,13:48:03 [DEBUG] (base_handler.py:base_handler:115): Checking request headers for authentication data
2021-01-28,13:48:03 [INFO] (base_handler.py:base_handler:115): Authorization header not found
2021-01-28,13:48:03 [DEBUG] (base_handler.py:base_handler:115): authentication not required, username and password are none
2021-01-28,13:48:03 [DEBUG] (state.py:state:511): Collecting Access-Control-Allow-Origin from state file ...
2021-01-28,13:48:03 [DEBUG] (state.py:state:613): Loading option 'Access-Control-Allow-Origin' from section [Service Info]...
2021-01-28,13:48:03 [DEBUG] (state.py:state:635): Returning value ''
2021-01-28,13:48:03 [DEBUG] (state.py:state:613): Loading option 'Access-Control-Allow-Headers' from section [Service Info]...
2021-01-28,13:48:03 [DEBUG] (state.py:state:635): Returning value ''
2021-01-28,13:48:03 [DEBUG] (state.py:state:613): Loading option 'Access-Control-Allow-Methods' from section [Service Info]...
2021-01-28,13:48:03 [DEBUG] (state.py:state:635): Returning value ''
2021-01-28,13:48:03 [DEBUG] (base_handler.py:base_handler:115): Processing POST request '{'data': {'_arg1': {'dummy': ['prep_string_type']}}, 'script': 'import pandas as pd\ndef get_output_schema():\n\treturn \'5e1663ee-aeb8-40e2-9e10-d7644bc9e928\'\ndef prep_string():\n\treturn [\'prep_string_type\']\ndef prep_bool():\n\treturn [\'prep_bool_type\']\ndef prep_int():\n\treturn [\'prep_int_type\']\ndef prep_decimal():\n    return [\'prep_decimal_type\']\ndef prep_date():\n\treturn [\'prep_date_type\']\ndef prep_datetime():\n\treturn [\'prep_datetime_type\']\n# os is used to retrieve environment variables\n# requests is used to make HTTP requests out to Tableau Server\n# json is used to parse the answer received from the Tableau metadata API\n# pandas is used to build a dataframe and return data to Tableau Prep\n\nimport os\nimport requests\nimport json\nimport pandas as pd\n\n\n# login will perform a login into Tableau Server and return a session token\n# it uses the API_SERVER, API_SECRET_TOKEN and API_TOKEN_NAME environment variables\n# see docker-compose.yml for these environment variables\n\ndef login():\n    body = {"credentials": {"personalAccessTokenName": os.environ[\'API_TOKEN_NAME\'],\n                            "personalAccessTokenSecret": os.environ[\'API_SECRET_TOKEN\'],\n                            "site": {"contentUrl": ""}}}\n\n    print("Performing login")\n\n    url = "https://{server}/api/3.9/auth/signin".format(\n        server=os.environ["API_SERVER"])\n\n    headers = {\n        \'accept\': \'application/json\',\n        \'content-type\': \'application/json\'\n    }\n\n    # making the request\n    x = requests.post(url, json=body, headers=headers)\n    # parsing the login response\n    response = json.loads(x.text)\n    # if everything goes well, session token is found here:\n    token = response["credentials"]["token"]\n\n    return token\n\n# run_query runs a GRAPHQL query against the Tableau metadata API\n# arguments are a session token (obtained with login function) and the query text\n# it uses the API_SERVER environment variable to connect to the server; see docker-compose.yml\n\n\ndef run_query(token, query):\n    uri = "https://{server}/api/metadata/graphql".format(\n        server=os.environ["API_SERVER"])\n    headers = {\n        \'content-type\': \'application/json\',\n        \'accept\': \'application/json\',\n        \'X-Tableau-Auth\': token\n    }\n    x = requests.post(uri, json={\'query\': query}, headers=headers)\n\n    # we print the plain text answer for debugging purposes\n    print(x.text)\n\n    # we return the plain text answer received\n    return x.text\n\n\n# This function is called by Tableau Prep to obtain the expected schema of the data to receive\ndef get_output_schema():\n    return pd.DataFrame({\n        \'ds_name\': prep_string(),\n        \'flow_name\': prep_string(),\n        \'owner_name\': prep_string(),\n        \'project_name\': prep_string()\n    })\n\n\n# This is the function we well name in a Tableau Prep script node\n# It received data on the input, but doesn\'t use it\n\ndef get_published_ds_used_in_flow(input):\n\n    # The hardcoded Graphql query\n    query = """query published_datasources_certified {\n    publishedDatasources {\n      name\n      isCertified\n      downstreamFlows {\n        name,\n        owner {\n          name\n        },\n        projectName\n      }\n    }\n  }\n  """\n\n    print("Logging into Tableau Server...")\n    token = login()\n    print("Session token is: " + token)\n    print("")\n    print("Running the following query:")\n    print(query)\n    print("")\n    print("Answer below:")\n\n    # here we get text\n    json_string = run_query(token, query)\n\n    # we parse the result as a json structure\n    response_as_json = json.loads(json_string)\n\n    # we print the json structure\n    print(json.dumps(response_as_json, sort_keys=True, indent=4))\n\n    # navigating the json structure to find the starting node we need\n    list_of_published_ds = response_as_json["data"]["publishedDatasources"]\n\n    # this array will contain the data we will return to Tableau Prep\n    resultset = []\n\n    # navigating the json structure and collecting data\n    for ds in list_of_published_ds:\n        for flow in ds["downstreamFlows"]:\n            # when we find a downstream flow, we create one entry into the resultset\n            resultset.append([ds["name"], flow["name"],\n                              flow["owner"]["name"], flow["projectName"]])\n\n    # print the resultset for debugging purposes\n    print(resultset)\n\n    # we turn this python array into a pandas dataframe\n    df = pd.DataFrame(data=resultset, columns=[\n                      "ds_name", "flow_name", "owner_name", "project_name"])\n\n    # we return the dataframe to Tableau Prep\n    return(df)\ndef get_output_schema_bea97b3a58e648258274adfc99cd41f5(df = pd.DataFrame()):\n    import inspect\n    if len(inspect.getfullargspec(get_output_schema).args) == 0:\n        return get_output_schema()\n    else:\n        return get_output_schema(df)\nresult_schema_output = get_output_schema_bea97b3a58e648258274adfc99cd41f5(pd.DataFrame(_arg1))\nreturn result_schema_output.to_dict(orient=\'split\') if isinstance(result_schema_output, pd.DataFrame) else result_schema_output'}'...
2021-01-28,13:48:03 [INFO] (base_handler.py:base_handler:115): function to evaluate=def _user_script(tabpy, _arg1):
 import pandas as pd
 def get_output_schema():
 	return '5e1663ee-aeb8-40e2-9e10-d7644bc9e928'
 def prep_string():
 	return ['prep_string_type']
 def prep_bool():
 	return ['prep_bool_type']
 def prep_int():
 	return ['prep_int_type']
 def prep_decimal():
     return ['prep_decimal_type']
 def prep_date():
 	return ['prep_date_type']
 def prep_datetime():
 	return ['prep_datetime_type']
 # os is used to retrieve environment variables
 # requests is used to make HTTP requests out to Tableau Server
 # json is used to parse the answer received from the Tableau metadata API
 # pandas is used to build a dataframe and return data to Tableau Prep
 
 import os
 import requests
 import json
 import pandas as pd
 
 
 # login will perform a login into Tableau Server and return a session token
 # it uses the API_SERVER, API_SECRET_TOKEN and API_TOKEN_NAME environment variables
 # see docker-compose.yml for these environment variables
 
 def login():
     body = {"credentials": {"personalAccessTokenName": os.environ['API_TOKEN_NAME'],
                             "personalAccessTokenSecret": os.environ['API_SECRET_TOKEN'],
                             "site": {"contentUrl": ""}}}
 
     print("Performing login")
 
     url = "https://{server}/api/3.9/auth/signin".format(
         server=os.environ["API_SERVER"])
 
     headers = {
         'accept': 'application/json',
         'content-type': 'application/json'
     }
 
     # making the request
     x = requests.post(url, json=body, headers=headers)
     # parsing the login response
     response = json.loads(x.text)
     # if everything goes well, session token is found here:
     token = response["credentials"]["token"]
 
     return token
 
 # run_query runs a GRAPHQL query against the Tableau metadata API
 # arguments are a session token (obtained with login function) and the query text
 # it uses the API_SERVER environment variable to connect to the server; see docker-compose.yml
 
 
 def run_query(token, query):
     uri = "https://{server}/api/metadata/graphql".format(
         server=os.environ["API_SERVER"])
     headers = {
         'content-type': 'application/json',
         'accept': 'application/json',
         'X-Tableau-Auth': token
     }
     x = requests.post(uri, json={'query': query}, headers=headers)
 
     # we print the plain text answer for debugging purposes
     print(x.text)
 
     # we return the plain text answer received
     return x.text
 
 
 # This function is called by Tableau Prep to obtain the expected schema of the data to receive
 def get_output_schema():
     return pd.DataFrame({
         'ds_name': prep_string(),
         'flow_name': prep_string(),
         'owner_name': prep_string(),
         'project_name': prep_string()
     })
 
 
 # This is the function we well name in a Tableau Prep script node
 # It received data on the input, but doesn't use it
 
 def get_published_ds_used_in_flow(input):
 
     # The hardcoded Graphql query
     query = """query published_datasources_certified {
     publishedDatasources {
       name
       isCertified
       downstreamFlows {
         name,
         owner {
           name
         },
         projectName
       }
     }
   }
   """
 
     print("Logging into Tableau Server...")
     token = login()
     print("Session token is: " + token)
     print("")
     print("Running the following query:")
     print(query)
     print("")
     print("Answer below:")
 
     # here we get text
     json_string = run_query(token, query)
 
     # we parse the result as a json structure
     response_as_json = json.loads(json_string)
 
     # we print the json structure
     print(json.dumps(response_as_json, sort_keys=True, indent=4))
 
     # navigating the json structure to find the starting node we need
     list_of_published_ds = response_as_json["data"]["publishedDatasources"]
 
     # this array will contain the data we will return to Tableau Prep
     resultset = []
 
     # navigating the json structure and collecting data
     for ds in list_of_published_ds:
         for flow in ds["downstreamFlows"]:
             # when we find a downstream flow, we create one entry into the resultset
             resultset.append([ds["name"], flow["name"],
                               flow["owner"]["name"], flow["projectName"]])
 
     # print the resultset for debugging purposes
     print(resultset)
 
     # we turn this python array into a pandas dataframe
     df = pd.DataFrame(data=resultset, columns=[
                       "ds_name", "flow_name", "owner_name", "project_name"])
 
     # we return the dataframe to Tableau Prep
     return(df)
 def get_output_schema_bea97b3a58e648258274adfc99cd41f5(df = pd.DataFrame()):
     import inspect
     if len(inspect.getfullargspec(get_output_schema).args) == 0:
         return get_output_schema()
     else:
         return get_output_schema(df)
 result_schema_output = get_output_schema_bea97b3a58e648258274adfc99cd41f5(pd.DataFrame(_arg1))
 return result_schema_output.to_dict(orient='split') if isinstance(result_schema_output, pd.DataFrame) else result_schema_output

2021-01-28,13:48:03 [DEBUG] (base_handler.py:base_handler:115): Checking if need to handle authentication
2021-01-28,13:48:03 [DEBUG] (base_handler.py:base_handler:115): Handling authentication
2021-01-28,13:48:03 [INFO] (base_handler.py:base_handler:115): Authentication is not a required feature for API "v1"
2021-01-28,13:48:03 [DEBUG] (base_handler.py:base_handler:115): Checking request headers for authentication data
2021-01-28,13:48:03 [INFO] (base_handler.py:base_handler:115): Authorization header not found
2021-01-28,13:48:03 [DEBUG] (base_handler.py:base_handler:115): authentication not required, username and password are none
2021-01-28,13:48:03 [DEBUG] (state.py:state:511): Collecting Access-Control-Allow-Origin from state file ...
2021-01-28,13:48:03 [DEBUG] (state.py:state:613): Loading option 'Access-Control-Allow-Origin' from section [Service Info]...
2021-01-28,13:48:03 [DEBUG] (state.py:state:635): Returning value ''
2021-01-28,13:48:03 [DEBUG] (state.py:state:613): Loading option 'Access-Control-Allow-Headers' from section [Service Info]...
2021-01-28,13:48:03 [DEBUG] (state.py:state:635): Returning value ''
2021-01-28,13:48:03 [DEBUG] (state.py:state:613): Loading option 'Access-Control-Allow-Methods' from section [Service Info]...
2021-01-28,13:48:03 [DEBUG] (state.py:state:635): Returning value ''
2021-01-28,13:48:03 [DEBUG] (base_handler.py:base_handler:115): Processing POST request '{'data': {'_arg1': {'dummy': ['prep_string_type']}}, 'script': 'import pandas as pd\ndef get_output_schema():\n\treturn \'5e1663ee-aeb8-40e2-9e10-d7644bc9e928\'\ndef prep_string():\n\treturn [\'prep_string_type\']\ndef prep_bool():\n\treturn [\'prep_bool_type\']\ndef prep_int():\n\treturn [\'prep_int_type\']\ndef prep_decimal():\n    return [\'prep_decimal_type\']\ndef prep_date():\n\treturn [\'prep_date_type\']\ndef prep_datetime():\n\treturn [\'prep_datetime_type\']\n# os is used to retrieve environment variables\n# requests is used to make HTTP requests out to Tableau Server\n# json is used to parse the answer received from the Tableau metadata API\n# pandas is used to build a dataframe and return data to Tableau Prep\n\nimport os\nimport requests\nimport json\nimport pandas as pd\n\n\n# login will perform a login into Tableau Server and return a session token\n# it uses the API_SERVER, API_SECRET_TOKEN and API_TOKEN_NAME environment variables\n# see docker-compose.yml for these environment variables\n\ndef login():\n    body = {"credentials": {"personalAccessTokenName": os.environ[\'API_TOKEN_NAME\'],\n                            "personalAccessTokenSecret": os.environ[\'API_SECRET_TOKEN\'],\n                            "site": {"contentUrl": ""}}}\n\n    print("Performing login")\n\n    url = "https://{server}/api/3.9/auth/signin".format(\n        server=os.environ["API_SERVER"])\n\n    headers = {\n        \'accept\': \'application/json\',\n        \'content-type\': \'application/json\'\n    }\n\n    # making the request\n    x = requests.post(url, json=body, headers=headers)\n    # parsing the login response\n    response = json.loads(x.text)\n    # if everything goes well, session token is found here:\n    token = response["credentials"]["token"]\n\n    return token\n\n# run_query runs a GRAPHQL query against the Tableau metadata API\n# arguments are a session token (obtained with login function) and the query text\n# it uses the API_SERVER environment variable to connect to the server; see docker-compose.yml\n\n\ndef run_query(token, query):\n    uri = "https://{server}/api/metadata/graphql".format(\n        server=os.environ["API_SERVER"])\n    headers = {\n        \'content-type\': \'application/json\',\n        \'accept\': \'application/json\',\n        \'X-Tableau-Auth\': token\n    }\n    x = requests.post(uri, json={\'query\': query}, headers=headers)\n\n    # we print the plain text answer for debugging purposes\n    print(x.text)\n\n    # we return the plain text answer received\n    return x.text\n\n\n# This function is called by Tableau Prep to obtain the expected schema of the data to receive\ndef get_output_schema():\n    return pd.DataFrame({\n        \'ds_name\': prep_string(),\n        \'flow_name\': prep_string(),\n        \'owner_name\': prep_string(),\n        \'project_name\': prep_string()\n    })\n\n\n# This is the function we well name in a Tableau Prep script node\n# It received data on the input, but doesn\'t use it\n\ndef get_published_ds_used_in_flow(input):\n\n    # The hardcoded Graphql query\n    query = """query published_datasources_certified {\n    publishedDatasources {\n      name\n      isCertified\n      downstreamFlows {\n        name,\n        owner {\n          name\n        },\n        projectName\n      }\n    }\n  }\n  """\n\n    print("Logging into Tableau Server...")\n    token = login()\n    print("Session token is: " + token)\n    print("")\n    print("Running the following query:")\n    print(query)\n    print("")\n    print("Answer below:")\n\n    # here we get text\n    json_string = run_query(token, query)\n\n    # we parse the result as a json structure\n    response_as_json = json.loads(json_string)\n\n    # we print the json structure\n    print(json.dumps(response_as_json, sort_keys=True, indent=4))\n\n    # navigating the json structure to find the starting node we need\n    list_of_published_ds = response_as_json["data"]["publishedDatasources"]\n\n    # this array will contain the data we will return to Tableau Prep\n    resultset = []\n\n    # navigating the json structure and collecting data\n    for ds in list_of_published_ds:\n        for flow in ds["downstreamFlows"]:\n            # when we find a downstream flow, we create one entry into the resultset\n            resultset.append([ds["name"], flow["name"],\n                              flow["owner"]["name"], flow["projectName"]])\n\n    # print the resultset for debugging purposes\n    print(resultset)\n\n    # we turn this python array into a pandas dataframe\n    df = pd.DataFrame(data=resultset, columns=[\n                      "ds_name", "flow_name", "owner_name", "project_name"])\n\n    # we return the dataframe to Tableau Prep\n    return(df)\ndef get_output_schema_bea97b3a58e648258274adfc99cd41f5(df = pd.DataFrame()):\n    import inspect\n    if len(inspect.getfullargspec(get_output_schema).args) == 0:\n        return get_output_schema()\n    else:\n        return get_output_schema(df)\nresult_schema_output = get_output_schema_bea97b3a58e648258274adfc99cd41f5(pd.DataFrame(_arg1))\nreturn result_schema_output.to_dict(orient=\'split\') if isinstance(result_schema_output, pd.DataFrame) else result_schema_output'}'...
2021-01-28,13:48:03 [INFO] (base_handler.py:base_handler:115): function to evaluate=def _user_script(tabpy, _arg1):
 import pandas as pd
 def get_output_schema():
 	return '5e1663ee-aeb8-40e2-9e10-d7644bc9e928'
 def prep_string():
 	return ['prep_string_type']
 def prep_bool():
 	return ['prep_bool_type']
 def prep_int():
 	return ['prep_int_type']
 def prep_decimal():
     return ['prep_decimal_type']
 def prep_date():
 	return ['prep_date_type']
 def prep_datetime():
 	return ['prep_datetime_type']
 # os is used to retrieve environment variables
 # requests is used to make HTTP requests out to Tableau Server
 # json is used to parse the answer received from the Tableau metadata API
 # pandas is used to build a dataframe and return data to Tableau Prep
 
 import os
 import requests
 import json
 import pandas as pd
 
 
 # login will perform a login into Tableau Server and return a session token
 # it uses the API_SERVER, API_SECRET_TOKEN and API_TOKEN_NAME environment variables
 # see docker-compose.yml for these environment variables
 
 def login():
     body = {"credentials": {"personalAccessTokenName": os.environ['API_TOKEN_NAME'],
                             "personalAccessTokenSecret": os.environ['API_SECRET_TOKEN'],
                             "site": {"contentUrl": ""}}}
 
     print("Performing login")
 
     url = "https://{server}/api/3.9/auth/signin".format(
         server=os.environ["API_SERVER"])
 
     headers = {
         'accept': 'application/json',
         'content-type': 'application/json'
     }
 
     # making the request
     x = requests.post(url, json=body, headers=headers)
     # parsing the login response
     response = json.loads(x.text)
     # if everything goes well, session token is found here:
     token = response["credentials"]["token"]
 
     return token
 
 # run_query runs a GRAPHQL query against the Tableau metadata API
 # arguments are a session token (obtained with login function) and the query text
 # it uses the API_SERVER environment variable to connect to the server; see docker-compose.yml
 
 
 def run_query(token, query):
     uri = "https://{server}/api/metadata/graphql".format(
         server=os.environ["API_SERVER"])
     headers = {
         'content-type': 'application/json',
         'accept': 'application/json',
         'X-Tableau-Auth': token
     }
     x = requests.post(uri, json={'query': query}, headers=headers)
 
     # we print the plain text answer for debugging purposes
     print(x.text)
 
     # we return the plain text answer received
     return x.text
 
 
 # This function is called by Tableau Prep to obtain the expected schema of the data to receive
 def get_output_schema():
     return pd.DataFrame({
         'ds_name': prep_string(),
         'flow_name': prep_string(),
         'owner_name': prep_string(),
         'project_name': prep_string()
     })
 
 
 # This is the function we well name in a Tableau Prep script node
 # It received data on the input, but doesn't use it
 
 def get_published_ds_used_in_flow(input):
 
     # The hardcoded Graphql query
     query = """query published_datasources_certified {
     publishedDatasources {
       name
       isCertified
       downstreamFlows {
         name,
         owner {
           name
         },
         projectName
       }
     }
   }
   """
 
     print("Logging into Tableau Server...")
     token = login()
     print("Session token is: " + token)
     print("")
     print("Running the following query:")
     print(query)
     print("")
     print("Answer below:")
 
     # here we get text
     json_string = run_query(token, query)
 
     # we parse the result as a json structure
     response_as_json = json.loads(json_string)
 
     # we print the json structure
     print(json.dumps(response_as_json, sort_keys=True, indent=4))
 
     # navigating the json structure to find the starting node we need
     list_of_published_ds = response_as_json["data"]["publishedDatasources"]
 
     # this array will contain the data we will return to Tableau Prep
     resultset = []
 
     # navigating the json structure and collecting data
     for ds in list_of_published_ds:
         for flow in ds["downstreamFlows"]:
             # when we find a downstream flow, we create one entry into the resultset
             resultset.append([ds["name"], flow["name"],
                               flow["owner"]["name"], flow["projectName"]])
 
     # print the resultset for debugging purposes
     print(resultset)
 
     # we turn this python array into a pandas dataframe
     df = pd.DataFrame(data=resultset, columns=[
                       "ds_name", "flow_name", "owner_name", "project_name"])
 
     # we return the dataframe to Tableau Prep
     return(df)
 def get_output_schema_bea97b3a58e648258274adfc99cd41f5(df = pd.DataFrame()):
     import inspect
     if len(inspect.getfullargspec(get_output_schema).args) == 0:
         return get_output_schema()
     else:
         return get_output_schema(df)
 result_schema_output = get_output_schema_bea97b3a58e648258274adfc99cd41f5(pd.DataFrame(_arg1))
 return result_schema_output.to_dict(orient='split') if isinstance(result_schema_output, pd.DataFrame) else result_schema_output

2021-01-28,13:48:03 [INFO] (web.py:web:2239): 200 POST /evaluate (172.18.0.1) 41.04ms
2021-01-28,13:48:03 [INFO] (web.py:web:2239): 200 POST /evaluate (172.18.0.1) 26.23ms
2021-01-28,13:48:04 [DEBUG] (base_handler.py:base_handler:115): Checking if need to handle authentication
2021-01-28,13:48:04 [DEBUG] (base_handler.py:base_handler:115): Handling authentication
2021-01-28,13:48:04 [INFO] (base_handler.py:base_handler:115): Authentication is not a required feature for API "v1"
2021-01-28,13:48:04 [DEBUG] (base_handler.py:base_handler:115): Checking request headers for authentication data
2021-01-28,13:48:04 [INFO] (base_handler.py:base_handler:115): Authorization header not found
2021-01-28,13:48:04 [DEBUG] (base_handler.py:base_handler:115): authentication not required, username and password are none
2021-01-28,13:48:04 [DEBUG] (state.py:state:511): Collecting Access-Control-Allow-Origin from state file ...
2021-01-28,13:48:04 [DEBUG] (state.py:state:613): Loading option 'Access-Control-Allow-Origin' from section [Service Info]...
2021-01-28,13:48:04 [DEBUG] (state.py:state:635): Returning value ''
2021-01-28,13:48:04 [DEBUG] (state.py:state:613): Loading option 'Access-Control-Allow-Headers' from section [Service Info]...
2021-01-28,13:48:04 [DEBUG] (state.py:state:635): Returning value ''
2021-01-28,13:48:04 [DEBUG] (state.py:state:613): Loading option 'Access-Control-Allow-Methods' from section [Service Info]...
2021-01-28,13:48:04 [DEBUG] (state.py:state:635): Returning value ''
2021-01-28,13:48:04 [DEBUG] (base_handler.py:base_handler:115): Processing POST request '{'data': {'_arg1': {'dummy': ['prep_string_type']}}, 'script': 'import pandas as pd\ndef get_output_schema():\n\treturn \'5e1663ee-aeb8-40e2-9e10-d7644bc9e928\'\ndef prep_string():\n\treturn [\'prep_string_type\']\ndef prep_bool():\n\treturn [\'prep_bool_type\']\ndef prep_int():\n\treturn [\'prep_int_type\']\ndef prep_decimal():\n    return [\'prep_decimal_type\']\ndef prep_date():\n\treturn [\'prep_date_type\']\ndef prep_datetime():\n\treturn [\'prep_datetime_type\']\n# os is used to retrieve environment variables\n# requests is used to make HTTP requests out to Tableau Server\n# json is used to parse the answer received from the Tableau metadata API\n# pandas is used to build a dataframe and return data to Tableau Prep\n\nimport os\nimport requests\nimport json\nimport pandas as pd\n\n\n# login will perform a login into Tableau Server and return a session token\n# it uses the API_SERVER, API_SECRET_TOKEN and API_TOKEN_NAME environment variables\n# see docker-compose.yml for these environment variables\n\ndef login():\n    body = {"credentials": {"personalAccessTokenName": os.environ[\'API_TOKEN_NAME\'],\n                            "personalAccessTokenSecret": os.environ[\'API_SECRET_TOKEN\'],\n                            "site": {"contentUrl": ""}}}\n\n    print("Performing login")\n\n    url = "https://{server}/api/3.9/auth/signin".format(\n        server=os.environ["API_SERVER"])\n\n    headers = {\n        \'accept\': \'application/json\',\n        \'content-type\': \'application/json\'\n    }\n\n    # making the request\n    x = requests.post(url, json=body, headers=headers)\n    # parsing the login response\n    response = json.loads(x.text)\n    # if everything goes well, session token is found here:\n    token = response["credentials"]["token"]\n\n    return token\n\n# run_query runs a GRAPHQL query against the Tableau metadata API\n# arguments are a session token (obtained with login function) and the query text\n# it uses the API_SERVER environment variable to connect to the server; see docker-compose.yml\n\n\ndef run_query(token, query):\n    uri = "https://{server}/api/metadata/graphql".format(\n        server=os.environ["API_SERVER"])\n    headers = {\n        \'content-type\': \'application/json\',\n        \'accept\': \'application/json\',\n        \'X-Tableau-Auth\': token\n    }\n    x = requests.post(uri, json={\'query\': query}, headers=headers)\n\n    # we print the plain text answer for debugging purposes\n    print(x.text)\n\n    # we return the plain text answer received\n    return x.text\n\n\n# This function is called by Tableau Prep to obtain the expected schema of the data to receive\ndef get_output_schema():\n    return pd.DataFrame({\n        \'ds_name\': prep_string(),\n        \'flow_name\': prep_string(),\n        \'owner_name\': prep_string(),\n        \'project_name\': prep_string()\n    })\n\n\n# This is the function we well name in a Tableau Prep script node\n# It received data on the input, but doesn\'t use it\n\ndef get_published_ds_used_in_flow(input):\n\n    # The hardcoded Graphql query\n    query = """query published_datasources_certified {\n    publishedDatasources {\n      name\n      isCertified\n      downstreamFlows {\n        name,\n        owner {\n          name\n        },\n        projectName\n      }\n    }\n  }\n  """\n\n    print("Logging into Tableau Server...")\n    token = login()\n    print("Session token is: " + token)\n    print("")\n    print("Running the following query:")\n    print(query)\n    print("")\n    print("Answer below:")\n\n    # here we get text\n    json_string = run_query(token, query)\n\n    # we parse the result as a json structure\n    response_as_json = json.loads(json_string)\n\n    # we print the json structure\n    print(json.dumps(response_as_json, sort_keys=True, indent=4))\n\n    # navigating the json structure to find the starting node we need\n    list_of_published_ds = response_as_json["data"]["publishedDatasources"]\n\n    # this array will contain the data we will return to Tableau Prep\n    resultset = []\n\n    # navigating the json structure and collecting data\n    for ds in list_of_published_ds:\n        for flow in ds["downstreamFlows"]:\n            # when we find a downstream flow, we create one entry into the resultset\n            resultset.append([ds["name"], flow["name"],\n                              flow["owner"]["name"], flow["projectName"]])\n\n    # print the resultset for debugging purposes\n    print(resultset)\n\n    # we turn this python array into a pandas dataframe\n    df = pd.DataFrame(data=resultset, columns=[\n                      "ds_name", "flow_name", "owner_name", "project_name"])\n\n    # we return the dataframe to Tableau Prep\n    return(df)\ndef get_output_schema_bea97b3a58e648258274adfc99cd41f5(df = pd.DataFrame()):\n    import inspect\n    if len(inspect.getfullargspec(get_output_schema).args) == 0:\n        return get_output_schema()\n    else:\n        return get_output_schema(df)\nresult_schema_output = get_output_schema_bea97b3a58e648258274adfc99cd41f5(pd.DataFrame(_arg1))\nreturn result_schema_output.to_dict(orient=\'split\') if isinstance(result_schema_output, pd.DataFrame) else result_schema_output'}'...
2021-01-28,13:48:04 [INFO] (base_handler.py:base_handler:115): function to evaluate=def _user_script(tabpy, _arg1):
 import pandas as pd
 def get_output_schema():
 	return '5e1663ee-aeb8-40e2-9e10-d7644bc9e928'
 def prep_string():
 	return ['prep_string_type']
 def prep_bool():
 	return ['prep_bool_type']
 def prep_int():
 	return ['prep_int_type']
 def prep_decimal():
     return ['prep_decimal_type']
 def prep_date():
 	return ['prep_date_type']
 def prep_datetime():
 	return ['prep_datetime_type']
 # os is used to retrieve environment variables
 # requests is used to make HTTP requests out to Tableau Server
 # json is used to parse the answer received from the Tableau metadata API
 # pandas is used to build a dataframe and return data to Tableau Prep
 
 import os
 import requests
 import json
 import pandas as pd
 
 
 # login will perform a login into Tableau Server and return a session token
 # it uses the API_SERVER, API_SECRET_TOKEN and API_TOKEN_NAME environment variables
 # see docker-compose.yml for these environment variables
 
 def login():
     body = {"credentials": {"personalAccessTokenName": os.environ['API_TOKEN_NAME'],
                             "personalAccessTokenSecret": os.environ['API_SECRET_TOKEN'],
                             "site": {"contentUrl": ""}}}
 
     print("Performing login")
 
     url = "https://{server}/api/3.9/auth/signin".format(
         server=os.environ["API_SERVER"])
 
     headers = {
         'accept': 'application/json',
         'content-type': 'application/json'
     }
 
     # making the request
     x = requests.post(url, json=body, headers=headers)
     # parsing the login response
     response = json.loads(x.text)
     # if everything goes well, session token is found here:
     token = response["credentials"]["token"]
 
     return token
 
 # run_query runs a GRAPHQL query against the Tableau metadata API
 # arguments are a session token (obtained with login function) and the query text
 # it uses the API_SERVER environment variable to connect to the server; see docker-compose.yml
 
 
 def run_query(token, query):
     uri = "https://{server}/api/metadata/graphql".format(
         server=os.environ["API_SERVER"])
     headers = {
         'content-type': 'application/json',
         'accept': 'application/json',
         'X-Tableau-Auth': token
     }
     x = requests.post(uri, json={'query': query}, headers=headers)
 
     # we print the plain text answer for debugging purposes
     print(x.text)
 
     # we return the plain text answer received
     return x.text
 
 
 # This function is called by Tableau Prep to obtain the expected schema of the data to receive
 def get_output_schema():
     return pd.DataFrame({
         'ds_name': prep_string(),
         'flow_name': prep_string(),
         'owner_name': prep_string(),
         'project_name': prep_string()
     })
 
 
 # This is the function we well name in a Tableau Prep script node
 # It received data on the input, but doesn't use it
 
 def get_published_ds_used_in_flow(input):
 
     # The hardcoded Graphql query
     query = """query published_datasources_certified {
     publishedDatasources {
       name
       isCertified
       downstreamFlows {
         name,
         owner {
           name
         },
         projectName
       }
     }
   }
   """
 
     print("Logging into Tableau Server...")
     token = login()
     print("Session token is: " + token)
     print("")
     print("Running the following query:")
     print(query)
     print("")
     print("Answer below:")
 
     # here we get text
     json_string = run_query(token, query)
 
     # we parse the result as a json structure
     response_as_json = json.loads(json_string)
 
     # we print the json structure
     print(json.dumps(response_as_json, sort_keys=True, indent=4))
 
     # navigating the json structure to find the starting node we need
     list_of_published_ds = response_as_json["data"]["publishedDatasources"]
 
     # this array will contain the data we will return to Tableau Prep
     resultset = []
 
     # navigating the json structure and collecting data
     for ds in list_of_published_ds:
         for flow in ds["downstreamFlows"]:
             # when we find a downstream flow, we create one entry into the resultset
             resultset.append([ds["name"], flow["name"],
                               flow["owner"]["name"], flow["projectName"]])
 
     # print the resultset for debugging purposes
     print(resultset)
 
     # we turn this python array into a pandas dataframe
     df = pd.DataFrame(data=resultset, columns=[
                       "ds_name", "flow_name", "owner_name", "project_name"])
 
     # we return the dataframe to Tableau Prep
     return(df)
 def get_output_schema_bea97b3a58e648258274adfc99cd41f5(df = pd.DataFrame()):
     import inspect
     if len(inspect.getfullargspec(get_output_schema).args) == 0:
         return get_output_schema()
     else:
         return get_output_schema(df)
 result_schema_output = get_output_schema_bea97b3a58e648258274adfc99cd41f5(pd.DataFrame(_arg1))
 return result_schema_output.to_dict(orient='split') if isinstance(result_schema_output, pd.DataFrame) else result_schema_output

2021-01-28,13:48:04 [INFO] (web.py:web:2239): 200 POST /evaluate (172.18.0.1) 26.90ms
2021-01-28,13:48:04 [DEBUG] (base_handler.py:base_handler:115): Checking if need to handle authentication
2021-01-28,13:48:04 [DEBUG] (base_handler.py:base_handler:115): Handling authentication
2021-01-28,13:48:04 [INFO] (base_handler.py:base_handler:115): Authentication is not a required feature for API "v1"
2021-01-28,13:48:04 [DEBUG] (base_handler.py:base_handler:115): Checking request headers for authentication data
2021-01-28,13:48:04 [INFO] (base_handler.py:base_handler:115): Authorization header not found
2021-01-28,13:48:04 [DEBUG] (base_handler.py:base_handler:115): authentication not required, username and password are none
2021-01-28,13:48:04 [DEBUG] (state.py:state:511): Collecting Access-Control-Allow-Origin from state file ...
2021-01-28,13:48:04 [DEBUG] (state.py:state:613): Loading option 'Access-Control-Allow-Origin' from section [Service Info]...
2021-01-28,13:48:04 [DEBUG] (state.py:state:635): Returning value ''
2021-01-28,13:48:04 [DEBUG] (state.py:state:613): Loading option 'Access-Control-Allow-Headers' from section [Service Info]...
2021-01-28,13:48:04 [DEBUG] (state.py:state:635): Returning value ''
2021-01-28,13:48:04 [DEBUG] (state.py:state:613): Loading option 'Access-Control-Allow-Methods' from section [Service Info]...
2021-01-28,13:48:04 [DEBUG] (state.py:state:635): Returning value ''
2021-01-28,13:48:04 [DEBUG] (base_handler.py:base_handler:115): Processing POST request '{'data': {'_arg1': {'dummy': ['prep_string_type']}}, 'script': 'import pandas as pd\ndef get_output_schema():\n\treturn \'5e1663ee-aeb8-40e2-9e10-d7644bc9e928\'\ndef prep_string():\n\treturn [\'prep_string_type\']\ndef prep_bool():\n\treturn [\'prep_bool_type\']\ndef prep_int():\n\treturn [\'prep_int_type\']\ndef prep_decimal():\n    return [\'prep_decimal_type\']\ndef prep_date():\n\treturn [\'prep_date_type\']\ndef prep_datetime():\n\treturn [\'prep_datetime_type\']\n# os is used to retrieve environment variables\n# requests is used to make HTTP requests out to Tableau Server\n# json is used to parse the answer received from the Tableau metadata API\n# pandas is used to build a dataframe and return data to Tableau Prep\n\nimport os\nimport requests\nimport json\nimport pandas as pd\n\n\n# login will perform a login into Tableau Server and return a session token\n# it uses the API_SERVER, API_SECRET_TOKEN and API_TOKEN_NAME environment variables\n# see docker-compose.yml for these environment variables\n\ndef login():\n    body = {"credentials": {"personalAccessTokenName": os.environ[\'API_TOKEN_NAME\'],\n                            "personalAccessTokenSecret": os.environ[\'API_SECRET_TOKEN\'],\n                            "site": {"contentUrl": ""}}}\n\n    print("Performing login")\n\n    url = "https://{server}/api/3.9/auth/signin".format(\n        server=os.environ["API_SERVER"])\n\n    headers = {\n        \'accept\': \'application/json\',\n        \'content-type\': \'application/json\'\n    }\n\n    # making the request\n    x = requests.post(url, json=body, headers=headers)\n    # parsing the login response\n    response = json.loads(x.text)\n    # if everything goes well, session token is found here:\n    token = response["credentials"]["token"]\n\n    return token\n\n# run_query runs a GRAPHQL query against the Tableau metadata API\n# arguments are a session token (obtained with login function) and the query text\n# it uses the API_SERVER environment variable to connect to the server; see docker-compose.yml\n\n\ndef run_query(token, query):\n    uri = "https://{server}/api/metadata/graphql".format(\n        server=os.environ["API_SERVER"])\n    headers = {\n        \'content-type\': \'application/json\',\n        \'accept\': \'application/json\',\n        \'X-Tableau-Auth\': token\n    }\n    x = requests.post(uri, json={\'query\': query}, headers=headers)\n\n    # we print the plain text answer for debugging purposes\n    print(x.text)\n\n    # we return the plain text answer received\n    return x.text\n\n\n# This function is called by Tableau Prep to obtain the expected schema of the data to receive\ndef get_output_schema():\n    return pd.DataFrame({\n        \'ds_name\': prep_string(),\n        \'flow_name\': prep_string(),\n        \'owner_name\': prep_string(),\n        \'project_name\': prep_string()\n    })\n\n\n# This is the function we well name in a Tableau Prep script node\n# It received data on the input, but doesn\'t use it\n\ndef get_published_ds_used_in_flow(input):\n\n    # The hardcoded Graphql query\n    query = """query published_datasources_certified {\n    publishedDatasources {\n      name\n      isCertified\n      downstreamFlows {\n        name,\n        owner {\n          name\n        },\n        projectName\n      }\n    }\n  }\n  """\n\n    print("Logging into Tableau Server...")\n    token = login()\n    print("Session token is: " + token)\n    print("")\n    print("Running the following query:")\n    print(query)\n    print("")\n    print("Answer below:")\n\n    # here we get text\n    json_string = run_query(token, query)\n\n    # we parse the result as a json structure\n    response_as_json = json.loads(json_string)\n\n    # we print the json structure\n    print(json.dumps(response_as_json, sort_keys=True, indent=4))\n\n    # navigating the json structure to find the starting node we need\n    list_of_published_ds = response_as_json["data"]["publishedDatasources"]\n\n    # this array will contain the data we will return to Tableau Prep\n    resultset = []\n\n    # navigating the json structure and collecting data\n    for ds in list_of_published_ds:\n        for flow in ds["downstreamFlows"]:\n            # when we find a downstream flow, we create one entry into the resultset\n            resultset.append([ds["name"], flow["name"],\n                              flow["owner"]["name"], flow["projectName"]])\n\n    # print the resultset for debugging purposes\n    print(resultset)\n\n    # we turn this python array into a pandas dataframe\n    df = pd.DataFrame(data=resultset, columns=[\n                      "ds_name", "flow_name", "owner_name", "project_name"])\n\n    # we return the dataframe to Tableau Prep\n    return(df)\ndef get_output_schema_bea97b3a58e648258274adfc99cd41f5(df = pd.DataFrame()):\n    import inspect\n    if len(inspect.getfullargspec(get_output_schema).args) == 0:\n        return get_output_schema()\n    else:\n        return get_output_schema(df)\nresult_schema_output = get_output_schema_bea97b3a58e648258274adfc99cd41f5(pd.DataFrame(_arg1))\nreturn result_schema_output.to_dict(orient=\'split\') if isinstance(result_schema_output, pd.DataFrame) else result_schema_output'}'...
2021-01-28,13:48:04 [INFO] (base_handler.py:base_handler:115): function to evaluate=def _user_script(tabpy, _arg1):
 import pandas as pd
 def get_output_schema():
 	return '5e1663ee-aeb8-40e2-9e10-d7644bc9e928'
 def prep_string():
 	return ['prep_string_type']
 def prep_bool():
 	return ['prep_bool_type']
 def prep_int():
 	return ['prep_int_type']
 def prep_decimal():
     return ['prep_decimal_type']
 def prep_date():
 	return ['prep_date_type']
 def prep_datetime():
 	return ['prep_datetime_type']
 # os is used to retrieve environment variables
 # requests is used to make HTTP requests out to Tableau Server
 # json is used to parse the answer received from the Tableau metadata API
 # pandas is used to build a dataframe and return data to Tableau Prep
 
 import os
 import requests
 import json
 import pandas as pd
 
 
 # login will perform a login into Tableau Server and return a session token
 # it uses the API_SERVER, API_SECRET_TOKEN and API_TOKEN_NAME environment variables
 # see docker-compose.yml for these environment variables
 
 def login():
     body = {"credentials": {"personalAccessTokenName": os.environ['API_TOKEN_NAME'],
                             "personalAccessTokenSecret": os.environ['API_SECRET_TOKEN'],
                             "site": {"contentUrl": ""}}}
 
     print("Performing login")
 
     url = "https://{server}/api/3.9/auth/signin".format(
         server=os.environ["API_SERVER"])
 
     headers = {
         'accept': 'application/json',
         'content-type': 'application/json'
     }
 
     # making the request
     x = requests.post(url, json=body, headers=headers)
     # parsing the login response
     response = json.loads(x.text)
     # if everything goes well, session token is found here:
     token = response["credentials"]["token"]
 
     return token
 
 # run_query runs a GRAPHQL query against the Tableau metadata API
 # arguments are a session token (obtained with login function) and the query text
 # it uses the API_SERVER environment variable to connect to the server; see docker-compose.yml
 
 
 def run_query(token, query):
     uri = "https://{server}/api/metadata/graphql".format(
         server=os.environ["API_SERVER"])
     headers = {
         'content-type': 'application/json',
         'accept': 'application/json',
         'X-Tableau-Auth': token
     }
     x = requests.post(uri, json={'query': query}, headers=headers)
 
     # we print the plain text answer for debugging purposes
     print(x.text)
 
     # we return the plain text answer received
     return x.text
 
 
 # This function is called by Tableau Prep to obtain the expected schema of the data to receive
 def get_output_schema():
     return pd.DataFrame({
         'ds_name': prep_string(),
         'flow_name': prep_string(),
         'owner_name': prep_string(),
         'project_name': prep_string()
     })
 
 
 # This is the function we well name in a Tableau Prep script node
 # It received data on the input, but doesn't use it
 
 def get_published_ds_used_in_flow(input):
 
     # The hardcoded Graphql query
     query = """query published_datasources_certified {
     publishedDatasources {
       name
       isCertified
       downstreamFlows {
         name,
         owner {
           name
         },
         projectName
       }
     }
   }
   """
 
     print("Logging into Tableau Server...")
     token = login()
     print("Session token is: " + token)
     print("")
     print("Running the following query:")
     print(query)
     print("")
     print("Answer below:")
 
     # here we get text
     json_string = run_query(token, query)
 
     # we parse the result as a json structure
     response_as_json = json.loads(json_string)
 
     # we print the json structure
     print(json.dumps(response_as_json, sort_keys=True, indent=4))
 
     # navigating the json structure to find the starting node we need
     list_of_published_ds = response_as_json["data"]["publishedDatasources"]
 
     # this array will contain the data we will return to Tableau Prep
     resultset = []
 
     # navigating the json structure and collecting data
     for ds in list_of_published_ds:
         for flow in ds["downstreamFlows"]:
             # when we find a downstream flow, we create one entry into the resultset
             resultset.append([ds["name"], flow["name"],
                               flow["owner"]["name"], flow["projectName"]])
 
     # print the resultset for debugging purposes
     print(resultset)
 
     # we turn this python array into a pandas dataframe
     df = pd.DataFrame(data=resultset, columns=[
                       "ds_name", "flow_name", "owner_name", "project_name"])
 
     # we return the dataframe to Tableau Prep
     return(df)
 def get_output_schema_bea97b3a58e648258274adfc99cd41f5(df = pd.DataFrame()):
     import inspect
     if len(inspect.getfullargspec(get_output_schema).args) == 0:
         return get_output_schema()
     else:
         return get_output_schema(df)
 result_schema_output = get_output_schema_bea97b3a58e648258274adfc99cd41f5(pd.DataFrame(_arg1))
 return result_schema_output.to_dict(orient='split') if isinstance(result_schema_output, pd.DataFrame) else result_schema_output

2021-01-28,13:48:04 [INFO] (web.py:web:2239): 200 POST /evaluate (172.18.0.1) 26.14ms
2021-01-28,13:48:10 [DEBUG] (base_handler.py:base_handler:115): Checking if need to handle authentication
2021-01-28,13:48:10 [DEBUG] (base_handler.py:base_handler:115): Handling authentication
2021-01-28,13:48:10 [INFO] (base_handler.py:base_handler:115): Authentication is not a required feature for API "v1"
2021-01-28,13:48:10 [DEBUG] (base_handler.py:base_handler:115): Checking request headers for authentication data
2021-01-28,13:48:10 [INFO] (base_handler.py:base_handler:115): Authorization header not found
2021-01-28,13:48:10 [DEBUG] (base_handler.py:base_handler:115): authentication not required, username and password are none
2021-01-28,13:48:10 [DEBUG] (state.py:state:511): Collecting Access-Control-Allow-Origin from state file ...
2021-01-28,13:48:10 [DEBUG] (state.py:state:613): Loading option 'Access-Control-Allow-Origin' from section [Service Info]...
2021-01-28,13:48:10 [DEBUG] (state.py:state:635): Returning value ''
2021-01-28,13:48:10 [DEBUG] (state.py:state:613): Loading option 'Access-Control-Allow-Headers' from section [Service Info]...
2021-01-28,13:48:10 [DEBUG] (state.py:state:635): Returning value ''
2021-01-28,13:48:10 [DEBUG] (state.py:state:613): Loading option 'Access-Control-Allow-Methods' from section [Service Info]...
2021-01-28,13:48:10 [DEBUG] (state.py:state:635): Returning value ''
2021-01-28,13:48:10 [DEBUG] (base_handler.py:base_handler:115): Processing POST request '{'data': {'_arg1': {'dummy': ['prep_string_type']}}, 'script': 'import pandas as pd\ndef get_output_schema():\n\treturn \'5e1663ee-aeb8-40e2-9e10-d7644bc9e928\'\ndef prep_string():\n\treturn [\'prep_string_type\']\ndef prep_bool():\n\treturn [\'prep_bool_type\']\ndef prep_int():\n\treturn [\'prep_int_type\']\ndef prep_decimal():\n    return [\'prep_decimal_type\']\ndef prep_date():\n\treturn [\'prep_date_type\']\ndef prep_datetime():\n\treturn [\'prep_datetime_type\']\n# os is used to retrieve environment variables\n# requests is used to make HTTP requests out to Tableau Server\n# json is used to parse the answer received from the Tableau metadata API\n# pandas is used to build a dataframe and return data to Tableau Prep\n\nimport os\nimport requests\nimport json\nimport pandas as pd\n\n\n# login will perform a login into Tableau Server and return a session token\n# it uses the API_SERVER, API_SECRET_TOKEN and API_TOKEN_NAME environment variables\n# see docker-compose.yml for these environment variables\n\ndef login():\n    body = {"credentials": {"personalAccessTokenName": os.environ[\'API_TOKEN_NAME\'],\n                            "personalAccessTokenSecret": os.environ[\'API_SECRET_TOKEN\'],\n                            "site": {"contentUrl": ""}}}\n\n    print("Performing login")\n\n    url = "https://{server}/api/3.9/auth/signin".format(\n        server=os.environ["API_SERVER"])\n\n    headers = {\n        \'accept\': \'application/json\',\n        \'content-type\': \'application/json\'\n    }\n\n    # making the request\n    x = requests.post(url, json=body, headers=headers)\n    # parsing the login response\n    response = json.loads(x.text)\n    # if everything goes well, session token is found here:\n    token = response["credentials"]["token"]\n\n    return token\n\n# run_query runs a GRAPHQL query against the Tableau metadata API\n# arguments are a session token (obtained with login function) and the query text\n# it uses the API_SERVER environment variable to connect to the server; see docker-compose.yml\n\n\ndef run_query(token, query):\n    uri = "https://{server}/api/metadata/graphql".format(\n        server=os.environ["API_SERVER"])\n    headers = {\n        \'content-type\': \'application/json\',\n        \'accept\': \'application/json\',\n        \'X-Tableau-Auth\': token\n    }\n    x = requests.post(uri, json={\'query\': query}, headers=headers)\n\n    # we print the plain text answer for debugging purposes\n    print(x.text)\n\n    # we return the plain text answer received\n    return x.text\n\n\n# This function is called by Tableau Prep to obtain the expected schema of the data to receive\ndef get_output_schema():\n    return pd.DataFrame({\n        \'ds_name\': prep_string(),\n        \'flow_name\': prep_string(),\n        \'owner_name\': prep_string(),\n        \'project_name\': prep_string()\n    })\n\n\n# This is the function we well name in a Tableau Prep script node\n# It received data on the input, but doesn\'t use it\n\ndef get_published_ds_used_in_flow(input):\n\n    # The hardcoded Graphql query\n    query = """query published_datasources_certified {\n    publishedDatasources {\n      name\n      isCertified\n      downstreamFlows {\n        name,\n        owner {\n          name\n        },\n        projectName\n      }\n    }\n  }\n  """\n\n    print("Logging into Tableau Server...")\n    token = login()\n    print("Session token is: " + token)\n    print("")\n    print("Running the following query:")\n    print(query)\n    print("")\n    print("Answer below:")\n\n    # here we get text\n    json_string = run_query(token, query)\n\n    # we parse the result as a json structure\n    response_as_json = json.loads(json_string)\n\n    # we print the json structure\n    print(json.dumps(response_as_json, sort_keys=True, indent=4))\n\n    # navigating the json structure to find the starting node we need\n    list_of_published_ds = response_as_json["data"]["publishedDatasources"]\n\n    # this array will contain the data we will return to Tableau Prep\n    resultset = []\n\n    # navigating the json structure and collecting data\n    for ds in list_of_published_ds:\n        for flow in ds["downstreamFlows"]:\n            # when we find a downstream flow, we create one entry into the resultset\n            resultset.append([ds["name"], flow["name"],\n                              flow["owner"]["name"], flow["projectName"]])\n\n    # print the resultset for debugging purposes\n    print(resultset)\n\n    # we turn this python array into a pandas dataframe\n    df = pd.DataFrame(data=resultset, columns=[\n                      "ds_name", "flow_name", "owner_name", "project_name"])\n\n    # we return the dataframe to Tableau Prep\n    return(df)\ndef get_output_schema_bea97b3a58e648258274adfc99cd41f5(df = pd.DataFrame()):\n    import inspect\n    if len(inspect.getfullargspec(get_output_schema).args) == 0:\n        return get_output_schema()\n    else:\n        return get_output_schema(df)\nresult_schema_output = get_output_schema_bea97b3a58e648258274adfc99cd41f5(pd.DataFrame(_arg1))\nreturn result_schema_output.to_dict(orient=\'split\') if isinstance(result_schema_output, pd.DataFrame) else result_schema_output'}'...
2021-01-28,13:48:10 [INFO] (base_handler.py:base_handler:115): function to evaluate=def _user_script(tabpy, _arg1):
 import pandas as pd
 def get_output_schema():
 	return '5e1663ee-aeb8-40e2-9e10-d7644bc9e928'
 def prep_string():
 	return ['prep_string_type']
 def prep_bool():
 	return ['prep_bool_type']
 def prep_int():
 	return ['prep_int_type']
 def prep_decimal():
     return ['prep_decimal_type']
 def prep_date():
 	return ['prep_date_type']
 def prep_datetime():
 	return ['prep_datetime_type']
 # os is used to retrieve environment variables
 # requests is used to make HTTP requests out to Tableau Server
 # json is used to parse the answer received from the Tableau metadata API
 # pandas is used to build a dataframe and return data to Tableau Prep
 
 import os
 import requests
 import json
 import pandas as pd
 
 
 # login will perform a login into Tableau Server and return a session token
 # it uses the API_SERVER, API_SECRET_TOKEN and API_TOKEN_NAME environment variables
 # see docker-compose.yml for these environment variables
 
 def login():
     body = {"credentials": {"personalAccessTokenName": os.environ['API_TOKEN_NAME'],
                             "personalAccessTokenSecret": os.environ['API_SECRET_TOKEN'],
                             "site": {"contentUrl": ""}}}
 
     print("Performing login")
 
     url = "https://{server}/api/3.9/auth/signin".format(
         server=os.environ["API_SERVER"])
 
     headers = {
         'accept': 'application/json',
         'content-type': 'application/json'
     }
 
     # making the request
     x = requests.post(url, json=body, headers=headers)
     # parsing the login response
     response = json.loads(x.text)
     # if everything goes well, session token is found here:
     token = response["credentials"]["token"]
 
     return token
 
 # run_query runs a GRAPHQL query against the Tableau metadata API
 # arguments are a session token (obtained with login function) and the query text
 # it uses the API_SERVER environment variable to connect to the server; see docker-compose.yml
 
 
 def run_query(token, query):
     uri = "https://{server}/api/metadata/graphql".format(
         server=os.environ["API_SERVER"])
     headers = {
         'content-type': 'application/json',
         'accept': 'application/json',
         'X-Tableau-Auth': token
     }
     x = requests.post(uri, json={'query': query}, headers=headers)
 
     # we print the plain text answer for debugging purposes
     print(x.text)
 
     # we return the plain text answer received
     return x.text
 
 
 # This function is called by Tableau Prep to obtain the expected schema of the data to receive
 def get_output_schema():
     return pd.DataFrame({
         'ds_name': prep_string(),
         'flow_name': prep_string(),
         'owner_name': prep_string(),
         'project_name': prep_string()
     })
 
 
 # This is the function we well name in a Tableau Prep script node
 # It received data on the input, but doesn't use it
 
 def get_published_ds_used_in_flow(input):
 
     # The hardcoded Graphql query
     query = """query published_datasources_certified {
     publishedDatasources {
       name
       isCertified
       downstreamFlows {
         name,
         owner {
           name
         },
         projectName
       }
     }
   }
   """
 
     print("Logging into Tableau Server...")
     token = login()
     print("Session token is: " + token)
     print("")
     print("Running the following query:")
     print(query)
     print("")
     print("Answer below:")
 
     # here we get text
     json_string = run_query(token, query)
 
     # we parse the result as a json structure
     response_as_json = json.loads(json_string)
 
     # we print the json structure
     print(json.dumps(response_as_json, sort_keys=True, indent=4))
 
     # navigating the json structure to find the starting node we need
     list_of_published_ds = response_as_json["data"]["publishedDatasources"]
 
     # this array will contain the data we will return to Tableau Prep
     resultset = []
 
     # navigating the json structure and collecting data
     for ds in list_of_published_ds:
         for flow in ds["downstreamFlows"]:
             # when we find a downstream flow, we create one entry into the resultset
             resultset.append([ds["name"], flow["name"],
                               flow["owner"]["name"], flow["projectName"]])
 
     # print the resultset for debugging purposes
     print(resultset)
 
     # we turn this python array into a pandas dataframe
     df = pd.DataFrame(data=resultset, columns=[
                       "ds_name", "flow_name", "owner_name", "project_name"])
 
     # we return the dataframe to Tableau Prep
     return(df)
 def get_output_schema_bea97b3a58e648258274adfc99cd41f5(df = pd.DataFrame()):
     import inspect
     if len(inspect.getfullargspec(get_output_schema).args) == 0:
         return get_output_schema()
     else:
         return get_output_schema(df)
 result_schema_output = get_output_schema_bea97b3a58e648258274adfc99cd41f5(pd.DataFrame(_arg1))
 return result_schema_output.to_dict(orient='split') if isinstance(result_schema_output, pd.DataFrame) else result_schema_output

2021-01-28,13:48:10 [DEBUG] (base_handler.py:base_handler:115): Checking if need to handle authentication
2021-01-28,13:48:10 [DEBUG] (base_handler.py:base_handler:115): Handling authentication
2021-01-28,13:48:10 [INFO] (base_handler.py:base_handler:115): Authentication is not a required feature for API "v1"
2021-01-28,13:48:10 [DEBUG] (base_handler.py:base_handler:115): Checking request headers for authentication data
2021-01-28,13:48:10 [INFO] (base_handler.py:base_handler:115): Authorization header not found
2021-01-28,13:48:10 [DEBUG] (base_handler.py:base_handler:115): authentication not required, username and password are none
2021-01-28,13:48:10 [DEBUG] (state.py:state:511): Collecting Access-Control-Allow-Origin from state file ...
2021-01-28,13:48:10 [DEBUG] (state.py:state:613): Loading option 'Access-Control-Allow-Origin' from section [Service Info]...
2021-01-28,13:48:10 [DEBUG] (state.py:state:635): Returning value ''
2021-01-28,13:48:10 [DEBUG] (state.py:state:613): Loading option 'Access-Control-Allow-Headers' from section [Service Info]...
2021-01-28,13:48:10 [DEBUG] (state.py:state:635): Returning value ''
2021-01-28,13:48:10 [DEBUG] (state.py:state:613): Loading option 'Access-Control-Allow-Methods' from section [Service Info]...
2021-01-28,13:48:10 [DEBUG] (state.py:state:635): Returning value ''
2021-01-28,13:48:10 [DEBUG] (base_handler.py:base_handler:115): Processing POST request '{'data': {'_arg1': {'dummy': ['prep_string_type']}}, 'script': 'import pandas as pd\ndef get_output_schema():\n\treturn \'5e1663ee-aeb8-40e2-9e10-d7644bc9e928\'\ndef prep_string():\n\treturn [\'prep_string_type\']\ndef prep_bool():\n\treturn [\'prep_bool_type\']\ndef prep_int():\n\treturn [\'prep_int_type\']\ndef prep_decimal():\n    return [\'prep_decimal_type\']\ndef prep_date():\n\treturn [\'prep_date_type\']\ndef prep_datetime():\n\treturn [\'prep_datetime_type\']\n# os is used to retrieve environment variables\n# requests is used to make HTTP requests out to Tableau Server\n# json is used to parse the answer received from the Tableau metadata API\n# pandas is used to build a dataframe and return data to Tableau Prep\n\nimport os\nimport requests\nimport json\nimport pandas as pd\n\n\n# login will perform a login into Tableau Server and return a session token\n# it uses the API_SERVER, API_SECRET_TOKEN and API_TOKEN_NAME environment variables\n# see docker-compose.yml for these environment variables\n\ndef login():\n    body = {"credentials": {"personalAccessTokenName": os.environ[\'API_TOKEN_NAME\'],\n                            "personalAccessTokenSecret": os.environ[\'API_SECRET_TOKEN\'],\n                            "site": {"contentUrl": ""}}}\n\n    print("Performing login")\n\n    url = "https://{server}/api/3.9/auth/signin".format(\n        server=os.environ["API_SERVER"])\n\n    headers = {\n        \'accept\': \'application/json\',\n        \'content-type\': \'application/json\'\n    }\n\n    # making the request\n    x = requests.post(url, json=body, headers=headers)\n    # parsing the login response\n    response = json.loads(x.text)\n    # if everything goes well, session token is found here:\n    token = response["credentials"]["token"]\n\n    return token\n\n# run_query runs a GRAPHQL query against the Tableau metadata API\n# arguments are a session token (obtained with login function) and the query text\n# it uses the API_SERVER environment variable to connect to the server; see docker-compose.yml\n\n\ndef run_query(token, query):\n    uri = "https://{server}/api/metadata/graphql".format(\n        server=os.environ["API_SERVER"])\n    headers = {\n        \'content-type\': \'application/json\',\n        \'accept\': \'application/json\',\n        \'X-Tableau-Auth\': token\n    }\n    x = requests.post(uri, json={\'query\': query}, headers=headers)\n\n    # we print the plain text answer for debugging purposes\n    print(x.text)\n\n    # we return the plain text answer received\n    return x.text\n\n\n# This function is called by Tableau Prep to obtain the expected schema of the data to receive\ndef get_output_schema():\n    return pd.DataFrame({\n        \'ds_name\': prep_string(),\n        \'flow_name\': prep_string(),\n        \'owner_name\': prep_string(),\n        \'project_name\': prep_string()\n    })\n\n\n# This is the function we well name in a Tableau Prep script node\n# It received data on the input, but doesn\'t use it\n\ndef get_published_ds_used_in_flow(input):\n\n    # The hardcoded Graphql query\n    query = """query published_datasources_certified {\n    publishedDatasources {\n      name\n      isCertified\n      downstreamFlows {\n        name,\n        owner {\n          name\n        },\n        projectName\n      }\n    }\n  }\n  """\n\n    print("Logging into Tableau Server...")\n    token = login()\n    print("Session token is: " + token)\n    print("")\n    print("Running the following query:")\n    print(query)\n    print("")\n    print("Answer below:")\n\n    # here we get text\n    json_string = run_query(token, query)\n\n    # we parse the result as a json structure\n    response_as_json = json.loads(json_string)\n\n    # we print the json structure\n    print(json.dumps(response_as_json, sort_keys=True, indent=4))\n\n    # navigating the json structure to find the starting node we need\n    list_of_published_ds = response_as_json["data"]["publishedDatasources"]\n\n    # this array will contain the data we will return to Tableau Prep\n    resultset = []\n\n    # navigating the json structure and collecting data\n    for ds in list_of_published_ds:\n        for flow in ds["downstreamFlows"]:\n            # when we find a downstream flow, we create one entry into the resultset\n            resultset.append([ds["name"], flow["name"],\n                              flow["owner"]["name"], flow["projectName"]])\n\n    # print the resultset for debugging purposes\n    print(resultset)\n\n    # we turn this python array into a pandas dataframe\n    df = pd.DataFrame(data=resultset, columns=[\n                      "ds_name", "flow_name", "owner_name", "project_name"])\n\n    # we return the dataframe to Tableau Prep\n    return(df)\ndef get_output_schema_bea97b3a58e648258274adfc99cd41f5(df = pd.DataFrame()):\n    import inspect\n    if len(inspect.getfullargspec(get_output_schema).args) == 0:\n        return get_output_schema()\n    else:\n        return get_output_schema(df)\nresult_schema_output = get_output_schema_bea97b3a58e648258274adfc99cd41f5(pd.DataFrame(_arg1))\nreturn result_schema_output.to_dict(orient=\'split\') if isinstance(result_schema_output, pd.DataFrame) else result_schema_output'}'...
2021-01-28,13:48:10 [INFO] (base_handler.py:base_handler:115): function to evaluate=def _user_script(tabpy, _arg1):
 import pandas as pd
 def get_output_schema():
 	return '5e1663ee-aeb8-40e2-9e10-d7644bc9e928'
 def prep_string():
 	return ['prep_string_type']
 def prep_bool():
 	return ['prep_bool_type']
 def prep_int():
 	return ['prep_int_type']
 def prep_decimal():
     return ['prep_decimal_type']
 def prep_date():
 	return ['prep_date_type']
 def prep_datetime():
 	return ['prep_datetime_type']
 # os is used to retrieve environment variables
 # requests is used to make HTTP requests out to Tableau Server
 # json is used to parse the answer received from the Tableau metadata API
 # pandas is used to build a dataframe and return data to Tableau Prep
 
 import os
 import requests
 import json
 import pandas as pd
 
 
 # login will perform a login into Tableau Server and return a session token
 # it uses the API_SERVER, API_SECRET_TOKEN and API_TOKEN_NAME environment variables
 # see docker-compose.yml for these environment variables
 
 def login():
     body = {"credentials": {"personalAccessTokenName": os.environ['API_TOKEN_NAME'],
                             "personalAccessTokenSecret": os.environ['API_SECRET_TOKEN'],
                             "site": {"contentUrl": ""}}}
 
     print("Performing login")
 
     url = "https://{server}/api/3.9/auth/signin".format(
         server=os.environ["API_SERVER"])
 
     headers = {
         'accept': 'application/json',
         'content-type': 'application/json'
     }
 
     # making the request
     x = requests.post(url, json=body, headers=headers)
     # parsing the login response
     response = json.loads(x.text)
     # if everything goes well, session token is found here:
     token = response["credentials"]["token"]
 
     return token
 
 # run_query runs a GRAPHQL query against the Tableau metadata API
 # arguments are a session token (obtained with login function) and the query text
 # it uses the API_SERVER environment variable to connect to the server; see docker-compose.yml
 
 
 def run_query(token, query):
     uri = "https://{server}/api/metadata/graphql".format(
         server=os.environ["API_SERVER"])
     headers = {
         'content-type': 'application/json',
         'accept': 'application/json',
         'X-Tableau-Auth': token
     }
     x = requests.post(uri, json={'query': query}, headers=headers)
 
     # we print the plain text answer for debugging purposes
     print(x.text)
 
     # we return the plain text answer received
     return x.text
 
 
 # This function is called by Tableau Prep to obtain the expected schema of the data to receive
 def get_output_schema():
     return pd.DataFrame({
         'ds_name': prep_string(),
         'flow_name': prep_string(),
         'owner_name': prep_string(),
         'project_name': prep_string()
     })
 
 
 # This is the function we well name in a Tableau Prep script node
 # It received data on the input, but doesn't use it
 
 def get_published_ds_used_in_flow(input):
 
     # The hardcoded Graphql query
     query = """query published_datasources_certified {
     publishedDatasources {
       name
       isCertified
       downstreamFlows {
         name,
         owner {
           name
         },
         projectName
       }
     }
   }
   """
 
     print("Logging into Tableau Server...")
     token = login()
     print("Session token is: " + token)
     print("")
     print("Running the following query:")
     print(query)
     print("")
     print("Answer below:")
 
     # here we get text
     json_string = run_query(token, query)
 
     # we parse the result as a json structure
     response_as_json = json.loads(json_string)
 
     # we print the json structure
     print(json.dumps(response_as_json, sort_keys=True, indent=4))
 
     # navigating the json structure to find the starting node we need
     list_of_published_ds = response_as_json["data"]["publishedDatasources"]
 
     # this array will contain the data we will return to Tableau Prep
     resultset = []
 
     # navigating the json structure and collecting data
     for ds in list_of_published_ds:
         for flow in ds["downstreamFlows"]:
             # when we find a downstream flow, we create one entry into the resultset
             resultset.append([ds["name"], flow["name"],
                               flow["owner"]["name"], flow["projectName"]])
 
     # print the resultset for debugging purposes
     print(resultset)
 
     # we turn this python array into a pandas dataframe
     df = pd.DataFrame(data=resultset, columns=[
                       "ds_name", "flow_name", "owner_name", "project_name"])
 
     # we return the dataframe to Tableau Prep
     return(df)
 def get_output_schema_bea97b3a58e648258274adfc99cd41f5(df = pd.DataFrame()):
     import inspect
     if len(inspect.getfullargspec(get_output_schema).args) == 0:
         return get_output_schema()
     else:
         return get_output_schema(df)
 result_schema_output = get_output_schema_bea97b3a58e648258274adfc99cd41f5(pd.DataFrame(_arg1))
 return result_schema_output.to_dict(orient='split') if isinstance(result_schema_output, pd.DataFrame) else result_schema_output

2021-01-28,13:48:10 [INFO] (web.py:web:2239): 200 POST /evaluate (172.18.0.1) 52.26ms
2021-01-28,13:48:10 [DEBUG] (base_handler.py:base_handler:115): Checking if need to handle authentication
2021-01-28,13:48:10 [DEBUG] (base_handler.py:base_handler:115): Handling authentication
2021-01-28,13:48:10 [INFO] (base_handler.py:base_handler:115): Authentication is not a required feature for API "v1"
2021-01-28,13:48:10 [DEBUG] (base_handler.py:base_handler:115): Checking request headers for authentication data
2021-01-28,13:48:10 [INFO] (base_handler.py:base_handler:115): Authorization header not found
2021-01-28,13:48:10 [DEBUG] (base_handler.py:base_handler:115): authentication not required, username and password are none
2021-01-28,13:48:10 [INFO] (web.py:web:2239): 200 POST /evaluate (172.18.0.1) 30.32ms
2021-01-28,13:48:10 [DEBUG] (state.py:state:511): Collecting Access-Control-Allow-Origin from state file ...
2021-01-28,13:48:10 [DEBUG] (state.py:state:613): Loading option 'Access-Control-Allow-Origin' from section [Service Info]...
2021-01-28,13:48:10 [DEBUG] (state.py:state:635): Returning value ''
2021-01-28,13:48:10 [DEBUG] (state.py:state:613): Loading option 'Access-Control-Allow-Headers' from section [Service Info]...
2021-01-28,13:48:10 [DEBUG] (state.py:state:635): Returning value ''
2021-01-28,13:48:10 [DEBUG] (state.py:state:613): Loading option 'Access-Control-Allow-Methods' from section [Service Info]...
2021-01-28,13:48:10 [DEBUG] (state.py:state:635): Returning value ''
2021-01-28,13:48:10 [DEBUG] (base_handler.py:base_handler:115): Processing POST request '{'data': {'_arg1': {'dummy': ['prep_string_type']}}, 'script': 'import pandas as pd\ndef get_output_schema():\n\treturn \'5e1663ee-aeb8-40e2-9e10-d7644bc9e928\'\ndef prep_string():\n\treturn [\'prep_string_type\']\ndef prep_bool():\n\treturn [\'prep_bool_type\']\ndef prep_int():\n\treturn [\'prep_int_type\']\ndef prep_decimal():\n    return [\'prep_decimal_type\']\ndef prep_date():\n\treturn [\'prep_date_type\']\ndef prep_datetime():\n\treturn [\'prep_datetime_type\']\n# os is used to retrieve environment variables\n# requests is used to make HTTP requests out to Tableau Server\n# json is used to parse the answer received from the Tableau metadata API\n# pandas is used to build a dataframe and return data to Tableau Prep\n\nimport os\nimport requests\nimport json\nimport pandas as pd\n\n\n# login will perform a login into Tableau Server and return a session token\n# it uses the API_SERVER, API_SECRET_TOKEN and API_TOKEN_NAME environment variables\n# see docker-compose.yml for these environment variables\n\ndef login():\n    body = {"credentials": {"personalAccessTokenName": os.environ[\'API_TOKEN_NAME\'],\n                            "personalAccessTokenSecret": os.environ[\'API_SECRET_TOKEN\'],\n                            "site": {"contentUrl": ""}}}\n\n    print("Performing login")\n\n    url = "https://{server}/api/3.9/auth/signin".format(\n        server=os.environ["API_SERVER"])\n\n    headers = {\n        \'accept\': \'application/json\',\n        \'content-type\': \'application/json\'\n    }\n\n    # making the request\n    x = requests.post(url, json=body, headers=headers)\n    # parsing the login response\n    response = json.loads(x.text)\n    # if everything goes well, session token is found here:\n    token = response["credentials"]["token"]\n\n    return token\n\n# run_query runs a GRAPHQL query against the Tableau metadata API\n# arguments are a session token (obtained with login function) and the query text\n# it uses the API_SERVER environment variable to connect to the server; see docker-compose.yml\n\n\ndef run_query(token, query):\n    uri = "https://{server}/api/metadata/graphql".format(\n        server=os.environ["API_SERVER"])\n    headers = {\n        \'content-type\': \'application/json\',\n        \'accept\': \'application/json\',\n        \'X-Tableau-Auth\': token\n    }\n    x = requests.post(uri, json={\'query\': query}, headers=headers)\n\n    # we print the plain text answer for debugging purposes\n    print(x.text)\n\n    # we return the plain text answer received\n    return x.text\n\n\n# This function is called by Tableau Prep to obtain the expected schema of the data to receive\ndef get_output_schema():\n    return pd.DataFrame({\n        \'ds_name\': prep_string(),\n        \'flow_name\': prep_string(),\n        \'owner_name\': prep_string(),\n        \'project_name\': prep_string()\n    })\n\n\n# This is the function we well name in a Tableau Prep script node\n# It received data on the input, but doesn\'t use it\n\ndef get_published_ds_used_in_flow(input):\n\n    # The hardcoded Graphql query\n    query = """query published_datasources_certified {\n    publishedDatasources {\n      name\n      isCertified\n      downstreamFlows {\n        name,\n        owner {\n          name\n        },\n        projectName\n      }\n    }\n  }\n  """\n\n    print("Logging into Tableau Server...")\n    token = login()\n    print("Session token is: " + token)\n    print("")\n    print("Running the following query:")\n    print(query)\n    print("")\n    print("Answer below:")\n\n    # here we get text\n    json_string = run_query(token, query)\n\n    # we parse the result as a json structure\n    response_as_json = json.loads(json_string)\n\n    # we print the json structure\n    print(json.dumps(response_as_json, sort_keys=True, indent=4))\n\n    # navigating the json structure to find the starting node we need\n    list_of_published_ds = response_as_json["data"]["publishedDatasources"]\n\n    # this array will contain the data we will return to Tableau Prep\n    resultset = []\n\n    # navigating the json structure and collecting data\n    for ds in list_of_published_ds:\n        for flow in ds["downstreamFlows"]:\n            # when we find a downstream flow, we create one entry into the resultset\n            resultset.append([ds["name"], flow["name"],\n                              flow["owner"]["name"], flow["projectName"]])\n\n    # print the resultset for debugging purposes\n    print(resultset)\n\n    # we turn this python array into a pandas dataframe\n    df = pd.DataFrame(data=resultset, columns=[\n                      "ds_name", "flow_name", "owner_name", "project_name"])\n\n    # we return the dataframe to Tableau Prep\n    return(df)\ndef get_output_schema_bea97b3a58e648258274adfc99cd41f5(df = pd.DataFrame()):\n    import inspect\n    if len(inspect.getfullargspec(get_output_schema).args) == 0:\n        return get_output_schema()\n    else:\n        return get_output_schema(df)\nresult_schema_output = get_output_schema_bea97b3a58e648258274adfc99cd41f5(pd.DataFrame(_arg1))\nreturn result_schema_output.to_dict(orient=\'split\') if isinstance(result_schema_output, pd.DataFrame) else result_schema_output'}'...
2021-01-28,13:48:10 [INFO] (base_handler.py:base_handler:115): function to evaluate=def _user_script(tabpy, _arg1):
 import pandas as pd
 def get_output_schema():
 	return '5e1663ee-aeb8-40e2-9e10-d7644bc9e928'
 def prep_string():
 	return ['prep_string_type']
 def prep_bool():
 	return ['prep_bool_type']
 def prep_int():
 	return ['prep_int_type']
 def prep_decimal():
     return ['prep_decimal_type']
 def prep_date():
 	return ['prep_date_type']
 def prep_datetime():
 	return ['prep_datetime_type']
 # os is used to retrieve environment variables
 # requests is used to make HTTP requests out to Tableau Server
 # json is used to parse the answer received from the Tableau metadata API
 # pandas is used to build a dataframe and return data to Tableau Prep
 
 import os
 import requests
 import json
 import pandas as pd
 
 
 # login will perform a login into Tableau Server and return a session token
 # it uses the API_SERVER, API_SECRET_TOKEN and API_TOKEN_NAME environment variables
 # see docker-compose.yml for these environment variables
 
 def login():
     body = {"credentials": {"personalAccessTokenName": os.environ['API_TOKEN_NAME'],
                             "personalAccessTokenSecret": os.environ['API_SECRET_TOKEN'],
                             "site": {"contentUrl": ""}}}
 
     print("Performing login")
 
     url = "https://{server}/api/3.9/auth/signin".format(
         server=os.environ["API_SERVER"])
 
     headers = {
         'accept': 'application/json',
         'content-type': 'application/json'
     }
 
     # making the request
     x = requests.post(url, json=body, headers=headers)
     # parsing the login response
     response = json.loads(x.text)
     # if everything goes well, session token is found here:
     token = response["credentials"]["token"]
 
     return token
 
 # run_query runs a GRAPHQL query against the Tableau metadata API
 # arguments are a session token (obtained with login function) and the query text
 # it uses the API_SERVER environment variable to connect to the server; see docker-compose.yml
 
 
 def run_query(token, query):
     uri = "https://{server}/api/metadata/graphql".format(
         server=os.environ["API_SERVER"])
     headers = {
         'content-type': 'application/json',
         'accept': 'application/json',
         'X-Tableau-Auth': token
     }
     x = requests.post(uri, json={'query': query}, headers=headers)
 
     # we print the plain text answer for debugging purposes
     print(x.text)
 
     # we return the plain text answer received
     return x.text
 
 
 # This function is called by Tableau Prep to obtain the expected schema of the data to receive
 def get_output_schema():
     return pd.DataFrame({
         'ds_name': prep_string(),
         'flow_name': prep_string(),
         'owner_name': prep_string(),
         'project_name': prep_string()
     })
 
 
 # This is the function we well name in a Tableau Prep script node
 # It received data on the input, but doesn't use it
 
 def get_published_ds_used_in_flow(input):
 
     # The hardcoded Graphql query
     query = """query published_datasources_certified {
     publishedDatasources {
       name
       isCertified
       downstreamFlows {
         name,
         owner {
           name
         },
         projectName
       }
     }
   }
   """
 
     print("Logging into Tableau Server...")
     token = login()
     print("Session token is: " + token)
     print("")
     print("Running the following query:")
     print(query)
     print("")
     print("Answer below:")
 
     # here we get text
     json_string = run_query(token, query)
 
     # we parse the result as a json structure
     response_as_json = json.loads(json_string)
 
     # we print the json structure
     print(json.dumps(response_as_json, sort_keys=True, indent=4))
 
     # navigating the json structure to find the starting node we need
     list_of_published_ds = response_as_json["data"]["publishedDatasources"]
 
     # this array will contain the data we will return to Tableau Prep
     resultset = []
 
     # navigating the json structure and collecting data
     for ds in list_of_published_ds:
         for flow in ds["downstreamFlows"]:
             # when we find a downstream flow, we create one entry into the resultset
             resultset.append([ds["name"], flow["name"],
                               flow["owner"]["name"], flow["projectName"]])
 
     # print the resultset for debugging purposes
     print(resultset)
 
     # we turn this python array into a pandas dataframe
     df = pd.DataFrame(data=resultset, columns=[
                       "ds_name", "flow_name", "owner_name", "project_name"])
 
     # we return the dataframe to Tableau Prep
     return(df)
 def get_output_schema_bea97b3a58e648258274adfc99cd41f5(df = pd.DataFrame()):
     import inspect
     if len(inspect.getfullargspec(get_output_schema).args) == 0:
         return get_output_schema()
     else:
         return get_output_schema(df)
 result_schema_output = get_output_schema_bea97b3a58e648258274adfc99cd41f5(pd.DataFrame(_arg1))
 return result_schema_output.to_dict(orient='split') if isinstance(result_schema_output, pd.DataFrame) else result_schema_output

2021-01-28,13:48:10 [DEBUG] (base_handler.py:base_handler:115): Checking if need to handle authentication
2021-01-28,13:48:10 [DEBUG] (base_handler.py:base_handler:115): Handling authentication
2021-01-28,13:48:10 [INFO] (base_handler.py:base_handler:115): Authentication is not a required feature for API "v1"
2021-01-28,13:48:10 [DEBUG] (base_handler.py:base_handler:115): Checking request headers for authentication data
2021-01-28,13:48:10 [INFO] (base_handler.py:base_handler:115): Authorization header not found
2021-01-28,13:48:10 [DEBUG] (base_handler.py:base_handler:115): authentication not required, username and password are none
2021-01-28,13:48:10 [DEBUG] (state.py:state:511): Collecting Access-Control-Allow-Origin from state file ...
2021-01-28,13:48:10 [DEBUG] (state.py:state:613): Loading option 'Access-Control-Allow-Origin' from section [Service Info]...
2021-01-28,13:48:10 [DEBUG] (state.py:state:635): Returning value ''
2021-01-28,13:48:10 [DEBUG] (state.py:state:613): Loading option 'Access-Control-Allow-Headers' from section [Service Info]...
2021-01-28,13:48:10 [DEBUG] (state.py:state:635): Returning value ''
2021-01-28,13:48:10 [DEBUG] (state.py:state:613): Loading option 'Access-Control-Allow-Methods' from section [Service Info]...
2021-01-28,13:48:10 [DEBUG] (state.py:state:635): Returning value ''
2021-01-28,13:48:10 [DEBUG] (base_handler.py:base_handler:115): Processing POST request '{'data': {'_arg1': {'dummy': ['prep_string_type']}}, 'script': 'import pandas as pd\ndef get_output_schema():\n\treturn \'5e1663ee-aeb8-40e2-9e10-d7644bc9e928\'\ndef prep_string():\n\treturn [\'prep_string_type\']\ndef prep_bool():\n\treturn [\'prep_bool_type\']\ndef prep_int():\n\treturn [\'prep_int_type\']\ndef prep_decimal():\n    return [\'prep_decimal_type\']\ndef prep_date():\n\treturn [\'prep_date_type\']\ndef prep_datetime():\n\treturn [\'prep_datetime_type\']\n# os is used to retrieve environment variables\n# requests is used to make HTTP requests out to Tableau Server\n# json is used to parse the answer received from the Tableau metadata API\n# pandas is used to build a dataframe and return data to Tableau Prep\n\nimport os\nimport requests\nimport json\nimport pandas as pd\n\n\n# login will perform a login into Tableau Server and return a session token\n# it uses the API_SERVER, API_SECRET_TOKEN and API_TOKEN_NAME environment variables\n# see docker-compose.yml for these environment variables\n\ndef login():\n    body = {"credentials": {"personalAccessTokenName": os.environ[\'API_TOKEN_NAME\'],\n                            "personalAccessTokenSecret": os.environ[\'API_SECRET_TOKEN\'],\n                            "site": {"contentUrl": ""}}}\n\n    print("Performing login")\n\n    url = "https://{server}/api/3.9/auth/signin".format(\n        server=os.environ["API_SERVER"])\n\n    headers = {\n        \'accept\': \'application/json\',\n        \'content-type\': \'application/json\'\n    }\n\n    # making the request\n    x = requests.post(url, json=body, headers=headers)\n    # parsing the login response\n    response = json.loads(x.text)\n    # if everything goes well, session token is found here:\n    token = response["credentials"]["token"]\n\n    return token\n\n# run_query runs a GRAPHQL query against the Tableau metadata API\n# arguments are a session token (obtained with login function) and the query text\n# it uses the API_SERVER environment variable to connect to the server; see docker-compose.yml\n\n\ndef run_query(token, query):\n    uri = "https://{server}/api/metadata/graphql".format(\n        server=os.environ["API_SERVER"])\n    headers = {\n        \'content-type\': \'application/json\',\n        \'accept\': \'application/json\',\n        \'X-Tableau-Auth\': token\n    }\n    x = requests.post(uri, json={\'query\': query}, headers=headers)\n\n    # we print the plain text answer for debugging purposes\n    print(x.text)\n\n    # we return the plain text answer received\n    return x.text\n\n\n# This function is called by Tableau Prep to obtain the expected schema of the data to receive\ndef get_output_schema():\n    return pd.DataFrame({\n        \'ds_name\': prep_string(),\n        \'flow_name\': prep_string(),\n        \'owner_name\': prep_string(),\n        \'project_name\': prep_string()\n    })\n\n\n# This is the function we well name in a Tableau Prep script node\n# It received data on the input, but doesn\'t use it\n\ndef get_published_ds_used_in_flow(input):\n\n    # The hardcoded Graphql query\n    query = """query published_datasources_certified {\n    publishedDatasources {\n      name\n      isCertified\n      downstreamFlows {\n        name,\n        owner {\n          name\n        },\n        projectName\n      }\n    }\n  }\n  """\n\n    print("Logging into Tableau Server...")\n    token = login()\n    print("Session token is: " + token)\n    print("")\n    print("Running the following query:")\n    print(query)\n    print("")\n    print("Answer below:")\n\n    # here we get text\n    json_string = run_query(token, query)\n\n    # we parse the result as a json structure\n    response_as_json = json.loads(json_string)\n\n    # we print the json structure\n    print(json.dumps(response_as_json, sort_keys=True, indent=4))\n\n    # navigating the json structure to find the starting node we need\n    list_of_published_ds = response_as_json["data"]["publishedDatasources"]\n\n    # this array will contain the data we will return to Tableau Prep\n    resultset = []\n\n    # navigating the json structure and collecting data\n    for ds in list_of_published_ds:\n        for flow in ds["downstreamFlows"]:\n            # when we find a downstream flow, we create one entry into the resultset\n            resultset.append([ds["name"], flow["name"],\n                              flow["owner"]["name"], flow["projectName"]])\n\n    # print the resultset for debugging purposes\n    print(resultset)\n\n    # we turn this python array into a pandas dataframe\n    df = pd.DataFrame(data=resultset, columns=[\n                      "ds_name", "flow_name", "owner_name", "project_name"])\n\n    # we return the dataframe to Tableau Prep\n    return(df)\ndef get_output_schema_bea97b3a58e648258274adfc99cd41f5(df = pd.DataFrame()):\n    import inspect\n    if len(inspect.getfullargspec(get_output_schema).args) == 0:\n        return get_output_schema()\n    else:\n        return get_output_schema(df)\nresult_schema_output = get_output_schema_bea97b3a58e648258274adfc99cd41f5(pd.DataFrame(_arg1))\nreturn result_schema_output.to_dict(orient=\'split\') if isinstance(result_schema_output, pd.DataFrame) else result_schema_output'}'...
2021-01-28,13:48:10 [INFO] (base_handler.py:base_handler:115): function to evaluate=def _user_script(tabpy, _arg1):
 import pandas as pd
 def get_output_schema():
 	return '5e1663ee-aeb8-40e2-9e10-d7644bc9e928'
 def prep_string():
 	return ['prep_string_type']
 def prep_bool():
 	return ['prep_bool_type']
 def prep_int():
 	return ['prep_int_type']
 def prep_decimal():
     return ['prep_decimal_type']
 def prep_date():
 	return ['prep_date_type']
 def prep_datetime():
 	return ['prep_datetime_type']
 # os is used to retrieve environment variables
 # requests is used to make HTTP requests out to Tableau Server
 # json is used to parse the answer received from the Tableau metadata API
 # pandas is used to build a dataframe and return data to Tableau Prep
 
 import os
 import requests
 import json
 import pandas as pd
 
 
 # login will perform a login into Tableau Server and return a session token
 # it uses the API_SERVER, API_SECRET_TOKEN and API_TOKEN_NAME environment variables
 # see docker-compose.yml for these environment variables
 
 def login():
     body = {"credentials": {"personalAccessTokenName": os.environ['API_TOKEN_NAME'],
                             "personalAccessTokenSecret": os.environ['API_SECRET_TOKEN'],
                             "site": {"contentUrl": ""}}}
 
     print("Performing login")
 
     url = "https://{server}/api/3.9/auth/signin".format(
         server=os.environ["API_SERVER"])
 
     headers = {
         'accept': 'application/json',
         'content-type': 'application/json'
     }
 
     # making the request
     x = requests.post(url, json=body, headers=headers)
     # parsing the login response
     response = json.loads(x.text)
     # if everything goes well, session token is found here:
     token = response["credentials"]["token"]
 
     return token
 
 # run_query runs a GRAPHQL query against the Tableau metadata API
 # arguments are a session token (obtained with login function) and the query text
 # it uses the API_SERVER environment variable to connect to the server; see docker-compose.yml
 
 
 def run_query(token, query):
     uri = "https://{server}/api/metadata/graphql".format(
         server=os.environ["API_SERVER"])
     headers = {
         'content-type': 'application/json',
         'accept': 'application/json',
         'X-Tableau-Auth': token
     }
     x = requests.post(uri, json={'query': query}, headers=headers)
 
     # we print the plain text answer for debugging purposes
     print(x.text)
 
     # we return the plain text answer received
     return x.text
 
 
 # This function is called by Tableau Prep to obtain the expected schema of the data to receive
 def get_output_schema():
     return pd.DataFrame({
         'ds_name': prep_string(),
         'flow_name': prep_string(),
         'owner_name': prep_string(),
         'project_name': prep_string()
     })
 
 
 # This is the function we well name in a Tableau Prep script node
 # It received data on the input, but doesn't use it
 
 def get_published_ds_used_in_flow(input):
 
     # The hardcoded Graphql query
     query = """query published_datasources_certified {
     publishedDatasources {
       name
       isCertified
       downstreamFlows {
         name,
         owner {
           name
         },
         projectName
       }
     }
   }
   """
 
     print("Logging into Tableau Server...")
     token = login()
     print("Session token is: " + token)
     print("")
     print("Running the following query:")
     print(query)
     print("")
     print("Answer below:")
 
     # here we get text
     json_string = run_query(token, query)
 
     # we parse the result as a json structure
     response_as_json = json.loads(json_string)
 
     # we print the json structure
     print(json.dumps(response_as_json, sort_keys=True, indent=4))
 
     # navigating the json structure to find the starting node we need
     list_of_published_ds = response_as_json["data"]["publishedDatasources"]
 
     # this array will contain the data we will return to Tableau Prep
     resultset = []
 
     # navigating the json structure and collecting data
     for ds in list_of_published_ds:
         for flow in ds["downstreamFlows"]:
             # when we find a downstream flow, we create one entry into the resultset
             resultset.append([ds["name"], flow["name"],
                               flow["owner"]["name"], flow["projectName"]])
 
     # print the resultset for debugging purposes
     print(resultset)
 
     # we turn this python array into a pandas dataframe
     df = pd.DataFrame(data=resultset, columns=[
                       "ds_name", "flow_name", "owner_name", "project_name"])
 
     # we return the dataframe to Tableau Prep
     return(df)
 def get_output_schema_bea97b3a58e648258274adfc99cd41f5(df = pd.DataFrame()):
     import inspect
     if len(inspect.getfullargspec(get_output_schema).args) == 0:
         return get_output_schema()
     else:
         return get_output_schema(df)
 result_schema_output = get_output_schema_bea97b3a58e648258274adfc99cd41f5(pd.DataFrame(_arg1))
 return result_schema_output.to_dict(orient='split') if isinstance(result_schema_output, pd.DataFrame) else result_schema_output

2021-01-28,13:48:10 [INFO] (web.py:web:2239): 200 POST /evaluate (172.18.0.1) 42.90ms
2021-01-28,13:48:10 [INFO] (web.py:web:2239): 200 POST /evaluate (172.18.0.1) 21.18ms
2021-01-28,13:48:11 [DEBUG] (base_handler.py:base_handler:115): Checking if need to handle authentication
2021-01-28,13:48:11 [DEBUG] (base_handler.py:base_handler:115): Handling authentication
2021-01-28,13:48:11 [INFO] (base_handler.py:base_handler:115): Authentication is not a required feature for API "v1"
2021-01-28,13:48:11 [DEBUG] (base_handler.py:base_handler:115): Checking request headers for authentication data
2021-01-28,13:48:11 [INFO] (base_handler.py:base_handler:115): Authorization header not found
2021-01-28,13:48:11 [DEBUG] (base_handler.py:base_handler:115): authentication not required, username and password are none
2021-01-28,13:48:11 [DEBUG] (state.py:state:511): Collecting Access-Control-Allow-Origin from state file ...
2021-01-28,13:48:11 [DEBUG] (state.py:state:613): Loading option 'Access-Control-Allow-Origin' from section [Service Info]...
2021-01-28,13:48:11 [DEBUG] (state.py:state:635): Returning value ''
2021-01-28,13:48:11 [DEBUG] (state.py:state:613): Loading option 'Access-Control-Allow-Headers' from section [Service Info]...
2021-01-28,13:48:11 [DEBUG] (state.py:state:635): Returning value ''
2021-01-28,13:48:11 [DEBUG] (state.py:state:613): Loading option 'Access-Control-Allow-Methods' from section [Service Info]...
2021-01-28,13:48:11 [DEBUG] (state.py:state:635): Returning value ''
2021-01-28,13:48:11 [DEBUG] (base_handler.py:base_handler:115): Processing POST request '{'data': {'_arg1': {'dummy': ['prep_string_type']}}, 'script': 'import pandas as pd\ndef get_output_schema():\n\treturn \'5e1663ee-aeb8-40e2-9e10-d7644bc9e928\'\ndef prep_string():\n\treturn [\'prep_string_type\']\ndef prep_bool():\n\treturn [\'prep_bool_type\']\ndef prep_int():\n\treturn [\'prep_int_type\']\ndef prep_decimal():\n    return [\'prep_decimal_type\']\ndef prep_date():\n\treturn [\'prep_date_type\']\ndef prep_datetime():\n\treturn [\'prep_datetime_type\']\n# os is used to retrieve environment variables\n# requests is used to make HTTP requests out to Tableau Server\n# json is used to parse the answer received from the Tableau metadata API\n# pandas is used to build a dataframe and return data to Tableau Prep\n\nimport os\nimport requests\nimport json\nimport pandas as pd\n\n\n# login will perform a login into Tableau Server and return a session token\n# it uses the API_SERVER, API_SECRET_TOKEN and API_TOKEN_NAME environment variables\n# see docker-compose.yml for these environment variables\n\ndef login():\n    body = {"credentials": {"personalAccessTokenName": os.environ[\'API_TOKEN_NAME\'],\n                            "personalAccessTokenSecret": os.environ[\'API_SECRET_TOKEN\'],\n                            "site": {"contentUrl": ""}}}\n\n    print("Performing login")\n\n    url = "https://{server}/api/3.9/auth/signin".format(\n        server=os.environ["API_SERVER"])\n\n    headers = {\n        \'accept\': \'application/json\',\n        \'content-type\': \'application/json\'\n    }\n\n    # making the request\n    x = requests.post(url, json=body, headers=headers)\n    # parsing the login response\n    response = json.loads(x.text)\n    # if everything goes well, session token is found here:\n    token = response["credentials"]["token"]\n\n    return token\n\n# run_query runs a GRAPHQL query against the Tableau metadata API\n# arguments are a session token (obtained with login function) and the query text\n# it uses the API_SERVER environment variable to connect to the server; see docker-compose.yml\n\n\ndef run_query(token, query):\n    uri = "https://{server}/api/metadata/graphql".format(\n        server=os.environ["API_SERVER"])\n    headers = {\n        \'content-type\': \'application/json\',\n        \'accept\': \'application/json\',\n        \'X-Tableau-Auth\': token\n    }\n    x = requests.post(uri, json={\'query\': query}, headers=headers)\n\n    # we print the plain text answer for debugging purposes\n    print(x.text)\n\n    # we return the plain text answer received\n    return x.text\n\n\n# This function is called by Tableau Prep to obtain the expected schema of the data to receive\ndef get_output_schema():\n    return pd.DataFrame({\n        \'ds_name\': prep_string(),\n        \'flow_name\': prep_string(),\n        \'owner_name\': prep_string(),\n        \'project_name\': prep_string()\n    })\n\n\n# This is the function we well name in a Tableau Prep script node\n# It received data on the input, but doesn\'t use it\n\ndef get_published_ds_used_in_flow(input):\n\n    # The hardcoded Graphql query\n    query = """query published_datasources_certified {\n    publishedDatasources {\n      name\n      isCertified\n      downstreamFlows {\n        name,\n        owner {\n          name\n        },\n        projectName\n      }\n    }\n  }\n  """\n\n    print("Logging into Tableau Server...")\n    token = login()\n    print("Session token is: " + token)\n    print("")\n    print("Running the following query:")\n    print(query)\n    print("")\n    print("Answer below:")\n\n    # here we get text\n    json_string = run_query(token, query)\n\n    # we parse the result as a json structure\n    response_as_json = json.loads(json_string)\n\n    # we print the json structure\n    print(json.dumps(response_as_json, sort_keys=True, indent=4))\n\n    # navigating the json structure to find the starting node we need\n    list_of_published_ds = response_as_json["data"]["publishedDatasources"]\n\n    # this array will contain the data we will return to Tableau Prep\n    resultset = []\n\n    # navigating the json structure and collecting data\n    for ds in list_of_published_ds:\n        for flow in ds["downstreamFlows"]:\n            # when we find a downstream flow, we create one entry into the resultset\n            resultset.append([ds["name"], flow["name"],\n                              flow["owner"]["name"], flow["projectName"]])\n\n    # print the resultset for debugging purposes\n    print(resultset)\n\n    # we turn this python array into a pandas dataframe\n    df = pd.DataFrame(data=resultset, columns=[\n                      "ds_name", "flow_name", "owner_name", "project_name"])\n\n    # we return the dataframe to Tableau Prep\n    return(df)\ndef get_output_schema_bea97b3a58e648258274adfc99cd41f5(df = pd.DataFrame()):\n    import inspect\n    if len(inspect.getfullargspec(get_output_schema).args) == 0:\n        return get_output_schema()\n    else:\n        return get_output_schema(df)\nresult_schema_output = get_output_schema_bea97b3a58e648258274adfc99cd41f5(pd.DataFrame(_arg1))\nreturn result_schema_output.to_dict(orient=\'split\') if isinstance(result_schema_output, pd.DataFrame) else result_schema_output'}'...
2021-01-28,13:48:11 [INFO] (base_handler.py:base_handler:115): function to evaluate=def _user_script(tabpy, _arg1):
 import pandas as pd
 def get_output_schema():
 	return '5e1663ee-aeb8-40e2-9e10-d7644bc9e928'
 def prep_string():
 	return ['prep_string_type']
 def prep_bool():
 	return ['prep_bool_type']
 def prep_int():
 	return ['prep_int_type']
 def prep_decimal():
     return ['prep_decimal_type']
 def prep_date():
 	return ['prep_date_type']
 def prep_datetime():
 	return ['prep_datetime_type']
 # os is used to retrieve environment variables
 # requests is used to make HTTP requests out to Tableau Server
 # json is used to parse the answer received from the Tableau metadata API
 # pandas is used to build a dataframe and return data to Tableau Prep
 
 import os
 import requests
 import json
 import pandas as pd
 
 
 # login will perform a login into Tableau Server and return a session token
 # it uses the API_SERVER, API_SECRET_TOKEN and API_TOKEN_NAME environment variables
 # see docker-compose.yml for these environment variables
 
 def login():
     body = {"credentials": {"personalAccessTokenName": os.environ['API_TOKEN_NAME'],
                             "personalAccessTokenSecret": os.environ['API_SECRET_TOKEN'],
                             "site": {"contentUrl": ""}}}
 
     print("Performing login")
 
     url = "https://{server}/api/3.9/auth/signin".format(
         server=os.environ["API_SERVER"])
 
     headers = {
         'accept': 'application/json',
         'content-type': 'application/json'
     }
 
     # making the request
     x = requests.post(url, json=body, headers=headers)
     # parsing the login response
     response = json.loads(x.text)
     # if everything goes well, session token is found here:
     token = response["credentials"]["token"]
 
     return token
 
 # run_query runs a GRAPHQL query against the Tableau metadata API
 # arguments are a session token (obtained with login function) and the query text
 # it uses the API_SERVER environment variable to connect to the server; see docker-compose.yml
 
 
 def run_query(token, query):
     uri = "https://{server}/api/metadata/graphql".format(
         server=os.environ["API_SERVER"])
     headers = {
         'content-type': 'application/json',
         'accept': 'application/json',
         'X-Tableau-Auth': token
     }
     x = requests.post(uri, json={'query': query}, headers=headers)
 
     # we print the plain text answer for debugging purposes
     print(x.text)
 
     # we return the plain text answer received
     return x.text
 
 
 # This function is called by Tableau Prep to obtain the expected schema of the data to receive
 def get_output_schema():
     return pd.DataFrame({
         'ds_name': prep_string(),
         'flow_name': prep_string(),
         'owner_name': prep_string(),
         'project_name': prep_string()
     })
 
 
 # This is the function we well name in a Tableau Prep script node
 # It received data on the input, but doesn't use it
 
 def get_published_ds_used_in_flow(input):
 
     # The hardcoded Graphql query
     query = """query published_datasources_certified {
     publishedDatasources {
       name
       isCertified
       downstreamFlows {
         name,
         owner {
           name
         },
         projectName
       }
     }
   }
   """
 
     print("Logging into Tableau Server...")
     token = login()
     print("Session token is: " + token)
     print("")
     print("Running the following query:")
     print(query)
     print("")
     print("Answer below:")
 
     # here we get text
     json_string = run_query(token, query)
 
     # we parse the result as a json structure
     response_as_json = json.loads(json_string)
 
     # we print the json structure
     print(json.dumps(response_as_json, sort_keys=True, indent=4))
 
     # navigating the json structure to find the starting node we need
     list_of_published_ds = response_as_json["data"]["publishedDatasources"]
 
     # this array will contain the data we will return to Tableau Prep
     resultset = []
 
     # navigating the json structure and collecting data
     for ds in list_of_published_ds:
         for flow in ds["downstreamFlows"]:
             # when we find a downstream flow, we create one entry into the resultset
             resultset.append([ds["name"], flow["name"],
                               flow["owner"]["name"], flow["projectName"]])
 
     # print the resultset for debugging purposes
     print(resultset)
 
     # we turn this python array into a pandas dataframe
     df = pd.DataFrame(data=resultset, columns=[
                       "ds_name", "flow_name", "owner_name", "project_name"])
 
     # we return the dataframe to Tableau Prep
     return(df)
 def get_output_schema_bea97b3a58e648258274adfc99cd41f5(df = pd.DataFrame()):
     import inspect
     if len(inspect.getfullargspec(get_output_schema).args) == 0:
         return get_output_schema()
     else:
         return get_output_schema(df)
 result_schema_output = get_output_schema_bea97b3a58e648258274adfc99cd41f5(pd.DataFrame(_arg1))
 return result_schema_output.to_dict(orient='split') if isinstance(result_schema_output, pd.DataFrame) else result_schema_output

2021-01-28,13:48:11 [INFO] (web.py:web:2239): 200 POST /evaluate (172.18.0.1) 21.12ms
2021-01-28,13:48:11 [DEBUG] (base_handler.py:base_handler:115): Checking if need to handle authentication
2021-01-28,13:48:11 [DEBUG] (base_handler.py:base_handler:115): Handling authentication
2021-01-28,13:48:11 [INFO] (base_handler.py:base_handler:115): Authentication is not a required feature for API "v1"
2021-01-28,13:48:11 [DEBUG] (base_handler.py:base_handler:115): Checking request headers for authentication data
2021-01-28,13:48:11 [INFO] (base_handler.py:base_handler:115): Authorization header not found
2021-01-28,13:48:11 [DEBUG] (base_handler.py:base_handler:115): authentication not required, username and password are none
2021-01-28,13:48:11 [DEBUG] (state.py:state:511): Collecting Access-Control-Allow-Origin from state file ...
2021-01-28,13:48:11 [DEBUG] (state.py:state:613): Loading option 'Access-Control-Allow-Origin' from section [Service Info]...
2021-01-28,13:48:11 [DEBUG] (state.py:state:635): Returning value ''
2021-01-28,13:48:11 [DEBUG] (state.py:state:613): Loading option 'Access-Control-Allow-Headers' from section [Service Info]...
2021-01-28,13:48:11 [DEBUG] (state.py:state:635): Returning value ''
2021-01-28,13:48:11 [DEBUG] (state.py:state:613): Loading option 'Access-Control-Allow-Methods' from section [Service Info]...
2021-01-28,13:48:11 [DEBUG] (state.py:state:635): Returning value ''
2021-01-28,13:48:11 [DEBUG] (base_handler.py:base_handler:115): Processing POST request '{'data': {'_arg1': {'dummy': ['prep_string_type']}}, 'script': 'import pandas as pd\ndef get_output_schema():\n\treturn \'5e1663ee-aeb8-40e2-9e10-d7644bc9e928\'\ndef prep_string():\n\treturn [\'prep_string_type\']\ndef prep_bool():\n\treturn [\'prep_bool_type\']\ndef prep_int():\n\treturn [\'prep_int_type\']\ndef prep_decimal():\n    return [\'prep_decimal_type\']\ndef prep_date():\n\treturn [\'prep_date_type\']\ndef prep_datetime():\n\treturn [\'prep_datetime_type\']\n# os is used to retrieve environment variables\n# requests is used to make HTTP requests out to Tableau Server\n# json is used to parse the answer received from the Tableau metadata API\n# pandas is used to build a dataframe and return data to Tableau Prep\n\nimport os\nimport requests\nimport json\nimport pandas as pd\n\n\n# login will perform a login into Tableau Server and return a session token\n# it uses the API_SERVER, API_SECRET_TOKEN and API_TOKEN_NAME environment variables\n# see docker-compose.yml for these environment variables\n\ndef login():\n    body = {"credentials": {"personalAccessTokenName": os.environ[\'API_TOKEN_NAME\'],\n                            "personalAccessTokenSecret": os.environ[\'API_SECRET_TOKEN\'],\n                            "site": {"contentUrl": ""}}}\n\n    print("Performing login")\n\n    url = "https://{server}/api/3.9/auth/signin".format(\n        server=os.environ["API_SERVER"])\n\n    headers = {\n        \'accept\': \'application/json\',\n        \'content-type\': \'application/json\'\n    }\n\n    # making the request\n    x = requests.post(url, json=body, headers=headers)\n    # parsing the login response\n    response = json.loads(x.text)\n    # if everything goes well, session token is found here:\n    token = response["credentials"]["token"]\n\n    return token\n\n# run_query runs a GRAPHQL query against the Tableau metadata API\n# arguments are a session token (obtained with login function) and the query text\n# it uses the API_SERVER environment variable to connect to the server; see docker-compose.yml\n\n\ndef run_query(token, query):\n    uri = "https://{server}/api/metadata/graphql".format(\n        server=os.environ["API_SERVER"])\n    headers = {\n        \'content-type\': \'application/json\',\n        \'accept\': \'application/json\',\n        \'X-Tableau-Auth\': token\n    }\n    x = requests.post(uri, json={\'query\': query}, headers=headers)\n\n    # we print the plain text answer for debugging purposes\n    print(x.text)\n\n    # we return the plain text answer received\n    return x.text\n\n\n# This function is called by Tableau Prep to obtain the expected schema of the data to receive\ndef get_output_schema():\n    return pd.DataFrame({\n        \'ds_name\': prep_string(),\n        \'flow_name\': prep_string(),\n        \'owner_name\': prep_string(),\n        \'project_name\': prep_string()\n    })\n\n\n# This is the function we well name in a Tableau Prep script node\n# It received data on the input, but doesn\'t use it\n\ndef get_published_ds_used_in_flow(input):\n\n    # The hardcoded Graphql query\n    query = """query published_datasources_certified {\n    publishedDatasources {\n      name\n      isCertified\n      downstreamFlows {\n        name,\n        owner {\n          name\n        },\n        projectName\n      }\n    }\n  }\n  """\n\n    print("Logging into Tableau Server...")\n    token = login()\n    print("Session token is: " + token)\n    print("")\n    print("Running the following query:")\n    print(query)\n    print("")\n    print("Answer below:")\n\n    # here we get text\n    json_string = run_query(token, query)\n\n    # we parse the result as a json structure\n    response_as_json = json.loads(json_string)\n\n    # we print the json structure\n    print(json.dumps(response_as_json, sort_keys=True, indent=4))\n\n    # navigating the json structure to find the starting node we need\n    list_of_published_ds = response_as_json["data"]["publishedDatasources"]\n\n    # this array will contain the data we will return to Tableau Prep\n    resultset = []\n\n    # navigating the json structure and collecting data\n    for ds in list_of_published_ds:\n        for flow in ds["downstreamFlows"]:\n            # when we find a downstream flow, we create one entry into the resultset\n            resultset.append([ds["name"], flow["name"],\n                              flow["owner"]["name"], flow["projectName"]])\n\n    # print the resultset for debugging purposes\n    print(resultset)\n\n    # we turn this python array into a pandas dataframe\n    df = pd.DataFrame(data=resultset, columns=[\n                      "ds_name", "flow_name", "owner_name", "project_name"])\n\n    # we return the dataframe to Tableau Prep\n    return(df)\ndef get_output_schema_bea97b3a58e648258274adfc99cd41f5(df = pd.DataFrame()):\n    import inspect\n    if len(inspect.getfullargspec(get_output_schema).args) == 0:\n        return get_output_schema()\n    else:\n        return get_output_schema(df)\nresult_schema_output = get_output_schema_bea97b3a58e648258274adfc99cd41f5(pd.DataFrame(_arg1))\nreturn result_schema_output.to_dict(orient=\'split\') if isinstance(result_schema_output, pd.DataFrame) else result_schema_output'}'...
2021-01-28,13:48:11 [INFO] (base_handler.py:base_handler:115): function to evaluate=def _user_script(tabpy, _arg1):
 import pandas as pd
 def get_output_schema():
 	return '5e1663ee-aeb8-40e2-9e10-d7644bc9e928'
 def prep_string():
 	return ['prep_string_type']
 def prep_bool():
 	return ['prep_bool_type']
 def prep_int():
 	return ['prep_int_type']
 def prep_decimal():
     return ['prep_decimal_type']
 def prep_date():
 	return ['prep_date_type']
 def prep_datetime():
 	return ['prep_datetime_type']
 # os is used to retrieve environment variables
 # requests is used to make HTTP requests out to Tableau Server
 # json is used to parse the answer received from the Tableau metadata API
 # pandas is used to build a dataframe and return data to Tableau Prep
 
 import os
 import requests
 import json
 import pandas as pd
 
 
 # login will perform a login into Tableau Server and return a session token
 # it uses the API_SERVER, API_SECRET_TOKEN and API_TOKEN_NAME environment variables
 # see docker-compose.yml for these environment variables
 
 def login():
     body = {"credentials": {"personalAccessTokenName": os.environ['API_TOKEN_NAME'],
                             "personalAccessTokenSecret": os.environ['API_SECRET_TOKEN'],
                             "site": {"contentUrl": ""}}}
 
     print("Performing login")
 
     url = "https://{server}/api/3.9/auth/signin".format(
         server=os.environ["API_SERVER"])
 
     headers = {
         'accept': 'application/json',
         'content-type': 'application/json'
     }
 
     # making the request
     x = requests.post(url, json=body, headers=headers)
     # parsing the login response
     response = json.loads(x.text)
     # if everything goes well, session token is found here:
     token = response["credentials"]["token"]
 
     return token
 
 # run_query runs a GRAPHQL query against the Tableau metadata API
 # arguments are a session token (obtained with login function) and the query text
 # it uses the API_SERVER environment variable to connect to the server; see docker-compose.yml
 
 
 def run_query(token, query):
     uri = "https://{server}/api/metadata/graphql".format(
         server=os.environ["API_SERVER"])
     headers = {
         'content-type': 'application/json',
         'accept': 'application/json',
         'X-Tableau-Auth': token
     }
     x = requests.post(uri, json={'query': query}, headers=headers)
 
     # we print the plain text answer for debugging purposes
     print(x.text)
 
     # we return the plain text answer received
     return x.text
 
 
 # This function is called by Tableau Prep to obtain the expected schema of the data to receive
 def get_output_schema():
     return pd.DataFrame({
         'ds_name': prep_string(),
         'flow_name': prep_string(),
         'owner_name': prep_string(),
         'project_name': prep_string()
     })
 
 
 # This is the function we well name in a Tableau Prep script node
 # It received data on the input, but doesn't use it
 
 def get_published_ds_used_in_flow(input):
 
     # The hardcoded Graphql query
     query = """query published_datasources_certified {
     publishedDatasources {
       name
       isCertified
       downstreamFlows {
         name,
         owner {
           name
         },
         projectName
       }
     }
   }
   """
 
     print("Logging into Tableau Server...")
     token = login()
     print("Session token is: " + token)
     print("")
     print("Running the following query:")
     print(query)
     print("")
     print("Answer below:")
 
     # here we get text
     json_string = run_query(token, query)
 
     # we parse the result as a json structure
     response_as_json = json.loads(json_string)
 
     # we print the json structure
     print(json.dumps(response_as_json, sort_keys=True, indent=4))
 
     # navigating the json structure to find the starting node we need
     list_of_published_ds = response_as_json["data"]["publishedDatasources"]
 
     # this array will contain the data we will return to Tableau Prep
     resultset = []
 
     # navigating the json structure and collecting data
     for ds in list_of_published_ds:
         for flow in ds["downstreamFlows"]:
             # when we find a downstream flow, we create one entry into the resultset
             resultset.append([ds["name"], flow["name"],
                               flow["owner"]["name"], flow["projectName"]])
 
     # print the resultset for debugging purposes
     print(resultset)
 
     # we turn this python array into a pandas dataframe
     df = pd.DataFrame(data=resultset, columns=[
                       "ds_name", "flow_name", "owner_name", "project_name"])
 
     # we return the dataframe to Tableau Prep
     return(df)
 def get_output_schema_bea97b3a58e648258274adfc99cd41f5(df = pd.DataFrame()):
     import inspect
     if len(inspect.getfullargspec(get_output_schema).args) == 0:
         return get_output_schema()
     else:
         return get_output_schema(df)
 result_schema_output = get_output_schema_bea97b3a58e648258274adfc99cd41f5(pd.DataFrame(_arg1))
 return result_schema_output.to_dict(orient='split') if isinstance(result_schema_output, pd.DataFrame) else result_schema_output

2021-01-28,13:48:11 [INFO] (web.py:web:2239): 200 POST /evaluate (172.18.0.1) 21.67ms
2021-01-28,13:48:11 [DEBUG] (base_handler.py:base_handler:115): Checking if need to handle authentication
2021-01-28,13:48:11 [DEBUG] (base_handler.py:base_handler:115): Handling authentication
2021-01-28,13:48:11 [INFO] (base_handler.py:base_handler:115): Authentication is not a required feature for API "v1"
2021-01-28,13:48:11 [DEBUG] (base_handler.py:base_handler:115): Checking request headers for authentication data
2021-01-28,13:48:11 [INFO] (base_handler.py:base_handler:115): Authorization header not found
2021-01-28,13:48:11 [DEBUG] (base_handler.py:base_handler:115): authentication not required, username and password are none
2021-01-28,13:48:11 [DEBUG] (state.py:state:511): Collecting Access-Control-Allow-Origin from state file ...
2021-01-28,13:48:11 [DEBUG] (state.py:state:613): Loading option 'Access-Control-Allow-Origin' from section [Service Info]...
2021-01-28,13:48:11 [DEBUG] (state.py:state:635): Returning value ''
2021-01-28,13:48:11 [DEBUG] (state.py:state:613): Loading option 'Access-Control-Allow-Headers' from section [Service Info]...
2021-01-28,13:48:11 [DEBUG] (state.py:state:635): Returning value ''
2021-01-28,13:48:11 [DEBUG] (state.py:state:613): Loading option 'Access-Control-Allow-Methods' from section [Service Info]...
2021-01-28,13:48:11 [DEBUG] (state.py:state:635): Returning value ''
2021-01-28,13:48:11 [DEBUG] (base_handler.py:base_handler:115): Processing POST request '{'data': {'_arg1': {'dummy': ['data']}}, 'script': 'import pandas as pd\n# os is used to retrieve environment variables\n# requests is used to make HTTP requests out to Tableau Server\n# json is used to parse the answer received from the Tableau metadata API\n# pandas is used to build a dataframe and return data to Tableau Prep\n\nimport os\nimport requests\nimport json\nimport pandas as pd\n\n\n# login will perform a login into Tableau Server and return a session token\n# it uses the API_SERVER, API_SECRET_TOKEN and API_TOKEN_NAME environment variables\n# see docker-compose.yml for these environment variables\n\ndef login():\n    body = {"credentials": {"personalAccessTokenName": os.environ[\'API_TOKEN_NAME\'],\n                            "personalAccessTokenSecret": os.environ[\'API_SECRET_TOKEN\'],\n                            "site": {"contentUrl": ""}}}\n\n    print("Performing login")\n\n    url = "https://{server}/api/3.9/auth/signin".format(\n        server=os.environ["API_SERVER"])\n\n    headers = {\n        \'accept\': \'application/json\',\n        \'content-type\': \'application/json\'\n    }\n\n    # making the request\n    x = requests.post(url, json=body, headers=headers)\n    # parsing the login response\n    response = json.loads(x.text)\n    # if everything goes well, session token is found here:\n    token = response["credentials"]["token"]\n\n    return token\n\n# run_query runs a GRAPHQL query against the Tableau metadata API\n# arguments are a session token (obtained with login function) and the query text\n# it uses the API_SERVER environment variable to connect to the server; see docker-compose.yml\n\n\ndef run_query(token, query):\n    uri = "https://{server}/api/metadata/graphql".format(\n        server=os.environ["API_SERVER"])\n    headers = {\n        \'content-type\': \'application/json\',\n        \'accept\': \'application/json\',\n        \'X-Tableau-Auth\': token\n    }\n    x = requests.post(uri, json={\'query\': query}, headers=headers)\n\n    # we print the plain text answer for debugging purposes\n    print(x.text)\n\n    # we return the plain text answer received\n    return x.text\n\n\n# This function is called by Tableau Prep to obtain the expected schema of the data to receive\ndef get_output_schema():\n    return pd.DataFrame({\n        \'ds_name\': prep_string(),\n        \'flow_name\': prep_string(),\n        \'owner_name\': prep_string(),\n        \'project_name\': prep_string()\n    })\n\n\n# This is the function we well name in a Tableau Prep script node\n# It received data on the input, but doesn\'t use it\n\ndef get_published_ds_used_in_flow(input):\n\n    # The hardcoded Graphql query\n    query = """query published_datasources_certified {\n    publishedDatasources {\n      name\n      isCertified\n      downstreamFlows {\n        name,\n        owner {\n          name\n        },\n        projectName\n      }\n    }\n  }\n  """\n\n    print("Logging into Tableau Server...")\n    token = login()\n    print("Session token is: " + token)\n    print("")\n    print("Running the following query:")\n    print(query)\n    print("")\n    print("Answer below:")\n\n    # here we get text\n    json_string = run_query(token, query)\n\n    # we parse the result as a json structure\n    response_as_json = json.loads(json_string)\n\n    # we print the json structure\n    print(json.dumps(response_as_json, sort_keys=True, indent=4))\n\n    # navigating the json structure to find the starting node we need\n    list_of_published_ds = response_as_json["data"]["publishedDatasources"]\n\n    # this array will contain the data we will return to Tableau Prep\n    resultset = []\n\n    # navigating the json structure and collecting data\n    for ds in list_of_published_ds:\n        for flow in ds["downstreamFlows"]:\n            # when we find a downstream flow, we create one entry into the resultset\n            resultset.append([ds["name"], flow["name"],\n                              flow["owner"]["name"], flow["projectName"]])\n\n    # print the resultset for debugging purposes\n    print(resultset)\n\n    # we turn this python array into a pandas dataframe\n    df = pd.DataFrame(data=resultset, columns=[\n                      "ds_name", "flow_name", "owner_name", "project_name"])\n\n    # we return the dataframe to Tableau Prep\n    return(df)\nexecution_result = get_published_ds_used_in_flow(pd.DataFrame(_arg1))\nreturn execution_result.to_dict(orient=\'list\') if isinstance(execution_result, pd.DataFrame) else execution_result\n'}'...
2021-01-28,13:48:11 [INFO] (base_handler.py:base_handler:115): function to evaluate=def _user_script(tabpy, _arg1):
 import pandas as pd
 # os is used to retrieve environment variables
 # requests is used to make HTTP requests out to Tableau Server
 # json is used to parse the answer received from the Tableau metadata API
 # pandas is used to build a dataframe and return data to Tableau Prep
 
 import os
 import requests
 import json
 import pandas as pd
 
 
 # login will perform a login into Tableau Server and return a session token
 # it uses the API_SERVER, API_SECRET_TOKEN and API_TOKEN_NAME environment variables
 # see docker-compose.yml for these environment variables
 
 def login():
     body = {"credentials": {"personalAccessTokenName": os.environ['API_TOKEN_NAME'],
                             "personalAccessTokenSecret": os.environ['API_SECRET_TOKEN'],
                             "site": {"contentUrl": ""}}}
 
     print("Performing login")
 
     url = "https://{server}/api/3.9/auth/signin".format(
         server=os.environ["API_SERVER"])
 
     headers = {
         'accept': 'application/json',
         'content-type': 'application/json'
     }
 
     # making the request
     x = requests.post(url, json=body, headers=headers)
     # parsing the login response
     response = json.loads(x.text)
     # if everything goes well, session token is found here:
     token = response["credentials"]["token"]
 
     return token
 
 # run_query runs a GRAPHQL query against the Tableau metadata API
 # arguments are a session token (obtained with login function) and the query text
 # it uses the API_SERVER environment variable to connect to the server; see docker-compose.yml
 
 
 def run_query(token, query):
     uri = "https://{server}/api/metadata/graphql".format(
         server=os.environ["API_SERVER"])
     headers = {
         'content-type': 'application/json',
         'accept': 'application/json',
         'X-Tableau-Auth': token
     }
     x = requests.post(uri, json={'query': query}, headers=headers)
 
     # we print the plain text answer for debugging purposes
     print(x.text)
 
     # we return the plain text answer received
     return x.text
 
 
 # This function is called by Tableau Prep to obtain the expected schema of the data to receive
 def get_output_schema():
     return pd.DataFrame({
         'ds_name': prep_string(),
         'flow_name': prep_string(),
         'owner_name': prep_string(),
         'project_name': prep_string()
     })
 
 
 # This is the function we well name in a Tableau Prep script node
 # It received data on the input, but doesn't use it
 
 def get_published_ds_used_in_flow(input):
 
     # The hardcoded Graphql query
     query = """query published_datasources_certified {
     publishedDatasources {
       name
       isCertified
       downstreamFlows {
         name,
         owner {
           name
         },
         projectName
       }
     }
   }
   """
 
     print("Logging into Tableau Server...")
     token = login()
     print("Session token is: " + token)
     print("")
     print("Running the following query:")
     print(query)
     print("")
     print("Answer below:")
 
     # here we get text
     json_string = run_query(token, query)
 
     # we parse the result as a json structure
     response_as_json = json.loads(json_string)
 
     # we print the json structure
     print(json.dumps(response_as_json, sort_keys=True, indent=4))
 
     # navigating the json structure to find the starting node we need
     list_of_published_ds = response_as_json["data"]["publishedDatasources"]
 
     # this array will contain the data we will return to Tableau Prep
     resultset = []
 
     # navigating the json structure and collecting data
     for ds in list_of_published_ds:
         for flow in ds["downstreamFlows"]:
             # when we find a downstream flow, we create one entry into the resultset
             resultset.append([ds["name"], flow["name"],
                               flow["owner"]["name"], flow["projectName"]])
 
     # print the resultset for debugging purposes
     print(resultset)
 
     # we turn this python array into a pandas dataframe
     df = pd.DataFrame(data=resultset, columns=[
                       "ds_name", "flow_name", "owner_name", "project_name"])
 
     # we return the dataframe to Tableau Prep
     return(df)
 execution_result = get_published_ds_used_in_flow(pd.DataFrame(_arg1))
 return execution_result.to_dict(orient='list') if isinstance(execution_result, pd.DataFrame) else execution_result

2021-01-28,13:48:11 [DEBUG] (connectionpool.py:connectionpool:971): Starting new HTTPS connection (1): healthcare.tableau.com:443
2021-01-28,13:48:11 [DEBUG] (connectionpool.py:connectionpool:452): https://healthcare.tableau.com:443 "POST /api/3.9/auth/signin HTTP/1.1" 200 192
2021-01-28,13:48:11 [DEBUG] (connectionpool.py:connectionpool:971): Starting new HTTPS connection (1): healthcare.tableau.com:443
2021-01-28,13:48:13 [DEBUG] (connectionpool.py:connectionpool:452): https://healthcare.tableau.com:443 "POST /api/metadata/graphql HTTP/1.1" 200 None
2021-01-28,13:48:13 [INFO] (web.py:web:2239): 200 POST /evaluate (172.18.0.1) 1591.32ms
2021-01-28,13:48:19 [DEBUG] (base_handler.py:base_handler:115): Checking if need to handle authentication
2021-01-28,13:48:19 [DEBUG] (base_handler.py:base_handler:115): Handling authentication
2021-01-28,13:48:19 [INFO] (base_handler.py:base_handler:115): Authentication is not a required feature for API "v1"
2021-01-28,13:48:19 [DEBUG] (base_handler.py:base_handler:115): Checking request headers for authentication data
2021-01-28,13:48:19 [INFO] (base_handler.py:base_handler:115): Authorization header not found
2021-01-28,13:48:19 [DEBUG] (base_handler.py:base_handler:115): authentication not required, username and password are none
2021-01-28,13:48:19 [DEBUG] (state.py:state:511): Collecting Access-Control-Allow-Origin from state file ...
2021-01-28,13:48:19 [DEBUG] (state.py:state:613): Loading option 'Access-Control-Allow-Origin' from section [Service Info]...
2021-01-28,13:48:19 [DEBUG] (state.py:state:635): Returning value ''
2021-01-28,13:48:19 [DEBUG] (state.py:state:613): Loading option 'Access-Control-Allow-Headers' from section [Service Info]...
2021-01-28,13:48:19 [DEBUG] (state.py:state:635): Returning value ''
2021-01-28,13:48:19 [DEBUG] (state.py:state:613): Loading option 'Access-Control-Allow-Methods' from section [Service Info]...
2021-01-28,13:48:19 [DEBUG] (state.py:state:635): Returning value ''
2021-01-28,13:48:19 [DEBUG] (base_handler.py:base_handler:115): Processing POST request '{'data': {'_arg1': {'dummy': ['prep_string_type']}}, 'script': 'import pandas as pd\ndef get_output_schema():\n\treturn \'5e1663ee-aeb8-40e2-9e10-d7644bc9e928\'\ndef prep_string():\n\treturn [\'prep_string_type\']\ndef prep_bool():\n\treturn [\'prep_bool_type\']\ndef prep_int():\n\treturn [\'prep_int_type\']\ndef prep_decimal():\n    return [\'prep_decimal_type\']\ndef prep_date():\n\treturn [\'prep_date_type\']\ndef prep_datetime():\n\treturn [\'prep_datetime_type\']\n# os is used to retrieve environment variables\n# requests is used to make HTTP requests out to Tableau Server\n# json is used to parse the answer received from the Tableau metadata API\n# pandas is used to build a dataframe and return data to Tableau Prep\n\nimport os\nimport requests\nimport json\nimport pandas as pd\n\n\n# login will perform a login into Tableau Server and return a session token\n# it uses the API_SERVER, API_SECRET_TOKEN and API_TOKEN_NAME environment variables\n# see docker-compose.yml for these environment variables\n\ndef login():\n    body = {"credentials": {"personalAccessTokenName": os.environ[\'API_TOKEN_NAME\'],\n                            "personalAccessTokenSecret": os.environ[\'API_SECRET_TOKEN\'],\n                            "site": {"contentUrl": ""}}}\n\n    print("Performing login")\n\n    url = "https://{server}/api/3.9/auth/signin".format(\n        server=os.environ["API_SERVER"])\n\n    headers = {\n        \'accept\': \'application/json\',\n        \'content-type\': \'application/json\'\n    }\n\n    # making the request\n    x = requests.post(url, json=body, headers=headers)\n    # parsing the login response\n    response = json.loads(x.text)\n    # if everything goes well, session token is found here:\n    token = response["credentials"]["token"]\n\n    return token\n\n# run_query runs a GRAPHQL query against the Tableau metadata API\n# arguments are a session token (obtained with login function) and the query text\n# it uses the API_SERVER environment variable to connect to the server; see docker-compose.yml\n\n\ndef run_query(token, query):\n    uri = "https://{server}/api/metadata/graphql".format(\n        server=os.environ["API_SERVER"])\n    headers = {\n        \'content-type\': \'application/json\',\n        \'accept\': \'application/json\',\n        \'X-Tableau-Auth\': token\n    }\n    x = requests.post(uri, json={\'query\': query}, headers=headers)\n\n    # we print the plain text answer for debugging purposes\n    print(x.text)\n\n    # we return the plain text answer received\n    return x.text\n\n\n# This function is called by Tableau Prep to obtain the expected schema of the data to receive\ndef get_output_schema():\n    return pd.DataFrame({\n        \'ds_name\': prep_string(),\n        \'flow_name\': prep_string(),\n        \'owner_name\': prep_string(),\n        \'project_name\': prep_string()\n    })\n\n\n# This is the function we well name in a Tableau Prep script node\n# It received data on the input, but doesn\'t use it\n\ndef get_published_ds_used_in_flow(input):\n\n    # The hardcoded Graphql query\n    query = """query published_datasources_certified {\n    publishedDatasources {\n      name\n      isCertified\n      downstreamFlows {\n        name,\n        owner {\n          name\n        },\n        projectName\n      }\n    }\n  }\n  """\n\n    print("Logging into Tableau Server...")\n    token = login()\n    print("Session token is: " + token)\n    print("")\n    print("Running the following query:")\n    print(query)\n    print("")\n    print("Answer below:")\n\n    # here we get text\n    json_string = run_query(token, query)\n\n    # we parse the result as a json structure\n    response_as_json = json.loads(json_string)\n\n    # we print the json structure\n    print(json.dumps(response_as_json, sort_keys=True, indent=4))\n\n    # navigating the json structure to find the starting node we need\n    list_of_published_ds = response_as_json["data"]["publishedDatasources"]\n\n    # this array will contain the data we will return to Tableau Prep\n    resultset = []\n\n    # navigating the json structure and collecting data\n    for ds in list_of_published_ds:\n        for flow in ds["downstreamFlows"]:\n            # when we find a downstream flow, we create one entry into the resultset\n            resultset.append([ds["name"], flow["name"],\n                              flow["owner"]["name"], flow["projectName"]])\n\n    # print the resultset for debugging purposes\n    print(resultset)\n\n    # we turn this python array into a pandas dataframe\n    df = pd.DataFrame(data=resultset, columns=[\n                      "ds_name", "flow_name", "owner_name", "project_name"])\n\n    # we return the dataframe to Tableau Prep\n    return(df)\ndef get_output_schema_bea97b3a58e648258274adfc99cd41f5(df = pd.DataFrame()):\n    import inspect\n    if len(inspect.getfullargspec(get_output_schema).args) == 0:\n        return get_output_schema()\n    else:\n        return get_output_schema(df)\nresult_schema_output = get_output_schema_bea97b3a58e648258274adfc99cd41f5(pd.DataFrame(_arg1))\nreturn result_schema_output.to_dict(orient=\'split\') if isinstance(result_schema_output, pd.DataFrame) else result_schema_output'}'...
2021-01-28,13:48:19 [INFO] (base_handler.py:base_handler:115): function to evaluate=def _user_script(tabpy, _arg1):
 import pandas as pd
 def get_output_schema():
 	return '5e1663ee-aeb8-40e2-9e10-d7644bc9e928'
 def prep_string():
 	return ['prep_string_type']
 def prep_bool():
 	return ['prep_bool_type']
 def prep_int():
 	return ['prep_int_type']
 def prep_decimal():
     return ['prep_decimal_type']
 def prep_date():
 	return ['prep_date_type']
 def prep_datetime():
 	return ['prep_datetime_type']
 # os is used to retrieve environment variables
 # requests is used to make HTTP requests out to Tableau Server
 # json is used to parse the answer received from the Tableau metadata API
 # pandas is used to build a dataframe and return data to Tableau Prep
 
 import os
 import requests
 import json
 import pandas as pd
 
 
 # login will perform a login into Tableau Server and return a session token
 # it uses the API_SERVER, API_SECRET_TOKEN and API_TOKEN_NAME environment variables
 # see docker-compose.yml for these environment variables
 
 def login():
     body = {"credentials": {"personalAccessTokenName": os.environ['API_TOKEN_NAME'],
                             "personalAccessTokenSecret": os.environ['API_SECRET_TOKEN'],
                             "site": {"contentUrl": ""}}}
 
     print("Performing login")
 
     url = "https://{server}/api/3.9/auth/signin".format(
         server=os.environ["API_SERVER"])
 
     headers = {
         'accept': 'application/json',
         'content-type': 'application/json'
     }
 
     # making the request
     x = requests.post(url, json=body, headers=headers)
     # parsing the login response
     response = json.loads(x.text)
     # if everything goes well, session token is found here:
     token = response["credentials"]["token"]
 
     return token
 
 # run_query runs a GRAPHQL query against the Tableau metadata API
 # arguments are a session token (obtained with login function) and the query text
 # it uses the API_SERVER environment variable to connect to the server; see docker-compose.yml
 
 
 def run_query(token, query):
     uri = "https://{server}/api/metadata/graphql".format(
         server=os.environ["API_SERVER"])
     headers = {
         'content-type': 'application/json',
         'accept': 'application/json',
         'X-Tableau-Auth': token
     }
     x = requests.post(uri, json={'query': query}, headers=headers)
 
     # we print the plain text answer for debugging purposes
     print(x.text)
 
     # we return the plain text answer received
     return x.text
 
 
 # This function is called by Tableau Prep to obtain the expected schema of the data to receive
 def get_output_schema():
     return pd.DataFrame({
         'ds_name': prep_string(),
         'flow_name': prep_string(),
         'owner_name': prep_string(),
         'project_name': prep_string()
     })
 
 
 # This is the function we well name in a Tableau Prep script node
 # It received data on the input, but doesn't use it
 
 def get_published_ds_used_in_flow(input):
 
     # The hardcoded Graphql query
     query = """query published_datasources_certified {
     publishedDatasources {
       name
       isCertified
       downstreamFlows {
         name,
         owner {
           name
         },
         projectName
       }
     }
   }
   """
 
     print("Logging into Tableau Server...")
     token = login()
     print("Session token is: " + token)
     print("")
     print("Running the following query:")
     print(query)
     print("")
     print("Answer below:")
 
     # here we get text
     json_string = run_query(token, query)
 
     # we parse the result as a json structure
     response_as_json = json.loads(json_string)
 
     # we print the json structure
     print(json.dumps(response_as_json, sort_keys=True, indent=4))
 
     # navigating the json structure to find the starting node we need
     list_of_published_ds = response_as_json["data"]["publishedDatasources"]
 
     # this array will contain the data we will return to Tableau Prep
     resultset = []
 
     # navigating the json structure and collecting data
     for ds in list_of_published_ds:
         for flow in ds["downstreamFlows"]:
             # when we find a downstream flow, we create one entry into the resultset
             resultset.append([ds["name"], flow["name"],
                               flow["owner"]["name"], flow["projectName"]])
 
     # print the resultset for debugging purposes
     print(resultset)
 
     # we turn this python array into a pandas dataframe
     df = pd.DataFrame(data=resultset, columns=[
                       "ds_name", "flow_name", "owner_name", "project_name"])
 
     # we return the dataframe to Tableau Prep
     return(df)
 def get_output_schema_bea97b3a58e648258274adfc99cd41f5(df = pd.DataFrame()):
     import inspect
     if len(inspect.getfullargspec(get_output_schema).args) == 0:
         return get_output_schema()
     else:
         return get_output_schema(df)
 result_schema_output = get_output_schema_bea97b3a58e648258274adfc99cd41f5(pd.DataFrame(_arg1))
 return result_schema_output.to_dict(orient='split') if isinstance(result_schema_output, pd.DataFrame) else result_schema_output

2021-01-28,13:48:19 [INFO] (web.py:web:2239): 200 POST /evaluate (172.18.0.1) 24.60ms
2021-01-28,13:48:19 [DEBUG] (base_handler.py:base_handler:115): Checking if need to handle authentication
2021-01-28,13:48:19 [DEBUG] (base_handler.py:base_handler:115): Handling authentication
2021-01-28,13:48:19 [INFO] (base_handler.py:base_handler:115): Authentication is not a required feature for API "v1"
2021-01-28,13:48:19 [DEBUG] (base_handler.py:base_handler:115): Checking request headers for authentication data
2021-01-28,13:48:19 [INFO] (base_handler.py:base_handler:115): Authorization header not found
2021-01-28,13:48:19 [DEBUG] (base_handler.py:base_handler:115): authentication not required, username and password are none
2021-01-28,13:48:19 [DEBUG] (state.py:state:511): Collecting Access-Control-Allow-Origin from state file ...
2021-01-28,13:48:19 [DEBUG] (state.py:state:613): Loading option 'Access-Control-Allow-Origin' from section [Service Info]...
2021-01-28,13:48:19 [DEBUG] (state.py:state:635): Returning value ''
2021-01-28,13:48:19 [DEBUG] (state.py:state:613): Loading option 'Access-Control-Allow-Headers' from section [Service Info]...
2021-01-28,13:48:19 [DEBUG] (state.py:state:635): Returning value ''
2021-01-28,13:48:19 [DEBUG] (state.py:state:613): Loading option 'Access-Control-Allow-Methods' from section [Service Info]...
2021-01-28,13:48:19 [DEBUG] (state.py:state:635): Returning value ''
2021-01-28,13:48:19 [DEBUG] (base_handler.py:base_handler:115): Processing POST request '{'data': {'_arg1': {'dummy': ['prep_string_type']}}, 'script': 'import pandas as pd\ndef get_output_schema():\n\treturn \'5e1663ee-aeb8-40e2-9e10-d7644bc9e928\'\ndef prep_string():\n\treturn [\'prep_string_type\']\ndef prep_bool():\n\treturn [\'prep_bool_type\']\ndef prep_int():\n\treturn [\'prep_int_type\']\ndef prep_decimal():\n    return [\'prep_decimal_type\']\ndef prep_date():\n\treturn [\'prep_date_type\']\ndef prep_datetime():\n\treturn [\'prep_datetime_type\']\n# os is used to retrieve environment variables\n# requests is used to make HTTP requests out to Tableau Server\n# json is used to parse the answer received from the Tableau metadata API\n# pandas is used to build a dataframe and return data to Tableau Prep\n\nimport os\nimport requests\nimport json\nimport pandas as pd\n\n\n# login will perform a login into Tableau Server and return a session token\n# it uses the API_SERVER, API_SECRET_TOKEN and API_TOKEN_NAME environment variables\n# see docker-compose.yml for these environment variables\n\ndef login():\n    body = {"credentials": {"personalAccessTokenName": os.environ[\'API_TOKEN_NAME\'],\n                            "personalAccessTokenSecret": os.environ[\'API_SECRET_TOKEN\'],\n                            "site": {"contentUrl": ""}}}\n\n    print("Performing login")\n\n    url = "https://{server}/api/3.9/auth/signin".format(\n        server=os.environ["API_SERVER"])\n\n    headers = {\n        \'accept\': \'application/json\',\n        \'content-type\': \'application/json\'\n    }\n\n    # making the request\n    x = requests.post(url, json=body, headers=headers)\n    # parsing the login response\n    response = json.loads(x.text)\n    # if everything goes well, session token is found here:\n    token = response["credentials"]["token"]\n\n    return token\n\n# run_query runs a GRAPHQL query against the Tableau metadata API\n# arguments are a session token (obtained with login function) and the query text\n# it uses the API_SERVER environment variable to connect to the server; see docker-compose.yml\n\n\ndef run_query(token, query):\n    uri = "https://{server}/api/metadata/graphql".format(\n        server=os.environ["API_SERVER"])\n    headers = {\n        \'content-type\': \'application/json\',\n        \'accept\': \'application/json\',\n        \'X-Tableau-Auth\': token\n    }\n    x = requests.post(uri, json={\'query\': query}, headers=headers)\n\n    # we print the plain text answer for debugging purposes\n    print(x.text)\n\n    # we return the plain text answer received\n    return x.text\n\n\n# This function is called by Tableau Prep to obtain the expected schema of the data to receive\ndef get_output_schema():\n    return pd.DataFrame({\n        \'ds_name\': prep_string(),\n        \'flow_name\': prep_string(),\n        \'owner_name\': prep_string(),\n        \'project_name\': prep_string()\n    })\n\n\n# This is the function we well name in a Tableau Prep script node\n# It received data on the input, but doesn\'t use it\n\ndef get_published_ds_used_in_flow(input):\n\n    # The hardcoded Graphql query\n    query = """query published_datasources_certified {\n    publishedDatasources {\n      name\n      isCertified\n      downstreamFlows {\n        name,\n        owner {\n          name\n        },\n        projectName\n      }\n    }\n  }\n  """\n\n    print("Logging into Tableau Server...")\n    token = login()\n    print("Session token is: " + token)\n    print("")\n    print("Running the following query:")\n    print(query)\n    print("")\n    print("Answer below:")\n\n    # here we get text\n    json_string = run_query(token, query)\n\n    # we parse the result as a json structure\n    response_as_json = json.loads(json_string)\n\n    # we print the json structure\n    print(json.dumps(response_as_json, sort_keys=True, indent=4))\n\n    # navigating the json structure to find the starting node we need\n    list_of_published_ds = response_as_json["data"]["publishedDatasources"]\n\n    # this array will contain the data we will return to Tableau Prep\n    resultset = []\n\n    # navigating the json structure and collecting data\n    for ds in list_of_published_ds:\n        for flow in ds["downstreamFlows"]:\n            # when we find a downstream flow, we create one entry into the resultset\n            resultset.append([ds["name"], flow["name"],\n                              flow["owner"]["name"], flow["projectName"]])\n\n    # print the resultset for debugging purposes\n    print(resultset)\n\n    # we turn this python array into a pandas dataframe\n    df = pd.DataFrame(data=resultset, columns=[\n                      "ds_name", "flow_name", "owner_name", "project_name"])\n\n    # we return the dataframe to Tableau Prep\n    return(df)\ndef get_output_schema_bea97b3a58e648258274adfc99cd41f5(df = pd.DataFrame()):\n    import inspect\n    if len(inspect.getfullargspec(get_output_schema).args) == 0:\n        return get_output_schema()\n    else:\n        return get_output_schema(df)\nresult_schema_output = get_output_schema_bea97b3a58e648258274adfc99cd41f5(pd.DataFrame(_arg1))\nreturn result_schema_output.to_dict(orient=\'split\') if isinstance(result_schema_output, pd.DataFrame) else result_schema_output'}'...
2021-01-28,13:48:19 [INFO] (base_handler.py:base_handler:115): function to evaluate=def _user_script(tabpy, _arg1):
 import pandas as pd
 def get_output_schema():
 	return '5e1663ee-aeb8-40e2-9e10-d7644bc9e928'
 def prep_string():
 	return ['prep_string_type']
 def prep_bool():
 	return ['prep_bool_type']
 def prep_int():
 	return ['prep_int_type']
 def prep_decimal():
     return ['prep_decimal_type']
 def prep_date():
 	return ['prep_date_type']
 def prep_datetime():
 	return ['prep_datetime_type']
 # os is used to retrieve environment variables
 # requests is used to make HTTP requests out to Tableau Server
 # json is used to parse the answer received from the Tableau metadata API
 # pandas is used to build a dataframe and return data to Tableau Prep
 
 import os
 import requests
 import json
 import pandas as pd
 
 
 # login will perform a login into Tableau Server and return a session token
 # it uses the API_SERVER, API_SECRET_TOKEN and API_TOKEN_NAME environment variables
 # see docker-compose.yml for these environment variables
 
 def login():
     body = {"credentials": {"personalAccessTokenName": os.environ['API_TOKEN_NAME'],
                             "personalAccessTokenSecret": os.environ['API_SECRET_TOKEN'],
                             "site": {"contentUrl": ""}}}
 
     print("Performing login")
 
     url = "https://{server}/api/3.9/auth/signin".format(
         server=os.environ["API_SERVER"])
 
     headers = {
         'accept': 'application/json',
         'content-type': 'application/json'
     }
 
     # making the request
     x = requests.post(url, json=body, headers=headers)
     # parsing the login response
     response = json.loads(x.text)
     # if everything goes well, session token is found here:
     token = response["credentials"]["token"]
 
     return token
 
 # run_query runs a GRAPHQL query against the Tableau metadata API
 # arguments are a session token (obtained with login function) and the query text
 # it uses the API_SERVER environment variable to connect to the server; see docker-compose.yml
 
 
 def run_query(token, query):
     uri = "https://{server}/api/metadata/graphql".format(
         server=os.environ["API_SERVER"])
     headers = {
         'content-type': 'application/json',
         'accept': 'application/json',
         'X-Tableau-Auth': token
     }
     x = requests.post(uri, json={'query': query}, headers=headers)
 
     # we print the plain text answer for debugging purposes
     print(x.text)
 
     # we return the plain text answer received
     return x.text
 
 
 # This function is called by Tableau Prep to obtain the expected schema of the data to receive
 def get_output_schema():
     return pd.DataFrame({
         'ds_name': prep_string(),
         'flow_name': prep_string(),
         'owner_name': prep_string(),
         'project_name': prep_string()
     })
 
 
 # This is the function we well name in a Tableau Prep script node
 # It received data on the input, but doesn't use it
 
 def get_published_ds_used_in_flow(input):
 
     # The hardcoded Graphql query
     query = """query published_datasources_certified {
     publishedDatasources {
       name
       isCertified
       downstreamFlows {
         name,
         owner {
           name
         },
         projectName
       }
     }
   }
   """
 
     print("Logging into Tableau Server...")
     token = login()
     print("Session token is: " + token)
     print("")
     print("Running the following query:")
     print(query)
     print("")
     print("Answer below:")
 
     # here we get text
     json_string = run_query(token, query)
 
     # we parse the result as a json structure
     response_as_json = json.loads(json_string)
 
     # we print the json structure
     print(json.dumps(response_as_json, sort_keys=True, indent=4))
 
     # navigating the json structure to find the starting node we need
     list_of_published_ds = response_as_json["data"]["publishedDatasources"]
 
     # this array will contain the data we will return to Tableau Prep
     resultset = []
 
     # navigating the json structure and collecting data
     for ds in list_of_published_ds:
         for flow in ds["downstreamFlows"]:
             # when we find a downstream flow, we create one entry into the resultset
             resultset.append([ds["name"], flow["name"],
                               flow["owner"]["name"], flow["projectName"]])
 
     # print the resultset for debugging purposes
     print(resultset)
 
     # we turn this python array into a pandas dataframe
     df = pd.DataFrame(data=resultset, columns=[
                       "ds_name", "flow_name", "owner_name", "project_name"])
 
     # we return the dataframe to Tableau Prep
     return(df)
 def get_output_schema_bea97b3a58e648258274adfc99cd41f5(df = pd.DataFrame()):
     import inspect
     if len(inspect.getfullargspec(get_output_schema).args) == 0:
         return get_output_schema()
     else:
         return get_output_schema(df)
 result_schema_output = get_output_schema_bea97b3a58e648258274adfc99cd41f5(pd.DataFrame(_arg1))
 return result_schema_output.to_dict(orient='split') if isinstance(result_schema_output, pd.DataFrame) else result_schema_output

2021-01-28,13:48:19 [INFO] (web.py:web:2239): 200 POST /evaluate (172.18.0.1) 21.00ms
2021-01-28,13:48:21 [DEBUG] (base_handler.py:base_handler:115): Checking if need to handle authentication
2021-01-28,13:48:21 [DEBUG] (base_handler.py:base_handler:115): Handling authentication
2021-01-28,13:48:21 [INFO] (base_handler.py:base_handler:115): Authentication is not a required feature for API "v1"
2021-01-28,13:48:21 [DEBUG] (base_handler.py:base_handler:115): Checking request headers for authentication data
2021-01-28,13:48:21 [INFO] (base_handler.py:base_handler:115): Authorization header not found
2021-01-28,13:48:21 [DEBUG] (base_handler.py:base_handler:115): authentication not required, username and password are none
2021-01-28,13:48:21 [DEBUG] (state.py:state:511): Collecting Access-Control-Allow-Origin from state file ...
2021-01-28,13:48:21 [DEBUG] (state.py:state:613): Loading option 'Access-Control-Allow-Origin' from section [Service Info]...
2021-01-28,13:48:21 [DEBUG] (state.py:state:635): Returning value ''
2021-01-28,13:48:21 [DEBUG] (state.py:state:613): Loading option 'Access-Control-Allow-Headers' from section [Service Info]...
2021-01-28,13:48:21 [DEBUG] (state.py:state:635): Returning value ''
2021-01-28,13:48:21 [DEBUG] (state.py:state:613): Loading option 'Access-Control-Allow-Methods' from section [Service Info]...
2021-01-28,13:48:21 [DEBUG] (state.py:state:635): Returning value ''
2021-01-28,13:48:21 [DEBUG] (base_handler.py:base_handler:115): Processing POST request '{'data': {'_arg1': {'dummy': ['prep_string_type']}}, 'script': 'import pandas as pd\ndef get_output_schema():\n\treturn \'5e1663ee-aeb8-40e2-9e10-d7644bc9e928\'\ndef prep_string():\n\treturn [\'prep_string_type\']\ndef prep_bool():\n\treturn [\'prep_bool_type\']\ndef prep_int():\n\treturn [\'prep_int_type\']\ndef prep_decimal():\n    return [\'prep_decimal_type\']\ndef prep_date():\n\treturn [\'prep_date_type\']\ndef prep_datetime():\n\treturn [\'prep_datetime_type\']\n# os is used to retrieve environment variables\n# requests is used to make HTTP requests out to Tableau Server\n# json is used to parse the answer received from the Tableau metadata API\n# pandas is used to build a dataframe and return data to Tableau Prep\n\nimport os\nimport requests\nimport json\nimport pandas as pd\n\n\n# login will perform a login into Tableau Server and return a session token\n# it uses the API_SERVER, API_SECRET_TOKEN and API_TOKEN_NAME environment variables\n# see docker-compose.yml for these environment variables\n\ndef login():\n    body = {"credentials": {"personalAccessTokenName": os.environ[\'API_TOKEN_NAME\'],\n                            "personalAccessTokenSecret": os.environ[\'API_SECRET_TOKEN\'],\n                            "site": {"contentUrl": ""}}}\n\n    print("Performing login")\n\n    url = "https://{server}/api/3.9/auth/signin".format(\n        server=os.environ["API_SERVER"])\n\n    headers = {\n        \'accept\': \'application/json\',\n        \'content-type\': \'application/json\'\n    }\n\n    # making the request\n    x = requests.post(url, json=body, headers=headers)\n    # parsing the login response\n    response = json.loads(x.text)\n    # if everything goes well, session token is found here:\n    token = response["credentials"]["token"]\n\n    return token\n\n# run_query runs a GRAPHQL query against the Tableau metadata API\n# arguments are a session token (obtained with login function) and the query text\n# it uses the API_SERVER environment variable to connect to the server; see docker-compose.yml\n\n\ndef run_query(token, query):\n    uri = "https://{server}/api/metadata/graphql".format(\n        server=os.environ["API_SERVER"])\n    headers = {\n        \'content-type\': \'application/json\',\n        \'accept\': \'application/json\',\n        \'X-Tableau-Auth\': token\n    }\n    x = requests.post(uri, json={\'query\': query}, headers=headers)\n\n    # we print the plain text answer for debugging purposes\n    print(x.text)\n\n    # we return the plain text answer received\n    return x.text\n\n\n# This function is called by Tableau Prep to obtain the expected schema of the data to receive\ndef get_output_schema():\n    return pd.DataFrame({\n        \'ds_name\': prep_string(),\n        \'flow_name\': prep_string(),\n        \'owner_name\': prep_string(),\n        \'project_name\': prep_string()\n    })\n\n\n# This is the function we well name in a Tableau Prep script node\n# It received data on the input, but doesn\'t use it\n\ndef get_published_ds_used_in_flow(input):\n\n    # The hardcoded Graphql query\n    query = """query published_datasources_certified {\n    publishedDatasources {\n      name\n      isCertified\n      downstreamFlows {\n        name,\n        owner {\n          name\n        },\n        projectName\n      }\n    }\n  }\n  """\n\n    print("Logging into Tableau Server...")\n    token = login()\n    print("Session token is: " + token)\n    print("")\n    print("Running the following query:")\n    print(query)\n    print("")\n    print("Answer below:")\n\n    # here we get text\n    json_string = run_query(token, query)\n\n    # we parse the result as a json structure\n    response_as_json = json.loads(json_string)\n\n    # we print the json structure\n    print(json.dumps(response_as_json, sort_keys=True, indent=4))\n\n    # navigating the json structure to find the starting node we need\n    list_of_published_ds = response_as_json["data"]["publishedDatasources"]\n\n    # this array will contain the data we will return to Tableau Prep\n    resultset = []\n\n    # navigating the json structure and collecting data\n    for ds in list_of_published_ds:\n        for flow in ds["downstreamFlows"]:\n            # when we find a downstream flow, we create one entry into the resultset\n            resultset.append([ds["name"], flow["name"],\n                              flow["owner"]["name"], flow["projectName"]])\n\n    # print the resultset for debugging purposes\n    print(resultset)\n\n    # we turn this python array into a pandas dataframe\n    df = pd.DataFrame(data=resultset, columns=[\n                      "ds_name", "flow_name", "owner_name", "project_name"])\n\n    # we return the dataframe to Tableau Prep\n    return(df)\ndef get_output_schema_bea97b3a58e648258274adfc99cd41f5(df = pd.DataFrame()):\n    import inspect\n    if len(inspect.getfullargspec(get_output_schema).args) == 0:\n        return get_output_schema()\n    else:\n        return get_output_schema(df)\nresult_schema_output = get_output_schema_bea97b3a58e648258274adfc99cd41f5(pd.DataFrame(_arg1))\nreturn result_schema_output.to_dict(orient=\'split\') if isinstance(result_schema_output, pd.DataFrame) else result_schema_output'}'...
2021-01-28,13:48:21 [INFO] (base_handler.py:base_handler:115): function to evaluate=def _user_script(tabpy, _arg1):
 import pandas as pd
 def get_output_schema():
 	return '5e1663ee-aeb8-40e2-9e10-d7644bc9e928'
 def prep_string():
 	return ['prep_string_type']
 def prep_bool():
 	return ['prep_bool_type']
 def prep_int():
 	return ['prep_int_type']
 def prep_decimal():
     return ['prep_decimal_type']
 def prep_date():
 	return ['prep_date_type']
 def prep_datetime():
 	return ['prep_datetime_type']
 # os is used to retrieve environment variables
 # requests is used to make HTTP requests out to Tableau Server
 # json is used to parse the answer received from the Tableau metadata API
 # pandas is used to build a dataframe and return data to Tableau Prep
 
 import os
 import requests
 import json
 import pandas as pd
 
 
 # login will perform a login into Tableau Server and return a session token
 # it uses the API_SERVER, API_SECRET_TOKEN and API_TOKEN_NAME environment variables
 # see docker-compose.yml for these environment variables
 
 def login():
     body = {"credentials": {"personalAccessTokenName": os.environ['API_TOKEN_NAME'],
                             "personalAccessTokenSecret": os.environ['API_SECRET_TOKEN'],
                             "site": {"contentUrl": ""}}}
 
     print("Performing login")
 
     url = "https://{server}/api/3.9/auth/signin".format(
         server=os.environ["API_SERVER"])
 
     headers = {
         'accept': 'application/json',
         'content-type': 'application/json'
     }
 
     # making the request
     x = requests.post(url, json=body, headers=headers)
     # parsing the login response
     response = json.loads(x.text)
     # if everything goes well, session token is found here:
     token = response["credentials"]["token"]
 
     return token
 
 # run_query runs a GRAPHQL query against the Tableau metadata API
 # arguments are a session token (obtained with login function) and the query text
 # it uses the API_SERVER environment variable to connect to the server; see docker-compose.yml
 
 
 def run_query(token, query):
     uri = "https://{server}/api/metadata/graphql".format(
         server=os.environ["API_SERVER"])
     headers = {
         'content-type': 'application/json',
         'accept': 'application/json',
         'X-Tableau-Auth': token
     }
     x = requests.post(uri, json={'query': query}, headers=headers)
 
     # we print the plain text answer for debugging purposes
     print(x.text)
 
     # we return the plain text answer received
     return x.text
 
 
 # This function is called by Tableau Prep to obtain the expected schema of the data to receive
 def get_output_schema():
     return pd.DataFrame({
         'ds_name': prep_string(),
         'flow_name': prep_string(),
         'owner_name': prep_string(),
         'project_name': prep_string()
     })
 
 
 # This is the function we well name in a Tableau Prep script node
 # It received data on the input, but doesn't use it
 
 def get_published_ds_used_in_flow(input):
 
     # The hardcoded Graphql query
     query = """query published_datasources_certified {
     publishedDatasources {
       name
       isCertified
       downstreamFlows {
         name,
         owner {
           name
         },
         projectName
       }
     }
   }
   """
 
     print("Logging into Tableau Server...")
     token = login()
     print("Session token is: " + token)
     print("")
     print("Running the following query:")
     print(query)
     print("")
     print("Answer below:")
 
     # here we get text
     json_string = run_query(token, query)
 
     # we parse the result as a json structure
     response_as_json = json.loads(json_string)
 
     # we print the json structure
     print(json.dumps(response_as_json, sort_keys=True, indent=4))
 
     # navigating the json structure to find the starting node we need
     list_of_published_ds = response_as_json["data"]["publishedDatasources"]
 
     # this array will contain the data we will return to Tableau Prep
     resultset = []
 
     # navigating the json structure and collecting data
     for ds in list_of_published_ds:
         for flow in ds["downstreamFlows"]:
             # when we find a downstream flow, we create one entry into the resultset
             resultset.append([ds["name"], flow["name"],
                               flow["owner"]["name"], flow["projectName"]])
 
     # print the resultset for debugging purposes
     print(resultset)
 
     # we turn this python array into a pandas dataframe
     df = pd.DataFrame(data=resultset, columns=[
                       "ds_name", "flow_name", "owner_name", "project_name"])
 
     # we return the dataframe to Tableau Prep
     return(df)
 def get_output_schema_bea97b3a58e648258274adfc99cd41f5(df = pd.DataFrame()):
     import inspect
     if len(inspect.getfullargspec(get_output_schema).args) == 0:
         return get_output_schema()
     else:
         return get_output_schema(df)
 result_schema_output = get_output_schema_bea97b3a58e648258274adfc99cd41f5(pd.DataFrame(_arg1))
 return result_schema_output.to_dict(orient='split') if isinstance(result_schema_output, pd.DataFrame) else result_schema_output

2021-01-28,13:48:21 [INFO] (web.py:web:2239): 200 POST /evaluate (172.18.0.1) 23.95ms
2021-01-28,13:48:21 [DEBUG] (base_handler.py:base_handler:115): Checking if need to handle authentication
2021-01-28,13:48:21 [DEBUG] (base_handler.py:base_handler:115): Handling authentication
2021-01-28,13:48:21 [INFO] (base_handler.py:base_handler:115): Authentication is not a required feature for API "v1"
2021-01-28,13:48:21 [DEBUG] (base_handler.py:base_handler:115): Checking request headers for authentication data
2021-01-28,13:48:21 [INFO] (base_handler.py:base_handler:115): Authorization header not found
2021-01-28,13:48:21 [DEBUG] (base_handler.py:base_handler:115): authentication not required, username and password are none
2021-01-28,13:48:21 [DEBUG] (state.py:state:511): Collecting Access-Control-Allow-Origin from state file ...
2021-01-28,13:48:21 [DEBUG] (state.py:state:613): Loading option 'Access-Control-Allow-Origin' from section [Service Info]...
2021-01-28,13:48:21 [DEBUG] (state.py:state:635): Returning value ''
2021-01-28,13:48:21 [DEBUG] (state.py:state:613): Loading option 'Access-Control-Allow-Headers' from section [Service Info]...
2021-01-28,13:48:21 [DEBUG] (state.py:state:635): Returning value ''
2021-01-28,13:48:21 [DEBUG] (state.py:state:613): Loading option 'Access-Control-Allow-Methods' from section [Service Info]...
2021-01-28,13:48:21 [DEBUG] (state.py:state:635): Returning value ''
2021-01-28,13:48:21 [DEBUG] (base_handler.py:base_handler:115): Processing POST request '{'data': {'_arg1': {'dummy': ['prep_string_type']}}, 'script': 'import pandas as pd\ndef get_output_schema():\n\treturn \'5e1663ee-aeb8-40e2-9e10-d7644bc9e928\'\ndef prep_string():\n\treturn [\'prep_string_type\']\ndef prep_bool():\n\treturn [\'prep_bool_type\']\ndef prep_int():\n\treturn [\'prep_int_type\']\ndef prep_decimal():\n    return [\'prep_decimal_type\']\ndef prep_date():\n\treturn [\'prep_date_type\']\ndef prep_datetime():\n\treturn [\'prep_datetime_type\']\n# os is used to retrieve environment variables\n# requests is used to make HTTP requests out to Tableau Server\n# json is used to parse the answer received from the Tableau metadata API\n# pandas is used to build a dataframe and return data to Tableau Prep\n\nimport os\nimport requests\nimport json\nimport pandas as pd\n\n\n# login will perform a login into Tableau Server and return a session token\n# it uses the API_SERVER, API_SECRET_TOKEN and API_TOKEN_NAME environment variables\n# see docker-compose.yml for these environment variables\n\ndef login():\n    body = {"credentials": {"personalAccessTokenName": os.environ[\'API_TOKEN_NAME\'],\n                            "personalAccessTokenSecret": os.environ[\'API_SECRET_TOKEN\'],\n                            "site": {"contentUrl": ""}}}\n\n    print("Performing login")\n\n    url = "https://{server}/api/3.9/auth/signin".format(\n        server=os.environ["API_SERVER"])\n\n    headers = {\n        \'accept\': \'application/json\',\n        \'content-type\': \'application/json\'\n    }\n\n    # making the request\n    x = requests.post(url, json=body, headers=headers)\n    # parsing the login response\n    response = json.loads(x.text)\n    # if everything goes well, session token is found here:\n    token = response["credentials"]["token"]\n\n    return token\n\n# run_query runs a GRAPHQL query against the Tableau metadata API\n# arguments are a session token (obtained with login function) and the query text\n# it uses the API_SERVER environment variable to connect to the server; see docker-compose.yml\n\n\ndef run_query(token, query):\n    uri = "https://{server}/api/metadata/graphql".format(\n        server=os.environ["API_SERVER"])\n    headers = {\n        \'content-type\': \'application/json\',\n        \'accept\': \'application/json\',\n        \'X-Tableau-Auth\': token\n    }\n    x = requests.post(uri, json={\'query\': query}, headers=headers)\n\n    # we print the plain text answer for debugging purposes\n    print(x.text)\n\n    # we return the plain text answer received\n    return x.text\n\n\n# This function is called by Tableau Prep to obtain the expected schema of the data to receive\ndef get_output_schema():\n    return pd.DataFrame({\n        \'ds_name\': prep_string(),\n        \'flow_name\': prep_string(),\n        \'owner_name\': prep_string(),\n        \'project_name\': prep_string()\n    })\n\n\n# This is the function we well name in a Tableau Prep script node\n# It received data on the input, but doesn\'t use it\n\ndef get_published_ds_used_in_flow(input):\n\n    # The hardcoded Graphql query\n    query = """query published_datasources_certified {\n    publishedDatasources {\n      name\n      isCertified\n      downstreamFlows {\n        name,\n        owner {\n          name\n        },\n        projectName\n      }\n    }\n  }\n  """\n\n    print("Logging into Tableau Server...")\n    token = login()\n    print("Session token is: " + token)\n    print("")\n    print("Running the following query:")\n    print(query)\n    print("")\n    print("Answer below:")\n\n    # here we get text\n    json_string = run_query(token, query)\n\n    # we parse the result as a json structure\n    response_as_json = json.loads(json_string)\n\n    # we print the json structure\n    print(json.dumps(response_as_json, sort_keys=True, indent=4))\n\n    # navigating the json structure to find the starting node we need\n    list_of_published_ds = response_as_json["data"]["publishedDatasources"]\n\n    # this array will contain the data we will return to Tableau Prep\n    resultset = []\n\n    # navigating the json structure and collecting data\n    for ds in list_of_published_ds:\n        for flow in ds["downstreamFlows"]:\n            # when we find a downstream flow, we create one entry into the resultset\n            resultset.append([ds["name"], flow["name"],\n                              flow["owner"]["name"], flow["projectName"]])\n\n    # print the resultset for debugging purposes\n    print(resultset)\n\n    # we turn this python array into a pandas dataframe\n    df = pd.DataFrame(data=resultset, columns=[\n                      "ds_name", "flow_name", "owner_name", "project_name"])\n\n    # we return the dataframe to Tableau Prep\n    return(df)\ndef get_output_schema_bea97b3a58e648258274adfc99cd41f5(df = pd.DataFrame()):\n    import inspect\n    if len(inspect.getfullargspec(get_output_schema).args) == 0:\n        return get_output_schema()\n    else:\n        return get_output_schema(df)\nresult_schema_output = get_output_schema_bea97b3a58e648258274adfc99cd41f5(pd.DataFrame(_arg1))\nreturn result_schema_output.to_dict(orient=\'split\') if isinstance(result_schema_output, pd.DataFrame) else result_schema_output'}'...
2021-01-28,13:48:21 [INFO] (base_handler.py:base_handler:115): function to evaluate=def _user_script(tabpy, _arg1):
 import pandas as pd
 def get_output_schema():
 	return '5e1663ee-aeb8-40e2-9e10-d7644bc9e928'
 def prep_string():
 	return ['prep_string_type']
 def prep_bool():
 	return ['prep_bool_type']
 def prep_int():
 	return ['prep_int_type']
 def prep_decimal():
     return ['prep_decimal_type']
 def prep_date():
 	return ['prep_date_type']
 def prep_datetime():
 	return ['prep_datetime_type']
 # os is used to retrieve environment variables
 # requests is used to make HTTP requests out to Tableau Server
 # json is used to parse the answer received from the Tableau metadata API
 # pandas is used to build a dataframe and return data to Tableau Prep
 
 import os
 import requests
 import json
 import pandas as pd
 
 
 # login will perform a login into Tableau Server and return a session token
 # it uses the API_SERVER, API_SECRET_TOKEN and API_TOKEN_NAME environment variables
 # see docker-compose.yml for these environment variables
 
 def login():
     body = {"credentials": {"personalAccessTokenName": os.environ['API_TOKEN_NAME'],
                             "personalAccessTokenSecret": os.environ['API_SECRET_TOKEN'],
                             "site": {"contentUrl": ""}}}
 
     print("Performing login")
 
     url = "https://{server}/api/3.9/auth/signin".format(
         server=os.environ["API_SERVER"])
 
     headers = {
         'accept': 'application/json',
         'content-type': 'application/json'
     }
 
     # making the request
     x = requests.post(url, json=body, headers=headers)
     # parsing the login response
     response = json.loads(x.text)
     # if everything goes well, session token is found here:
     token = response["credentials"]["token"]
 
     return token
 
 # run_query runs a GRAPHQL query against the Tableau metadata API
 # arguments are a session token (obtained with login function) and the query text
 # it uses the API_SERVER environment variable to connect to the server; see docker-compose.yml
 
 
 def run_query(token, query):
     uri = "https://{server}/api/metadata/graphql".format(
         server=os.environ["API_SERVER"])
     headers = {
         'content-type': 'application/json',
         'accept': 'application/json',
         'X-Tableau-Auth': token
     }
     x = requests.post(uri, json={'query': query}, headers=headers)
 
     # we print the plain text answer for debugging purposes
     print(x.text)
 
     # we return the plain text answer received
     return x.text
 
 
 # This function is called by Tableau Prep to obtain the expected schema of the data to receive
 def get_output_schema():
     return pd.DataFrame({
         'ds_name': prep_string(),
         'flow_name': prep_string(),
         'owner_name': prep_string(),
         'project_name': prep_string()
     })
 
 
 # This is the function we well name in a Tableau Prep script node
 # It received data on the input, but doesn't use it
 
 def get_published_ds_used_in_flow(input):
 
     # The hardcoded Graphql query
     query = """query published_datasources_certified {
     publishedDatasources {
       name
       isCertified
       downstreamFlows {
         name,
         owner {
           name
         },
         projectName
       }
     }
   }
   """
 
     print("Logging into Tableau Server...")
     token = login()
     print("Session token is: " + token)
     print("")
     print("Running the following query:")
     print(query)
     print("")
     print("Answer below:")
 
     # here we get text
     json_string = run_query(token, query)
 
     # we parse the result as a json structure
     response_as_json = json.loads(json_string)
 
     # we print the json structure
     print(json.dumps(response_as_json, sort_keys=True, indent=4))
 
     # navigating the json structure to find the starting node we need
     list_of_published_ds = response_as_json["data"]["publishedDatasources"]
 
     # this array will contain the data we will return to Tableau Prep
     resultset = []
 
     # navigating the json structure and collecting data
     for ds in list_of_published_ds:
         for flow in ds["downstreamFlows"]:
             # when we find a downstream flow, we create one entry into the resultset
             resultset.append([ds["name"], flow["name"],
                               flow["owner"]["name"], flow["projectName"]])
 
     # print the resultset for debugging purposes
     print(resultset)
 
     # we turn this python array into a pandas dataframe
     df = pd.DataFrame(data=resultset, columns=[
                       "ds_name", "flow_name", "owner_name", "project_name"])
 
     # we return the dataframe to Tableau Prep
     return(df)
 def get_output_schema_bea97b3a58e648258274adfc99cd41f5(df = pd.DataFrame()):
     import inspect
     if len(inspect.getfullargspec(get_output_schema).args) == 0:
         return get_output_schema()
     else:
         return get_output_schema(df)
 result_schema_output = get_output_schema_bea97b3a58e648258274adfc99cd41f5(pd.DataFrame(_arg1))
 return result_schema_output.to_dict(orient='split') if isinstance(result_schema_output, pd.DataFrame) else result_schema_output

2021-01-28,13:48:21 [INFO] (web.py:web:2239): 200 POST /evaluate (172.18.0.1) 26.60ms
